{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 11257.114258\n",
      "bce: 104.845108, kld: 44.609077\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 7963.406738\n",
      "bce: 103.430153, kld: 31.439907\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 7084.927246\n",
      "bce: 102.355148, kld: 27.930288\n",
      "====> Epoch: 0 Average loss: 8576.4697, bce: 103.3553, kld: 33.8925\n",
      "====> Testing Average Loss: 83.58046115696978\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 7005.168945\n",
      "bce: 102.284912, kld: 27.611536\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 6640.970703\n",
      "bce: 101.209114, kld: 26.159046\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 6416.898926\n",
      "bce: 100.267792, kld: 25.266525\n",
      "====> Epoch: 1 Average loss: 6658.7632, bce: 101.2383, kld: 26.2301\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 6369.008789\n",
      "bce: 100.273468, kld: 25.074942\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 6188.260742\n",
      "bce: 99.548080, kld: 24.354851\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 6001.984375\n",
      "bce: 98.633270, kld: 23.613405\n",
      "====> Epoch: 2 Average loss: 6181.4191, bce: 99.3882, kld: 24.3281\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 5970.723633\n",
      "bce: 98.351242, kld: 23.489491\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 5828.916992\n",
      "bce: 97.271935, kld: 22.926580\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 5669.823730\n",
      "bce: 96.704994, kld: 22.292475\n",
      "====> Epoch: 3 Average loss: 5823.2702, bce: 97.4481, kld: 22.9033\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 5645.020020\n",
      "bce: 96.312622, kld: 22.194830\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 5486.989258\n",
      "bce: 95.896591, kld: 21.564371\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 5315.918945\n",
      "bce: 95.361740, kld: 20.882229\n",
      "====> Epoch: 4 Average loss: 5481.5375, bce: 95.9032, kld: 21.5425\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 5288.139160\n",
      "bce: 95.334366, kld: 20.771219\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 5108.964355\n",
      "bce: 94.933113, kld: 20.056126\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 4921.764648\n",
      "bce: 94.704803, kld: 19.308241\n",
      "====> Epoch: 5 Average loss: 5107.3372, bce: 94.8520, kld: 20.0499\n",
      "====> Testing Average Loss: 77.14117627479696\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 4882.908203\n",
      "bce: 94.542427, kld: 19.153463\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 4682.315430\n",
      "bce: 93.941185, kld: 18.353497\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 4481.026855\n",
      "bce: 93.831711, kld: 17.548780\n",
      "====> Epoch: 6 Average loss: 4683.2338, bce: 94.0157, kld: 18.3569\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 4432.522461\n",
      "bce: 93.522957, kld: 17.355997\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 4209.403809\n",
      "bce: 93.092712, kld: 16.465244\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 3982.164307\n",
      "bce: 92.964790, kld: 15.556798\n",
      "====> Epoch: 7 Average loss: 4208.9263, bce: 93.2609, kld: 16.4627\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 3938.567871\n",
      "bce: 93.085220, kld: 15.381930\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 3702.026611\n",
      "bce: 92.567802, kld: 14.437835\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 3470.428711\n",
      "bce: 92.476135, kld: 13.511810\n",
      "====> Epoch: 8 Average loss: 3702.7719, bce: 92.5858, kld: 14.4407\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 3417.229492\n",
      "bce: 92.221985, kld: 13.300031\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 3194.290039\n",
      "bce: 91.918137, kld: 12.409488\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 2971.661865\n",
      "bce: 91.432755, kld: 11.520916\n",
      "====> Epoch: 9 Average loss: 3194.8369, bce: 91.9294, kld: 12.4116\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 2928.490723\n",
      "bce: 91.838310, kld: 11.346609\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 2712.911621\n",
      "bce: 91.355721, kld: 10.486223\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 2511.830566\n",
      "bce: 91.182510, kld: 9.682591\n",
      "====> Epoch: 10 Average loss: 2716.0808, bce: 91.2859, kld: 10.4992\n",
      "====> Testing Average Loss: 74.33793769138596\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 2473.687744\n",
      "bce: 91.166763, kld: 9.530084\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 2284.645752\n",
      "bce: 90.676056, kld: 8.775879\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 2111.423828\n",
      "bce: 90.401909, kld: 8.084087\n",
      "====> Epoch: 11 Average loss: 2288.9627, bce: 90.6521, kld: 8.7932\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 2080.655273\n",
      "bce: 90.323540, kld: 7.961327\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 1922.012085\n",
      "bce: 89.997185, kld: 7.328060\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 1775.632568\n",
      "bce: 89.834946, kld: 6.743190\n",
      "====> Epoch: 12 Average loss: 1924.3760, bce: 90.0325, kld: 7.3374\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 1749.978027\n",
      "bce: 89.578842, kld: 6.641597\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 1621.502319\n",
      "bce: 89.280396, kld: 6.128888\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 1502.585083\n",
      "bce: 89.146637, kld: 5.653754\n",
      "====> Epoch: 13 Average loss: 1622.4251, bce: 89.4139, kld: 6.1320\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 1479.375610\n",
      "bce: 89.170494, kld: 5.560820\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 1374.572144\n",
      "bce: 88.609550, kld: 5.143851\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 1279.255737\n",
      "bce: 88.545403, kld: 4.762841\n",
      "====> Epoch: 14 Average loss: 1376.7686, bce: 88.8177, kld: 5.1518\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 1261.190918\n",
      "bce: 88.368263, kld: 4.691290\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 1177.105835\n",
      "bce: 88.445076, kld: 4.354643\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 1100.822998\n",
      "bce: 88.159981, kld: 4.050652\n",
      "====> Epoch: 15 Average loss: 1178.5913, bce: 88.2242, kld: 4.3615\n",
      "====> Testing Average Loss: 71.87628145386766\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 1086.955444\n",
      "bce: 88.147285, kld: 3.995232\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 1018.998291\n",
      "bce: 87.633148, kld: 3.725461\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 956.032043\n",
      "bce: 87.409447, kld: 3.474490\n",
      "====> Epoch: 16 Average loss: 1018.7379, bce: 87.6362, kld: 3.7244\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 944.114685\n",
      "bce: 87.462410, kld: 3.426609\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 889.458435\n",
      "bce: 87.121338, kld: 3.209348\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 838.254883\n",
      "bce: 86.809944, kld: 3.005780\n",
      "====> Epoch: 17 Average loss: 889.3609, bce: 87.0657, kld: 3.2092\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 829.298950\n",
      "bce: 86.764854, kld: 2.970136\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 783.818420\n",
      "bce: 86.850647, kld: 2.787871\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 742.132324\n",
      "bce: 86.106964, kld: 2.624101\n",
      "====> Epoch: 18 Average loss: 783.8261, bce: 86.4980, kld: 2.7893\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 734.065857\n",
      "bce: 86.213913, kld: 2.591408\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 697.128296\n",
      "bce: 85.805710, kld: 2.445290\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 662.474915\n",
      "bce: 85.691666, kld: 2.307133\n",
      "====> Epoch: 19 Average loss: 697.0214, bce: 85.9397, kld: 2.4443\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 656.131531\n",
      "bce: 86.012589, kld: 2.280476\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 624.978882\n",
      "bce: 85.267555, kld: 2.158845\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 595.822632\n",
      "bce: 85.193535, kld: 2.042516\n",
      "====> Epoch: 20 Average loss: 624.9971, bce: 85.3901, kld: 2.1584\n",
      "====> Testing Average Loss: 69.59935636067101\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 590.612671\n",
      "bce: 84.990234, kld: 2.022490\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 564.478821\n",
      "bce: 84.746933, kld: 1.918928\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 539.855408\n",
      "bce: 84.428764, kld: 1.821707\n",
      "====> Epoch: 21 Average loss: 564.6210, bce: 84.8467, kld: 1.9191\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 535.291382\n",
      "bce: 84.594719, kld: 1.802787\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 513.367188\n",
      "bce: 84.334373, kld: 1.716131\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 493.212006\n",
      "bce: 84.128326, kld: 1.636335\n",
      "====> Epoch: 22 Average loss: 513.5904, bce: 84.3064, kld: 1.7171\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 489.087402\n",
      "bce: 84.260925, kld: 1.619306\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 469.817963\n",
      "bce: 83.640511, kld: 1.544710\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 452.388977\n",
      "bce: 83.399368, kld: 1.475958\n",
      "====> Epoch: 23 Average loss: 470.1158, bce: 83.7741, kld: 1.5454\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 448.787994\n",
      "bce: 83.619850, kld: 1.460673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 433.085358\n",
      "bce: 83.193634, kld: 1.399567\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 417.704834\n",
      "bce: 83.047562, kld: 1.338629\n",
      "====> Epoch: 24 Average loss: 432.7688, bce: 83.2501, kld: 1.3981\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 414.017944\n",
      "bce: 82.971153, kld: 1.324187\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 400.334991\n",
      "bce: 82.764000, kld: 1.270284\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 387.446259\n",
      "bce: 82.703613, kld: 1.218971\n",
      "====> Epoch: 25 Average loss: 400.4447, bce: 82.7336, kld: 1.2708\n",
      "====> Testing Average Loss: 67.4688644155239\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 383.905212\n",
      "bce: 82.353027, kld: 1.206209\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 372.260559\n",
      "bce: 82.230759, kld: 1.160119\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 360.231689\n",
      "bce: 81.888962, kld: 1.113371\n",
      "====> Epoch: 26 Average loss: 372.2902, bce: 82.2183, kld: 1.1603\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 358.575714\n",
      "bce: 82.057037, kld: 1.106075\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 347.830719\n",
      "bce: 81.781891, kld: 1.064195\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 337.519440\n",
      "bce: 81.300842, kld: 1.024874\n",
      "====> Epoch: 27 Average loss: 347.6063, bce: 81.7102, kld: 1.0636\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 335.316650\n",
      "bce: 81.604065, kld: 1.014850\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 325.216217\n",
      "bce: 81.154877, kld: 0.976245\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 317.036499\n",
      "bce: 81.126038, kld: 0.943642\n",
      "====> Epoch: 28 Average loss: 325.8163, bce: 81.2118, kld: 0.9784\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 314.895142\n",
      "bce: 80.832886, kld: 0.936249\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 307.030945\n",
      "bce: 80.706184, kld: 0.905299\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 298.424347\n",
      "bce: 80.434273, kld: 0.871960\n",
      "====> Epoch: 29 Average loss: 306.5240, bce: 80.7163, kld: 0.9032\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 297.280792\n",
      "bce: 80.585281, kld: 0.866782\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 289.278412\n",
      "bce: 80.288177, kld: 0.835961\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 282.128754\n",
      "bce: 80.229126, kld: 0.807599\n",
      "====> Epoch: 30 Average loss: 289.3178, bce: 80.2284, kld: 0.8364\n",
      "====> Testing Average Loss: 65.46463936226867\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 280.228882\n",
      "bce: 79.875473, kld: 0.801414\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 273.966919\n",
      "bce: 79.703171, kld: 0.777055\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 267.129364\n",
      "bce: 79.581718, kld: 0.750191\n",
      "====> Epoch: 31 Average loss: 273.9146, bce: 79.7420, kld: 0.7767\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 266.114899\n",
      "bce: 79.379250, kld: 0.746943\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 260.540710\n",
      "bce: 79.436066, kld: 0.724419\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 254.386765\n",
      "bce: 78.868988, kld: 0.702071\n",
      "====> Epoch: 32 Average loss: 260.0670, bce: 79.2676, kld: 0.7232\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 253.109329\n",
      "bce: 79.128433, kld: 0.695924\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 247.489639\n",
      "bce: 78.792740, kld: 0.674788\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 242.453445\n",
      "bce: 78.819595, kld: 0.654535\n",
      "====> Epoch: 33 Average loss: 247.5534, bce: 78.7940, kld: 0.6750\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 241.326416\n",
      "bce: 78.499580, kld: 0.651307\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 236.089630\n",
      "bce: 78.354118, kld: 0.630942\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 231.475082\n",
      "bce: 78.166367, kld: 0.613235\n",
      "====> Epoch: 34 Average loss: 236.2305, bce: 78.3284, kld: 0.6316\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 230.449127\n",
      "bce: 78.258163, kld: 0.608764\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 225.963852\n",
      "bce: 77.835190, kld: 0.592515\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 221.555634\n",
      "bce: 77.656158, kld: 0.575598\n",
      "====> Epoch: 35 Average loss: 225.9138, bce: 77.8665, kld: 0.5922\n",
      "====> Testing Average Loss: 63.57390410730928\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 220.301895\n",
      "bce: 77.501450, kld: 0.571202\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 216.991608\n",
      "bce: 77.541969, kld: 0.557799\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 212.619263\n",
      "bce: 77.299316, kld: 0.541280\n",
      "====> Epoch: 36 Average loss: 216.5132, bce: 77.4116, kld: 0.5564\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 211.921387\n",
      "bce: 77.307549, kld: 0.538455\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 208.136963\n",
      "bce: 77.103233, kld: 0.524135\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 203.927094\n",
      "bce: 76.639755, kld: 0.509149\n",
      "====> Epoch: 37 Average loss: 207.9053, bce: 76.9612, kld: 0.5238\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 203.622681\n",
      "bce: 76.819550, kld: 0.507213\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 200.012329\n",
      "bce: 76.484261, kld: 0.494112\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 196.634247\n",
      "bce: 76.112740, kld: 0.482086\n",
      "====> Epoch: 38 Average loss: 200.0008, bce: 76.5184, kld: 0.4939\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 195.733444\n",
      "bce: 76.260376, kld: 0.477892\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 192.585358\n",
      "bce: 75.985786, kld: 0.466398\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 189.760361\n",
      "bce: 75.969818, kld: 0.455162\n",
      "====> Epoch: 39 Average loss: 192.7176, bce: 76.0750, kld: 0.4666\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 188.857208\n",
      "bce: 75.905991, kld: 0.451805\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 186.134995\n",
      "bce: 75.719742, kld: 0.441661\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 182.909210\n",
      "bce: 75.347855, kld: 0.430245\n",
      "====> Epoch: 40 Average loss: 185.9870, bce: 75.6400, kld: 0.4414\n",
      "====> Testing Average Loss: 61.78661920849421\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 182.876099\n",
      "bce: 75.517258, kld: 0.429435\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 179.712738\n",
      "bce: 75.354340, kld: 0.417434\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 177.449005\n",
      "bce: 75.003113, kld: 0.409784\n",
      "====> Epoch: 41 Average loss: 179.7674, bce: 75.2080, kld: 0.4182\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 176.733551\n",
      "bce: 75.084091, kld: 0.406598\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 173.819778\n",
      "bce: 74.823349, kld: 0.395986\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 171.655731\n",
      "bce: 74.654587, kld: 0.388005\n",
      "====> Epoch: 42 Average loss: 173.9977, bce: 74.7803, kld: 0.3969\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 170.931732\n",
      "bce: 74.599426, kld: 0.385329\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 168.652756\n",
      "bce: 74.412613, kld: 0.376961\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 166.282471\n",
      "bce: 74.233376, kld: 0.368196\n",
      "====> Epoch: 43 Average loss: 168.6173, bce: 74.3587, kld: 0.3770\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 165.805542\n",
      "bce: 74.229599, kld: 0.366304\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 163.954987\n",
      "bce: 73.940125, kld: 0.360059\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 161.476868\n",
      "bce: 73.782074, kld: 0.350779\n",
      "====> Epoch: 44 Average loss: 163.6266, bce: 73.9433, kld: 0.3587\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 160.990295\n",
      "bce: 73.627380, kld: 0.349452\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 158.859436\n",
      "bce: 73.606194, kld: 0.341013\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 156.722748\n",
      "bce: 73.277924, kld: 0.333779\n",
      "====> Epoch: 45 Average loss: 158.9531, bce: 73.5306, kld: 0.3417\n",
      "====> Testing Average Loss: 60.10215642058314\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 156.765472\n",
      "bce: 73.406212, kld: 0.333437\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 154.611267\n",
      "bce: 73.104240, kld: 0.326028\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 152.904572\n",
      "bce: 73.074295, kld: 0.319321\n",
      "====> Epoch: 46 Average loss: 154.5797, bce: 73.1222, kld: 0.3258\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 152.402603\n",
      "bce: 72.919952, kld: 0.317931\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 150.549530\n",
      "bce: 72.804123, kld: 0.310982\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 148.521515\n",
      "bce: 72.444046, kld: 0.304310\n",
      "====> Epoch: 47 Average loss: 150.4867, bce: 72.7187, kld: 0.3111\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 148.453339\n",
      "bce: 72.499016, kld: 0.303817\n",
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 146.539154\n",
      "bce: 72.216042, kld: 0.297292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 145.037003\n",
      "bce: 72.264191, kld: 0.291091\n",
      "====> Epoch: 48 Average loss: 146.6363, bce: 72.3187, kld: 0.2973\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 144.822510\n",
      "bce: 72.249748, kld: 0.290291\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 143.186127\n",
      "bce: 71.919167, kld: 0.285068\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 141.183044\n",
      "bce: 71.633682, kld: 0.278197\n",
      "====> Epoch: 49 Average loss: 143.0181, bce: 71.9215, kld: 0.2844\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 141.054749\n",
      "bce: 71.538651, kld: 0.278064\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 139.456909\n",
      "bce: 71.556778, kld: 0.271601\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 138.139313\n",
      "bce: 71.414963, kld: 0.266897\n",
      "====> Epoch: 50 Average loss: 139.6049, bce: 71.5303, kld: 0.2723\n",
      "====> Testing Average Loss: 58.49849387564905\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 137.822250\n",
      "bce: 71.284882, kld: 0.266149\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 136.241241\n",
      "bce: 71.044373, kld: 0.260788\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 135.068665\n",
      "bce: 70.989975, kld: 0.256315\n",
      "====> Epoch: 51 Average loss: 136.3829, bce: 71.1423, kld: 0.2610\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 135.013367\n",
      "bce: 71.028450, kld: 0.255940\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 133.791183\n",
      "bce: 71.033043, kld: 0.251033\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 131.611954\n",
      "bce: 70.328049, kld: 0.245136\n",
      "====> Epoch: 52 Average loss: 133.3407, bce: 70.7608, kld: 0.2503\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 131.628937\n",
      "bce: 70.492256, kld: 0.244547\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 130.573563\n",
      "bce: 70.418884, kld: 0.240619\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 129.193634\n",
      "bce: 70.198326, kld: 0.235981\n",
      "====> Epoch: 53 Average loss: 130.4672, bce: 70.3821, kld: 0.2403\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 129.112152\n",
      "bce: 70.332619, kld: 0.235118\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 127.765854\n",
      "bce: 69.953979, kld: 0.231247\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 126.638588\n",
      "bce: 69.933105, kld: 0.226822\n",
      "====> Epoch: 54 Average loss: 127.7350, bce: 70.0067, kld: 0.2309\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 126.335030\n",
      "bce: 69.785698, kld: 0.226197\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 125.183975\n",
      "bce: 69.731430, kld: 0.221810\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 123.945198\n",
      "bce: 69.488022, kld: 0.217829\n",
      "====> Epoch: 55 Average loss: 125.1475, bce: 69.6411, kld: 0.2220\n",
      "====> Testing Average Loss: 56.989850302889096\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 123.719940\n",
      "bce: 69.485039, kld: 0.216940\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 122.446503\n",
      "bce: 69.136322, kld: 0.213241\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 121.554108\n",
      "bce: 69.098541, kld: 0.209822\n",
      "====> Epoch: 56 Average loss: 122.6968, bce: 69.2774, kld: 0.2137\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 121.301086\n",
      "bce: 68.954018, kld: 0.209388\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 120.273552\n",
      "bce: 68.985428, kld: 0.205152\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 119.386833\n",
      "bce: 68.911179, kld: 0.201903\n",
      "====> Epoch: 57 Average loss: 120.3574, bce: 68.9189, kld: 0.2058\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 119.112930\n",
      "bce: 68.783897, kld: 0.201316\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 118.238968\n",
      "bce: 68.597588, kld: 0.198566\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 117.188934\n",
      "bce: 68.339546, kld: 0.195398\n",
      "====> Epoch: 58 Average loss: 118.1336, bce: 68.5673, kld: 0.1983\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 117.045563\n",
      "bce: 68.417358, kld: 0.194513\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 115.886795\n",
      "bce: 68.191345, kld: 0.190782\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 114.962479\n",
      "bce: 68.054199, kld: 0.187633\n",
      "====> Epoch: 59 Average loss: 116.0101, bce: 68.2167, kld: 0.1912\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 114.766457\n",
      "bce: 68.035049, kld: 0.186926\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 114.127930\n",
      "bce: 68.003952, kld: 0.184496\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 112.978516\n",
      "bce: 67.637733, kld: 0.181363\n",
      "====> Epoch: 60 Average loss: 113.9805, bce: 67.8686, kld: 0.1844\n",
      "====> Testing Average Loss: 55.57447618492877\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 113.001785\n",
      "bce: 67.669472, kld: 0.181329\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 112.047829\n",
      "bce: 67.574852, kld: 0.177892\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 111.215363\n",
      "bce: 67.367157, kld: 0.175393\n",
      "====> Epoch: 61 Average loss: 112.0515, bce: 67.5284, kld: 0.1781\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 111.094139\n",
      "bce: 67.333603, kld: 0.175042\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 109.964653\n",
      "bce: 67.102745, kld: 0.171448\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 109.474823\n",
      "bce: 67.125854, kld: 0.169396\n",
      "====> Epoch: 62 Average loss: 110.1993, bce: 67.1920, kld: 0.1720\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 109.402863\n",
      "bce: 67.138008, kld: 0.169059\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 108.417374\n",
      "bce: 66.930389, kld: 0.165948\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 107.583389\n",
      "bce: 66.669151, kld: 0.163657\n",
      "====> Epoch: 63 Average loss: 108.4355, bce: 66.8605, kld: 0.1663\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 107.413666\n",
      "bce: 66.584732, kld: 0.163316\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 106.671616\n",
      "bce: 66.437805, kld: 0.160935\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 106.028290\n",
      "bce: 66.448990, kld: 0.158317\n",
      "====> Epoch: 64 Average loss: 106.7366, bce: 66.5296, kld: 0.1608\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 105.847382\n",
      "bce: 66.384087, kld: 0.157853\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 105.124535\n",
      "bce: 66.148956, kld: 0.155902\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 104.299683\n",
      "bce: 65.963409, kld: 0.153345\n",
      "====> Epoch: 65 Average loss: 105.1045, bce: 66.2033, kld: 0.1556\n",
      "====> Testing Average Loss: 54.242201021834646\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 104.109390\n",
      "bce: 65.863121, kld: 0.152985\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 103.702477\n",
      "bce: 65.998581, kld: 0.150816\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 102.821526\n",
      "bce: 65.718529, kld: 0.148412\n",
      "====> Epoch: 66 Average loss: 103.5462, bce: 65.8813, kld: 0.1507\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 102.911324\n",
      "bce: 65.925102, kld: 0.147945\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 101.866287\n",
      "bce: 65.369728, kld: 0.145986\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 101.659637\n",
      "bce: 65.639664, kld: 0.144080\n",
      "====> Epoch: 67 Average loss: 102.0458, bce: 65.5640, kld: 0.1459\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 101.257217\n",
      "bce: 65.463501, kld: 0.143175\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 100.518410\n",
      "bce: 65.143341, kld: 0.141500\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 100.140244\n",
      "bce: 65.266930, kld: 0.139493\n",
      "====> Epoch: 68 Average loss: 100.6015, bce: 65.2483, kld: 0.1414\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 99.615280\n",
      "bce: 64.957230, kld: 0.138632\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 99.328232\n",
      "bce: 64.999191, kld: 0.137316\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 98.724358\n",
      "bce: 64.848473, kld: 0.135504\n",
      "====> Epoch: 69 Average loss: 99.2078, bce: 64.9348, kld: 0.1371\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 98.603226\n",
      "bce: 64.869781, kld: 0.134934\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 98.190819\n",
      "bce: 64.871887, kld: 0.133276\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 97.272812\n",
      "bce: 64.525772, kld: 0.130988\n",
      "====> Epoch: 70 Average loss: 97.8770, bce: 64.6283, kld: 0.1330\n",
      "====> Testing Average Loss: 52.98565853414991\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 97.117065\n",
      "bce: 64.404610, kld: 0.130850\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 96.781563\n",
      "bce: 64.572281, kld: 0.128837\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 95.939980\n",
      "bce: 64.099411, kld: 0.127362\n",
      "====> Epoch: 71 Average loss: 96.5814, bce: 64.3219, kld: 0.1290\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 96.178848\n",
      "bce: 64.387672, kld: 0.127165\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 95.542648\n",
      "bce: 64.184494, kld: 0.125433\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 94.756844\n",
      "bce: 63.878841, kld: 0.123512\n",
      "====> Epoch: 72 Average loss: 95.3385, bce: 64.0198, kld: 0.1253\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 94.811020\n",
      "bce: 64.026482, kld: 0.123138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 94.047165\n",
      "bce: 63.676392, kld: 0.121483\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 93.534027\n",
      "bce: 63.469543, kld: 0.120258\n",
      "====> Epoch: 73 Average loss: 94.1381, bce: 63.7218, kld: 0.1217\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 93.191437\n",
      "bce: 63.315483, kld: 0.119504\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 93.083199\n",
      "bce: 63.492168, kld: 0.118364\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 92.316444\n",
      "bce: 63.168785, kld: 0.116591\n",
      "====> Epoch: 74 Average loss: 92.9806, bce: 63.4287, kld: 0.1182\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 92.351662\n",
      "bce: 63.288254, kld: 0.116254\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 91.742645\n",
      "bce: 63.046391, kld: 0.114785\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 91.192284\n",
      "bce: 62.923393, kld: 0.113076\n",
      "====> Epoch: 75 Average loss: 91.8630, bce: 63.1375, kld: 0.1149\n",
      "====> Testing Average Loss: 51.796614964718415\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 91.054398\n",
      "bce: 62.825855, kld: 0.112914\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 91.199417\n",
      "bce: 63.243416, kld: 0.111824\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 90.079597\n",
      "bce: 62.595348, kld: 0.109937\n",
      "====> Epoch: 76 Average loss: 90.7754, bce: 62.8454, kld: 0.1117\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 90.360184\n",
      "bce: 62.908783, kld: 0.109806\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 89.774620\n",
      "bce: 62.648869, kld: 0.108503\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 89.107910\n",
      "bce: 62.257439, kld: 0.107402\n",
      "====> Epoch: 77 Average loss: 89.7293, bce: 62.5629, kld: 0.1087\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 89.184906\n",
      "bce: 62.393520, kld: 0.107166\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 88.699249\n",
      "bce: 62.281822, kld: 0.105670\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 88.066452\n",
      "bce: 61.973217, kld: 0.104373\n",
      "====> Epoch: 78 Average loss: 88.7133, bce: 62.2781, kld: 0.1057\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 88.247589\n",
      "bce: 62.189510, kld: 0.104232\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 87.667450\n",
      "bce: 61.975647, kld: 0.102767\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 87.234291\n",
      "bce: 61.778133, kld: 0.101825\n",
      "====> Epoch: 79 Average loss: 87.7274, bce: 61.9955, kld: 0.1029\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 87.377533\n",
      "bce: 61.935196, kld: 0.101769\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 86.704910\n",
      "bce: 61.610863, kld: 0.100376\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 86.172791\n",
      "bce: 61.507202, kld: 0.098662\n",
      "====> Epoch: 80 Average loss: 86.7736, bce: 61.7198, kld: 0.1002\n",
      "====> Testing Average Loss: 50.66569552156837\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 86.486771\n",
      "bce: 61.748932, kld: 0.098951\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 85.980103\n",
      "bce: 61.596420, kld: 0.097535\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 85.375732\n",
      "bce: 61.261242, kld: 0.096458\n",
      "====> Epoch: 81 Average loss: 85.8563, bce: 61.4479, kld: 0.0976\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 85.303970\n",
      "bce: 61.238335, kld: 0.096263\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 85.045197\n",
      "bce: 61.238346, kld: 0.095227\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 84.489532\n",
      "bce: 60.967033, kld: 0.094090\n",
      "====> Epoch: 82 Average loss: 84.9553, bce: 61.1717, kld: 0.0951\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 84.631950\n",
      "bce: 61.116028, kld: 0.094064\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 84.225456\n",
      "bce: 61.005493, kld: 0.092880\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 83.699509\n",
      "bce: 60.741806, kld: 0.091831\n",
      "====> Epoch: 83 Average loss: 84.0827, bce: 60.9018, kld: 0.0927\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 83.901611\n",
      "bce: 61.018223, kld: 0.091534\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 83.179832\n",
      "bce: 60.609856, kld: 0.090280\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 82.732834\n",
      "bce: 60.423431, kld: 0.089238\n",
      "====> Epoch: 84 Average loss: 83.2399, bce: 60.6362, kld: 0.0904\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 82.548950\n",
      "bce: 60.247581, kld: 0.089205\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 82.829918\n",
      "bce: 60.702335, kld: 0.088510\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 81.928192\n",
      "bce: 60.121944, kld: 0.087225\n",
      "====> Epoch: 85 Average loss: 82.4048, bce: 60.3547, kld: 0.0882\n",
      "====> Testing Average Loss: 49.561363125748905\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 82.260117\n",
      "bce: 60.510143, kld: 0.087000\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 81.505783\n",
      "bce: 59.988728, kld: 0.086068\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 81.434792\n",
      "bce: 60.095325, kld: 0.085358\n",
      "====> Epoch: 86 Average loss: 81.6024, bce: 60.0778, kld: 0.0861\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 81.302917\n",
      "bce: 60.041126, kld: 0.085047\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 80.807938\n",
      "bce: 59.721821, kld: 0.084344\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 80.239288\n",
      "bce: 59.299728, kld: 0.083758\n",
      "====> Epoch: 87 Average loss: 80.7973, bce: 59.7607, kld: 0.0841\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 80.439713\n",
      "bce: 59.687553, kld: 0.083009\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 80.052765\n",
      "bce: 59.377632, kld: 0.082701\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 79.591438\n",
      "bce: 59.017384, kld: 0.082296\n",
      "====> Epoch: 88 Average loss: 79.9538, bce: 59.2915, kld: 0.0826\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 79.544128\n",
      "bce: 58.998844, kld: 0.082181\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 78.938980\n",
      "bce: 58.561790, kld: 0.081509\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 78.577835\n",
      "bce: 58.305782, kld: 0.081088\n",
      "====> Epoch: 89 Average loss: 79.0153, bce: 58.6061, kld: 0.0816\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 78.485382\n",
      "bce: 58.244545, kld: 0.080963\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 78.161125\n",
      "bce: 58.074139, kld: 0.080348\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 77.740341\n",
      "bce: 57.900074, kld: 0.079361\n",
      "====> Epoch: 90 Average loss: 78.1625, bce: 58.1333, kld: 0.0801\n",
      "====> Testing Average Loss: 47.46370531553721\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 77.871658\n",
      "bce: 58.084114, kld: 0.079150\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 77.378830\n",
      "bce: 57.727440, kld: 0.078606\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 76.895546\n",
      "bce: 57.566872, kld: 0.077315\n",
      "====> Epoch: 91 Average loss: 77.3673, bce: 57.7510, kld: 0.0785\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 76.934418\n",
      "bce: 57.637562, kld: 0.077187\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 76.711708\n",
      "bce: 57.571712, kld: 0.076560\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 76.498573\n",
      "bce: 57.426727, kld: 0.076287\n",
      "====> Epoch: 92 Average loss: 76.5797, bce: 57.3942, kld: 0.0767\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 76.360947\n",
      "bce: 57.364407, kld: 0.075986\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 75.520889\n",
      "bce: 56.813858, kld: 0.074828\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 75.649185\n",
      "bce: 57.074997, kld: 0.074297\n",
      "====> Epoch: 93 Average loss: 75.7982, bce: 57.0376, kld: 0.0750\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 75.415398\n",
      "bce: 56.970806, kld: 0.073778\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 75.360596\n",
      "bce: 57.043587, kld: 0.073268\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 74.714310\n",
      "bce: 56.552822, kld: 0.072646\n",
      "====> Epoch: 94 Average loss: 75.1093, bce: 56.7547, kld: 0.0734\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 74.924797\n",
      "bce: 56.829498, kld: 0.072381\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 74.171120\n",
      "bce: 56.314018, kld: 0.071428\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 74.086517\n",
      "bce: 56.252159, kld: 0.071337\n",
      "====> Epoch: 95 Average loss: 74.3937, bce: 56.4284, kld: 0.0719\n",
      "====> Testing Average Loss: 46.05257081280788\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 73.823410\n",
      "bce: 56.089157, kld: 0.070937\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 73.611847\n",
      "bce: 56.056091, kld: 0.070223\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 73.383087\n",
      "bce: 56.000015, kld: 0.069532\n",
      "====> Epoch: 96 Average loss: 73.7199, bce: 56.1355, kld: 0.0703\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 73.467361\n",
      "bce: 56.147102, kld: 0.069281\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 73.016068\n",
      "bce: 55.828773, kld: 0.068749\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 72.678299\n",
      "bce: 55.547913, kld: 0.068522\n",
      "====> Epoch: 97 Average loss: 73.0254, bce: 55.8202, kld: 0.0688\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 72.521751\n",
      "bce: 55.480049, kld: 0.068167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 72.144508\n",
      "bce: 55.299576, kld: 0.067380\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 72.117142\n",
      "bce: 55.459908, kld: 0.066629\n",
      "====> Epoch: 98 Average loss: 72.4021, bce: 55.5520, kld: 0.0674\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 71.936371\n",
      "bce: 55.415916, kld: 0.066082\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 71.456596\n",
      "bce: 55.060486, kld: 0.065584\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 71.483475\n",
      "bce: 55.115005, kld: 0.065474\n",
      "====> Epoch: 99 Average loss: 71.7648, bce: 55.2748, kld: 0.0660\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 71.423569\n",
      "bce: 55.174870, kld: 0.064995\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 71.093979\n",
      "bce: 55.069401, kld: 0.064098\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 70.956467\n",
      "bce: 54.975304, kld: 0.063925\n",
      "====> Epoch: 100 Average loss: 71.1523, bce: 55.0072, kld: 0.0646\n",
      "====> Testing Average Loss: 44.77536280122487\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 71.079170\n",
      "bce: 55.080597, kld: 0.063994\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 70.534332\n",
      "bce: 54.799122, kld: 0.062941\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 70.399025\n",
      "bce: 54.777016, kld: 0.062488\n",
      "====> Epoch: 101 Average loss: 70.5552, bce: 54.7394, kld: 0.0633\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 70.219460\n",
      "bce: 54.601200, kld: 0.062473\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 70.190552\n",
      "bce: 54.658070, kld: 0.062130\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 69.994675\n",
      "bce: 54.641617, kld: 0.061412\n",
      "====> Epoch: 102 Average loss: 69.9861, bce: 54.4952, kld: 0.0620\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 69.972977\n",
      "bce: 54.578453, kld: 0.061578\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 69.537888\n",
      "bce: 54.294731, kld: 0.060973\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 69.372955\n",
      "bce: 54.263676, kld: 0.060437\n",
      "====> Epoch: 103 Average loss: 69.3958, bce: 54.2254, kld: 0.0607\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 69.513969\n",
      "bce: 54.362415, kld: 0.060606\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 68.923355\n",
      "bce: 54.055450, kld: 0.059472\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 68.599777\n",
      "bce: 53.930264, kld: 0.058678\n",
      "====> Epoch: 104 Average loss: 68.8635, bce: 53.9952, kld: 0.0595\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 68.891327\n",
      "bce: 54.229881, kld: 0.058646\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 68.568398\n",
      "bce: 54.074379, kld: 0.057976\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 68.095001\n",
      "bce: 53.654202, kld: 0.057763\n",
      "====> Epoch: 105 Average loss: 68.3079, bce: 53.7400, kld: 0.0583\n",
      "====> Testing Average Loss: 43.659694947410465\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 68.147690\n",
      "bce: 53.666985, kld: 0.057923\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 67.540787\n",
      "bce: 53.147629, kld: 0.057573\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 67.544487\n",
      "bce: 53.222343, kld: 0.057289\n",
      "====> Epoch: 106 Average loss: 67.7683, bce: 53.4922, kld: 0.0571\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 67.461746\n",
      "bce: 53.155262, kld: 0.057226\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 67.630287\n",
      "bce: 53.596352, kld: 0.056136\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 67.201752\n",
      "bce: 53.299629, kld: 0.055609\n",
      "====> Epoch: 107 Average loss: 67.2779, bce: 53.2766, kld: 0.0560\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 67.070236\n",
      "bce: 53.215168, kld: 0.055420\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 66.902321\n",
      "bce: 53.226784, kld: 0.054702\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 66.540749\n",
      "bce: 52.891769, kld: 0.054596\n",
      "====> Epoch: 108 Average loss: 66.7693, bce: 53.0560, kld: 0.0549\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 66.340050\n",
      "bce: 52.711380, kld: 0.054515\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 66.067093\n",
      "bce: 52.618641, kld: 0.053794\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 65.790192\n",
      "bce: 52.557037, kld: 0.052933\n",
      "====> Epoch: 109 Average loss: 66.2507, bce: 52.8116, kld: 0.0538\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 65.563408\n",
      "bce: 52.267250, kld: 0.053185\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 65.903946\n",
      "bce: 52.797577, kld: 0.052425\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 65.942215\n",
      "bce: 52.863510, kld: 0.052315\n",
      "====> Epoch: 110 Average loss: 65.7774, bce: 52.5906, kld: 0.0527\n",
      "====> Testing Average Loss: 42.70237297796565\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 65.881256\n",
      "bce: 52.764515, kld: 0.052467\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 65.330482\n",
      "bce: 52.397243, kld: 0.051733\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 65.233139\n",
      "bce: 52.484879, kld: 0.050993\n",
      "====> Epoch: 111 Average loss: 65.3025, bce: 52.3652, kld: 0.0517\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 65.391373\n",
      "bce: 52.672417, kld: 0.050876\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 65.182526\n",
      "bce: 52.584156, kld: 0.050393\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 64.487068\n",
      "bce: 52.009869, kld: 0.049909\n",
      "====> Epoch: 112 Average loss: 64.8376, bce: 52.1609, kld: 0.0507\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 64.658096\n",
      "bce: 52.117363, kld: 0.050163\n",
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 64.528671\n",
      "bce: 51.984779, kld: 0.050176\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 64.559105\n",
      "bce: 52.110958, kld: 0.049793\n",
      "====> Epoch: 113 Average loss: 64.4033, bce: 51.9447, kld: 0.0498\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 64.177948\n",
      "bce: 51.679237, kld: 0.049995\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 63.793476\n",
      "bce: 51.470749, kld: 0.049291\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 63.697697\n",
      "bce: 51.583382, kld: 0.048457\n",
      "====> Epoch: 114 Average loss: 63.9553, bce: 51.7075, kld: 0.0490\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 63.782429\n",
      "bce: 51.937073, kld: 0.047381\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 63.399338\n",
      "bce: 51.511665, kld: 0.047551\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 63.345810\n",
      "bce: 51.446850, kld: 0.047596\n",
      "====> Epoch: 115 Average loss: 63.5035, bce: 51.5274, kld: 0.0479\n",
      "====> Testing Average Loss: 41.793430052589535\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 63.118755\n",
      "bce: 51.134808, kld: 0.047936\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 63.235649\n",
      "bce: 51.472649, kld: 0.047052\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 63.070950\n",
      "bce: 51.431839, kld: 0.046556\n",
      "====> Epoch: 116 Average loss: 63.0806, bce: 51.3115, kld: 0.0471\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 62.975288\n",
      "bce: 51.334671, kld: 0.046562\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 62.740459\n",
      "bce: 51.335281, kld: 0.045621\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 62.323784\n",
      "bce: 51.015701, kld: 0.045232\n",
      "====> Epoch: 117 Average loss: 62.6394, bce: 51.0971, kld: 0.0462\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 62.335194\n",
      "bce: 50.853333, kld: 0.045927\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 61.622540\n",
      "bce: 50.168091, kld: 0.045818\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 62.102081\n",
      "bce: 50.673370, kld: 0.045715\n",
      "====> Epoch: 118 Average loss: 62.2165, bce: 50.8518, kld: 0.0455\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 61.956753\n",
      "bce: 50.703773, kld: 0.045012\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 62.088669\n",
      "bce: 51.031364, kld: 0.044229\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 61.349754\n",
      "bce: 50.412094, kld: 0.043751\n",
      "====> Epoch: 119 Average loss: 61.8216, bce: 50.6938, kld: 0.0445\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 61.213673\n",
      "bce: 50.225655, kld: 0.043952\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 61.099655\n",
      "bce: 50.074997, kld: 0.044099\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 61.369736\n",
      "bce: 50.448303, kld: 0.043686\n",
      "====> Epoch: 120 Average loss: 61.3851, bce: 50.4459, kld: 0.0438\n",
      "====> Testing Average Loss: 41.003763230595126\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 61.384132\n",
      "bce: 50.573898, kld: 0.043241\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 60.942497\n",
      "bce: 50.237511, kld: 0.042820\n",
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 60.831932\n",
      "bce: 50.188046, kld: 0.042576\n",
      "====> Epoch: 121 Average loss: 60.9381, bce: 50.2278, kld: 0.0428\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 61.044647\n",
      "bce: 50.386742, kld: 0.042632\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 60.739017\n",
      "bce: 50.170525, kld: 0.042274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 59.852440\n",
      "bce: 49.437332, kld: 0.041660\n",
      "====> Epoch: 122 Average loss: 60.5832, bce: 50.0534, kld: 0.0421\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 60.111500\n",
      "bce: 49.681038, kld: 0.041722\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 60.765762\n",
      "bce: 50.437252, kld: 0.041314\n",
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 60.110348\n",
      "bce: 49.780563, kld: 0.041319\n",
      "====> Epoch: 123 Average loss: 60.2293, bce: 49.8689, kld: 0.0414\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 60.085701\n",
      "bce: 49.779659, kld: 0.041224\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 60.043819\n",
      "bce: 49.847893, kld: 0.040784\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 60.021694\n",
      "bce: 49.931133, kld: 0.040362\n",
      "====> Epoch: 124 Average loss: 59.8132, bce: 49.6450, kld: 0.0407\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 59.508774\n",
      "bce: 49.406799, kld: 0.040408\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 59.540527\n",
      "bce: 49.460682, kld: 0.040319\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 59.606670\n",
      "bce: 49.620667, kld: 0.039944\n",
      "====> Epoch: 125 Average loss: 59.4254, bce: 49.4264, kld: 0.0400\n",
      "====> Testing Average Loss: 40.318998801757424\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 59.104004\n",
      "bce: 49.242931, kld: 0.039444\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 59.293259\n",
      "bce: 49.464424, kld: 0.039315\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 58.973022\n",
      "bce: 49.200867, kld: 0.039089\n",
      "====> Epoch: 126 Average loss: 59.0798, bce: 49.2588, kld: 0.0393\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 58.856613\n",
      "bce: 49.084152, kld: 0.039090\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 59.104988\n",
      "bce: 49.378872, kld: 0.038904\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 58.390766\n",
      "bce: 48.789516, kld: 0.038405\n",
      "====> Epoch: 127 Average loss: 58.7098, bce: 49.0553, kld: 0.0386\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 58.683460\n",
      "bce: 49.067764, kld: 0.038463\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 58.056229\n",
      "bce: 48.639400, kld: 0.037667\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 58.642342\n",
      "bce: 49.138756, kld: 0.038014\n",
      "====> Epoch: 128 Average loss: 58.3599, bce: 48.8623, kld: 0.0380\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 57.879292\n",
      "bce: 48.402199, kld: 0.037908\n",
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 57.744694\n",
      "bce: 48.446152, kld: 0.037194\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 57.869343\n",
      "bce: 48.678925, kld: 0.036762\n",
      "====> Epoch: 129 Average loss: 57.9890, bce: 48.6593, kld: 0.0373\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 57.740318\n",
      "bce: 48.432648, kld: 0.037231\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 57.043808\n",
      "bce: 47.851288, kld: 0.036770\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 57.905720\n",
      "bce: 48.778381, kld: 0.036509\n",
      "====> Epoch: 130 Average loss: 57.6387, bce: 48.4501, kld: 0.0368\n",
      "====> Testing Average Loss: 39.36603918419651\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 57.726089\n",
      "bce: 48.597359, kld: 0.036515\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 57.310665\n",
      "bce: 48.285458, kld: 0.036101\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 56.926243\n",
      "bce: 48.056412, kld: 0.035479\n",
      "====> Epoch: 131 Average loss: 57.2633, bce: 48.2344, kld: 0.0361\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 56.711578\n",
      "bce: 47.856712, kld: 0.035419\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 56.799702\n",
      "bce: 47.850254, kld: 0.035798\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 56.735188\n",
      "bce: 47.941654, kld: 0.035174\n",
      "====> Epoch: 132 Average loss: 56.9335, bce: 48.0462, kld: 0.0355\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 56.850861\n",
      "bce: 48.162086, kld: 0.034755\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 56.912121\n",
      "bce: 48.135529, kld: 0.035106\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 56.825928\n",
      "bce: 48.118855, kld: 0.034828\n",
      "====> Epoch: 133 Average loss: 56.5901, bce: 47.8573, kld: 0.0349\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 56.050735\n",
      "bce: 47.443832, kld: 0.034428\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 56.324669\n",
      "bce: 47.774857, kld: 0.034199\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 56.454185\n",
      "bce: 47.874016, kld: 0.034321\n",
      "====> Epoch: 134 Average loss: 56.2468, bce: 47.6577, kld: 0.0344\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 56.127987\n",
      "bce: 47.557240, kld: 0.034283\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 55.698826\n",
      "bce: 47.251423, kld: 0.033790\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 55.903999\n",
      "bce: 47.510227, kld: 0.033575\n",
      "====> Epoch: 135 Average loss: 55.9285, bce: 47.4700, kld: 0.0338\n",
      "====> Testing Average Loss: 38.55119574623885\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 55.597851\n",
      "bce: 47.188435, kld: 0.033638\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 55.893360\n",
      "bce: 47.694687, kld: 0.032795\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 55.196632\n",
      "bce: 46.856308, kld: 0.033361\n",
      "====> Epoch: 136 Average loss: 55.6275, bce: 47.3050, kld: 0.0333\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 55.353542\n",
      "bce: 47.028172, kld: 0.033301\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 55.095894\n",
      "bce: 46.880550, kld: 0.032861\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 55.246147\n",
      "bce: 47.252892, kld: 0.031973\n",
      "====> Epoch: 137 Average loss: 55.3208, bce: 47.1307, kld: 0.0328\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 55.046082\n",
      "bce: 46.715256, kld: 0.033323\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 55.258213\n",
      "bce: 47.071297, kld: 0.032748\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 55.009647\n",
      "bce: 47.054420, kld: 0.031821\n",
      "====> Epoch: 138 Average loss: 55.1291, bce: 47.0359, kld: 0.0324\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 55.424564\n",
      "bce: 47.479523, kld: 0.031780\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 54.363274\n",
      "bce: 46.325165, kld: 0.032152\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 54.431740\n",
      "bce: 46.479939, kld: 0.031807\n",
      "====> Epoch: 139 Average loss: 54.7667, bce: 46.7958, kld: 0.0319\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 54.882751\n",
      "bce: 47.144073, kld: 0.030955\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 54.045647\n",
      "bce: 46.118729, kld: 0.031708\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 54.506245\n",
      "bce: 46.549606, kld: 0.031827\n",
      "====> Epoch: 140 Average loss: 54.5474, bce: 46.6888, kld: 0.0314\n",
      "====> Testing Average Loss: 37.838920624750365\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 54.498554\n",
      "bce: 46.750359, kld: 0.030993\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 54.136276\n",
      "bce: 46.551888, kld: 0.030338\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 54.220680\n",
      "bce: 46.606232, kld: 0.030458\n",
      "====> Epoch: 141 Average loss: 54.1810, bce: 46.4690, kld: 0.0308\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 54.253944\n",
      "bce: 46.476509, kld: 0.031110\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 53.776329\n",
      "bce: 45.956993, kld: 0.031277\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 53.624989\n",
      "bce: 46.017063, kld: 0.030432\n",
      "====> Epoch: 142 Average loss: 53.8859, bce: 46.2485, kld: 0.0305\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 53.913906\n",
      "bce: 46.436531, kld: 0.029910\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 53.419579\n",
      "bce: 46.007591, kld: 0.029648\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 53.550461\n",
      "bce: 46.132660, kld: 0.029671\n",
      "====> Epoch: 143 Average loss: 53.5564, bce: 46.0824, kld: 0.0299\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 52.938354\n",
      "bce: 45.469654, kld: 0.029875\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 53.453068\n",
      "bce: 46.155125, kld: 0.029192\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 53.540268\n",
      "bce: 46.285011, kld: 0.029021\n",
      "====> Epoch: 144 Average loss: 53.2937, bce: 45.9147, kld: 0.0295\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 52.857021\n",
      "bce: 45.545097, kld: 0.029248\n",
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 52.813210\n",
      "bce: 45.468250, kld: 0.029380\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 53.125607\n",
      "bce: 45.871742, kld: 0.029015\n",
      "====> Epoch: 145 Average loss: 52.9695, bce: 45.6984, kld: 0.0291\n",
      "====> Testing Average Loss: 37.13566872753295\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 53.457500\n",
      "bce: 46.263054, kld: 0.028778\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 52.780704\n",
      "bce: 45.593185, kld: 0.028750\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 52.599358\n",
      "bce: 45.436417, kld: 0.028652\n",
      "====> Epoch: 146 Average loss: 52.7134, bce: 45.5491, kld: 0.0287\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 52.958199\n",
      "bce: 45.784733, kld: 0.028694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 52.395744\n",
      "bce: 45.394833, kld: 0.028004\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 51.751701\n",
      "bce: 44.736557, kld: 0.028061\n",
      "====> Epoch: 147 Average loss: 52.4298, bce: 45.3517, kld: 0.0283\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 52.168526\n",
      "bce: 45.076187, kld: 0.028369\n",
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 51.688717\n",
      "bce: 44.648899, kld: 0.028159\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 52.161007\n",
      "bce: 45.147114, kld: 0.028056\n",
      "====> Epoch: 148 Average loss: 52.1391, bce: 45.1392, kld: 0.0280\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 52.050652\n",
      "bce: 45.174591, kld: 0.027504\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 52.157700\n",
      "bce: 45.154396, kld: 0.028013\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 51.696674\n",
      "bce: 44.686577, kld: 0.028040\n",
      "====> Epoch: 149 Average loss: 51.8539, bce: 44.9258, kld: 0.0277\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 51.579628\n",
      "bce: 44.762711, kld: 0.027268\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 51.579300\n",
      "bce: 44.863472, kld: 0.026863\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 50.806229\n",
      "bce: 43.987404, kld: 0.027275\n",
      "====> Epoch: 150 Average loss: 51.5842, bce: 44.7539, kld: 0.0273\n",
      "====> Testing Average Loss: 36.13904502562908\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 51.120461\n",
      "bce: 44.216194, kld: 0.027617\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 51.344276\n",
      "bce: 44.623352, kld: 0.026884\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 51.222164\n",
      "bce: 44.558182, kld: 0.026656\n",
      "====> Epoch: 151 Average loss: 51.3379, bce: 44.5806, kld: 0.0270\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 51.309128\n",
      "bce: 44.616112, kld: 0.026772\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 51.134495\n",
      "bce: 44.463837, kld: 0.026683\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 50.894958\n",
      "bce: 44.302238, kld: 0.026371\n",
      "====> Epoch: 152 Average loss: 51.0340, bce: 44.3838, kld: 0.0266\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 50.629715\n",
      "bce: 43.943413, kld: 0.026745\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 51.008152\n",
      "bce: 44.399536, kld: 0.026434\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 50.978130\n",
      "bce: 44.463737, kld: 0.026058\n",
      "====> Epoch: 153 Average loss: 50.7953, bce: 44.2167, kld: 0.0263\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 50.887886\n",
      "bce: 44.348057, kld: 0.026159\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 50.183331\n",
      "bce: 43.617470, kld: 0.026263\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 50.356575\n",
      "bce: 44.015533, kld: 0.025364\n",
      "====> Epoch: 154 Average loss: 50.5443, bce: 44.0670, kld: 0.0259\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 49.588760\n",
      "bce: 43.117397, kld: 0.025885\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 50.488777\n",
      "bce: 43.963741, kld: 0.026100\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 49.577244\n",
      "bce: 43.242966, kld: 0.025337\n",
      "====> Epoch: 155 Average loss: 50.3265, bce: 43.8965, kld: 0.0257\n",
      "====> Testing Average Loss: 35.74167159000133\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 50.675076\n",
      "bce: 44.390205, kld: 0.025139\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 50.375359\n",
      "bce: 44.035751, kld: 0.025358\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 49.688049\n",
      "bce: 43.327415, kld: 0.025443\n",
      "====> Epoch: 156 Average loss: 50.0633, bce: 43.7356, kld: 0.0253\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 49.521358\n",
      "bce: 43.188934, kld: 0.025330\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 49.453896\n",
      "bce: 43.285748, kld: 0.024673\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 50.207397\n",
      "bce: 44.017471, kld: 0.024760\n",
      "====> Epoch: 157 Average loss: 49.7951, bce: 43.5610, kld: 0.0249\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 49.563110\n",
      "bce: 43.342926, kld: 0.024881\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 49.651470\n",
      "bce: 43.489044, kld: 0.024650\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 49.484676\n",
      "bce: 43.347218, kld: 0.024550\n",
      "====> Epoch: 158 Average loss: 49.5662, bce: 43.4228, kld: 0.0246\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 49.225311\n",
      "bce: 43.027508, kld: 0.024791\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 49.264431\n",
      "bce: 43.260715, kld: 0.024015\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 49.136795\n",
      "bce: 43.035759, kld: 0.024404\n",
      "====> Epoch: 159 Average loss: 49.2834, bce: 43.2136, kld: 0.0243\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 48.576111\n",
      "bce: 42.441326, kld: 0.024539\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 49.230038\n",
      "bce: 43.311424, kld: 0.023674\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 49.150917\n",
      "bce: 43.289913, kld: 0.023444\n",
      "====> Epoch: 160 Average loss: 49.1461, bce: 43.1365, kld: 0.0240\n",
      "====> Testing Average Loss: 34.80039379743044\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 49.138138\n",
      "bce: 43.102005, kld: 0.024145\n",
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 48.587666\n",
      "bce: 42.568211, kld: 0.024078\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 49.007210\n",
      "bce: 43.032284, kld: 0.023900\n",
      "====> Epoch: 161 Average loss: 48.9272, bce: 42.9904, kld: 0.0237\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 48.525890\n",
      "bce: 42.636456, kld: 0.023558\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 48.822376\n",
      "bce: 42.980400, kld: 0.023368\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 48.717789\n",
      "bce: 42.956726, kld: 0.023044\n",
      "====> Epoch: 162 Average loss: 48.6218, bce: 42.8111, kld: 0.0232\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 47.897011\n",
      "bce: 42.147003, kld: 0.023000\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 48.668018\n",
      "bce: 42.947865, kld: 0.022881\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 48.994225\n",
      "bce: 43.336525, kld: 0.022631\n",
      "====> Epoch: 163 Average loss: 48.3686, bce: 42.6184, kld: 0.0230\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 48.333336\n",
      "bce: 42.564835, kld: 0.023074\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 48.301479\n",
      "bce: 42.526115, kld: 0.023101\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 48.118233\n",
      "bce: 42.480450, kld: 0.022551\n",
      "====> Epoch: 164 Average loss: 48.1736, bce: 42.4828, kld: 0.0228\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 47.933193\n",
      "bce: 42.393250, kld: 0.022160\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 47.750507\n",
      "bce: 42.035351, kld: 0.022861\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 47.930798\n",
      "bce: 42.296371, kld: 0.022538\n",
      "====> Epoch: 165 Average loss: 47.9742, bce: 42.3519, kld: 0.0225\n",
      "====> Testing Average Loss: 34.21265165257622\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 48.106934\n",
      "bce: 42.540318, kld: 0.022266\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 48.003605\n",
      "bce: 42.533325, kld: 0.021881\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 47.563957\n",
      "bce: 42.040215, kld: 0.022095\n",
      "====> Epoch: 166 Average loss: 47.7290, bce: 42.1906, kld: 0.0222\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 46.902016\n",
      "bce: 41.398827, kld: 0.022013\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 47.276379\n",
      "bce: 41.831635, kld: 0.021779\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 47.594700\n",
      "bce: 42.114578, kld: 0.021920\n",
      "====> Epoch: 167 Average loss: 47.5019, bce: 42.0269, kld: 0.0219\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 47.241573\n",
      "bce: 41.753330, kld: 0.021953\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 47.052227\n",
      "bce: 41.701885, kld: 0.021401\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 47.526440\n",
      "bce: 42.125038, kld: 0.021606\n",
      "====> Epoch: 168 Average loss: 47.3268, bce: 41.9176, kld: 0.0216\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 47.258366\n",
      "bce: 41.862961, kld: 0.021582\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 47.321384\n",
      "bce: 42.012039, kld: 0.021237\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 47.506523\n",
      "bce: 42.142113, kld: 0.021458\n",
      "====> Epoch: 169 Average loss: 47.0780, bce: 41.7427, kld: 0.0213\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 46.505299\n",
      "bce: 41.145180, kld: 0.021440\n",
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 47.254108\n",
      "bce: 42.023720, kld: 0.020922\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 46.947983\n",
      "bce: 41.724514, kld: 0.020894\n",
      "====> Epoch: 170 Average loss: 46.8609, bce: 41.5920, kld: 0.0211\n",
      "====> Testing Average Loss: 33.43968533650646\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 46.293720\n",
      "bce: 41.044407, kld: 0.020997\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 46.927238\n",
      "bce: 41.669121, kld: 0.021032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 46.477913\n",
      "bce: 41.227753, kld: 0.021001\n",
      "====> Epoch: 171 Average loss: 46.6454, bce: 41.4293, kld: 0.0209\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 46.531708\n",
      "bce: 41.342476, kld: 0.020757\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 46.270588\n",
      "bce: 41.147026, kld: 0.020494\n",
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 46.438778\n",
      "bce: 41.341248, kld: 0.020390\n",
      "====> Epoch: 172 Average loss: 46.4311, bce: 41.2841, kld: 0.0206\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 46.408043\n",
      "bce: 41.296265, kld: 0.020447\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 46.139862\n",
      "bce: 41.069523, kld: 0.020281\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 45.755363\n",
      "bce: 40.732536, kld: 0.020091\n",
      "====> Epoch: 173 Average loss: 46.2291, bce: 41.1465, kld: 0.0203\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 46.301739\n",
      "bce: 41.258972, kld: 0.020171\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 46.038971\n",
      "bce: 40.951633, kld: 0.020349\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 45.742195\n",
      "bce: 40.677902, kld: 0.020257\n",
      "====> Epoch: 174 Average loss: 46.0437, bce: 41.0134, kld: 0.0201\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 45.949310\n",
      "bce: 41.031319, kld: 0.019672\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 45.842171\n",
      "bce: 40.879974, kld: 0.019849\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 45.858555\n",
      "bce: 40.859680, kld: 0.019996\n",
      "====> Epoch: 175 Average loss: 45.8689, bce: 40.9022, kld: 0.0199\n",
      "====> Testing Average Loss: 32.82362951005192\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 45.548317\n",
      "bce: 40.511780, kld: 0.020146\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 45.988155\n",
      "bce: 41.101284, kld: 0.019547\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 45.691265\n",
      "bce: 40.817833, kld: 0.019494\n",
      "====> Epoch: 176 Average loss: 45.7104, bce: 40.7768, kld: 0.0197\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 45.814381\n",
      "bce: 41.015762, kld: 0.019194\n",
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 45.700928\n",
      "bce: 40.754562, kld: 0.019785\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 45.101208\n",
      "bce: 40.235783, kld: 0.019462\n",
      "====> Epoch: 177 Average loss: 45.5181, bce: 40.6390, kld: 0.0195\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 45.535587\n",
      "bce: 40.697186, kld: 0.019354\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 46.087017\n",
      "bce: 41.258072, kld: 0.019316\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 45.170094\n",
      "bce: 40.409599, kld: 0.019042\n",
      "====> Epoch: 178 Average loss: 45.3500, bce: 40.5308, kld: 0.0193\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 45.428497\n",
      "bce: 40.676559, kld: 0.019008\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 45.096855\n",
      "bce: 40.356407, kld: 0.018962\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 44.796432\n",
      "bce: 40.093330, kld: 0.018812\n",
      "====> Epoch: 179 Average loss: 45.0920, bce: 40.3497, kld: 0.0190\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 44.779366\n",
      "bce: 40.036461, kld: 0.018972\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 44.937035\n",
      "bce: 40.326332, kld: 0.018443\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 44.510387\n",
      "bce: 39.903435, kld: 0.018428\n",
      "====> Epoch: 180 Average loss: 44.9010, bce: 40.2131, kld: 0.0188\n",
      "====> Testing Average Loss: 32.26940071228864\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 45.135323\n",
      "bce: 40.502617, kld: 0.018531\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 44.725548\n",
      "bce: 40.090225, kld: 0.018541\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 44.024792\n",
      "bce: 39.455956, kld: 0.018275\n",
      "====> Epoch: 181 Average loss: 44.7707, bce: 40.1377, kld: 0.0185\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 44.267162\n",
      "bce: 39.687336, kld: 0.018319\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 44.968540\n",
      "bce: 40.335587, kld: 0.018532\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 44.554150\n",
      "bce: 39.957893, kld: 0.018385\n",
      "====> Epoch: 182 Average loss: 44.6037, bce: 40.0162, kld: 0.0184\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 44.820671\n",
      "bce: 40.268822, kld: 0.018207\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 44.521824\n",
      "bce: 39.971111, kld: 0.018203\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 44.019634\n",
      "bce: 39.467937, kld: 0.018207\n",
      "====> Epoch: 183 Average loss: 44.4400, bce: 39.8998, kld: 0.0182\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 43.907642\n",
      "bce: 39.376701, kld: 0.018124\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 44.059875\n",
      "bce: 39.567623, kld: 0.017969\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 44.273079\n",
      "bce: 39.853733, kld: 0.017677\n",
      "====> Epoch: 184 Average loss: 44.2022, bce: 39.7357, kld: 0.0179\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 44.087959\n",
      "bce: 39.623508, kld: 0.017858\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 44.052898\n",
      "bce: 39.621441, kld: 0.017726\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 43.817574\n",
      "bce: 39.371830, kld: 0.017783\n",
      "====> Epoch: 185 Average loss: 44.0388, bce: 39.6156, kld: 0.0177\n",
      "====> Testing Average Loss: 31.863453393356412\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 44.410557\n",
      "bce: 40.028946, kld: 0.017526\n",
      "Train Epoch: 186 [10240/22533 (45%)]      Loss: 43.813255\n",
      "bce: 39.466957, kld: 0.017385\n",
      "Train Epoch: 186 [20480/22533 (91%)]      Loss: 43.580791\n",
      "bce: 39.269516, kld: 0.017245\n",
      "====> Epoch: 186 Average loss: 43.8686, bce: 39.5211, kld: 0.0174\n",
      "Train Epoch: 187 [   0/22533 ( 0%)]      Loss: 43.861610\n",
      "bce: 39.463600, kld: 0.017592\n",
      "Train Epoch: 187 [10240/22533 (45%)]      Loss: 43.694775\n",
      "bce: 39.433853, kld: 0.017044\n",
      "Train Epoch: 187 [20480/22533 (91%)]      Loss: 43.872726\n",
      "bce: 39.509193, kld: 0.017454\n",
      "====> Epoch: 187 Average loss: 43.8303, bce: 39.4945, kld: 0.0173\n",
      "Train Epoch: 188 [   0/22533 ( 0%)]      Loss: 44.065075\n",
      "bce: 39.639484, kld: 0.017702\n",
      "Train Epoch: 188 [10240/22533 (45%)]      Loss: 43.323875\n",
      "bce: 39.064438, kld: 0.017038\n",
      "Train Epoch: 188 [20480/22533 (91%)]      Loss: 43.360088\n",
      "bce: 39.204212, kld: 0.016623\n",
      "====> Epoch: 188 Average loss: 43.6909, bce: 39.3984, kld: 0.0172\n",
      "Train Epoch: 189 [   0/22533 ( 0%)]      Loss: 43.697620\n",
      "bce: 39.450783, kld: 0.016987\n",
      "Train Epoch: 189 [10240/22533 (45%)]      Loss: 42.999424\n",
      "bce: 38.792233, kld: 0.016829\n",
      "Train Epoch: 189 [20480/22533 (91%)]      Loss: 43.062927\n",
      "bce: 38.891308, kld: 0.016686\n",
      "====> Epoch: 189 Average loss: 43.3726, bce: 39.1502, kld: 0.0169\n",
      "Train Epoch: 190 [   0/22533 ( 0%)]      Loss: 43.213451\n",
      "bce: 39.020657, kld: 0.016771\n",
      "Train Epoch: 190 [10240/22533 (45%)]      Loss: 42.717724\n",
      "bce: 38.589985, kld: 0.016511\n",
      "Train Epoch: 190 [20480/22533 (91%)]      Loss: 43.050507\n",
      "bce: 38.929340, kld: 0.016485\n",
      "====> Epoch: 190 Average loss: 43.1600, bce: 39.0105, kld: 0.0166\n",
      "====> Testing Average Loss: 31.223773881640263\n",
      "Train Epoch: 191 [   0/22533 ( 0%)]      Loss: 42.969982\n",
      "bce: 38.827415, kld: 0.016570\n",
      "Train Epoch: 191 [10240/22533 (45%)]      Loss: 43.345329\n",
      "bce: 39.219906, kld: 0.016502\n",
      "Train Epoch: 191 [20480/22533 (91%)]      Loss: 42.958725\n",
      "bce: 38.901516, kld: 0.016229\n",
      "====> Epoch: 191 Average loss: 43.0856, bce: 38.9788, kld: 0.0164\n",
      "Train Epoch: 192 [   0/22533 ( 0%)]      Loss: 42.844574\n",
      "bce: 38.682152, kld: 0.016650\n",
      "Train Epoch: 192 [10240/22533 (45%)]      Loss: 43.074890\n",
      "bce: 39.050251, kld: 0.016099\n",
      "Train Epoch: 192 [20480/22533 (91%)]      Loss: 43.816486\n",
      "bce: 39.658028, kld: 0.016634\n",
      "====> Epoch: 192 Average loss: 43.0555, bce: 38.9691, kld: 0.0163\n",
      "Train Epoch: 193 [   0/22533 ( 0%)]      Loss: 42.590317\n",
      "bce: 38.531521, kld: 0.016235\n",
      "Train Epoch: 193 [10240/22533 (45%)]      Loss: 42.915115\n",
      "bce: 38.941662, kld: 0.015894\n",
      "Train Epoch: 193 [20480/22533 (91%)]      Loss: 42.609367\n",
      "bce: 38.561146, kld: 0.016193\n",
      "====> Epoch: 193 Average loss: 42.7963, bce: 38.7611, kld: 0.0161\n",
      "Train Epoch: 194 [   0/22533 ( 0%)]      Loss: 42.873199\n",
      "bce: 38.802567, kld: 0.016283\n",
      "Train Epoch: 194 [10240/22533 (45%)]      Loss: 42.679943\n",
      "bce: 38.682285, kld: 0.015991\n",
      "Train Epoch: 194 [20480/22533 (91%)]      Loss: 42.596481\n",
      "bce: 38.649818, kld: 0.015787\n",
      "====> Epoch: 194 Average loss: 42.6287, bce: 38.6586, kld: 0.0159\n",
      "Train Epoch: 195 [   0/22533 ( 0%)]      Loss: 42.499226\n",
      "bce: 38.535072, kld: 0.015857\n",
      "Train Epoch: 195 [10240/22533 (45%)]      Loss: 42.580750\n",
      "bce: 38.676476, kld: 0.015617\n",
      "Train Epoch: 195 [20480/22533 (91%)]      Loss: 42.355320\n",
      "bce: 38.443443, kld: 0.015648\n",
      "====> Epoch: 195 Average loss: 42.4711, bce: 38.5449, kld: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Testing Average Loss: 30.877619075356144\n",
      "Train Epoch: 196 [   0/22533 ( 0%)]      Loss: 42.103371\n",
      "bce: 38.218681, kld: 0.015539\n",
      "Train Epoch: 196 [10240/22533 (45%)]      Loss: 42.053940\n",
      "bce: 38.203960, kld: 0.015400\n",
      "Train Epoch: 196 [20480/22533 (91%)]      Loss: 42.576931\n",
      "bce: 38.715137, kld: 0.015447\n",
      "====> Epoch: 196 Average loss: 42.3167, bce: 38.4415, kld: 0.0155\n",
      "Train Epoch: 197 [   0/22533 ( 0%)]      Loss: 42.616917\n",
      "bce: 38.829742, kld: 0.015149\n",
      "Train Epoch: 197 [10240/22533 (45%)]      Loss: 41.905540\n",
      "bce: 38.054951, kld: 0.015402\n",
      "Train Epoch: 197 [20480/22533 (91%)]      Loss: 41.994270\n",
      "bce: 38.179642, kld: 0.015259\n",
      "====> Epoch: 197 Average loss: 42.2175, bce: 38.3819, kld: 0.0153\n",
      "Train Epoch: 198 [   0/22533 ( 0%)]      Loss: 41.937481\n",
      "bce: 38.143795, kld: 0.015175\n",
      "Train Epoch: 198 [10240/22533 (45%)]      Loss: 42.294773\n",
      "bce: 38.528763, kld: 0.015064\n",
      "Train Epoch: 198 [20480/22533 (91%)]      Loss: 41.912865\n",
      "bce: 38.141479, kld: 0.015086\n",
      "====> Epoch: 198 Average loss: 42.1110, bce: 38.3226, kld: 0.0152\n",
      "Train Epoch: 199 [   0/22533 ( 0%)]      Loss: 42.126968\n",
      "bce: 38.342754, kld: 0.015137\n",
      "Train Epoch: 199 [10240/22533 (45%)]      Loss: 41.666973\n",
      "bce: 37.934391, kld: 0.014930\n",
      "Train Epoch: 199 [20480/22533 (91%)]      Loss: 42.283699\n",
      "bce: 38.541901, kld: 0.014967\n",
      "====> Epoch: 199 Average loss: 41.9245, bce: 38.1753, kld: 0.0150\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=250,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn_onemany.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
