{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 11257.114258\n",
      "bce: 104.845108, kld: 44.609077\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 7963.406738\n",
      "bce: 103.430153, kld: 31.439907\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 7084.927246\n",
      "bce: 102.355148, kld: 27.930288\n",
      "====> Epoch: 0 Average loss: 8576.4697, bce: 103.3553, kld: 33.8925\n",
      "====> Testing Average Loss: 83.58046115696978\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 7005.168945\n",
      "bce: 102.284912, kld: 27.611536\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 6640.970703\n",
      "bce: 101.209114, kld: 26.159046\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 6416.898926\n",
      "bce: 100.267792, kld: 25.266525\n",
      "====> Epoch: 1 Average loss: 6658.7632, bce: 101.2383, kld: 26.2301\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 6369.008789\n",
      "bce: 100.273468, kld: 25.074942\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 6188.260742\n",
      "bce: 99.548080, kld: 24.354851\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 6001.984375\n",
      "bce: 98.633270, kld: 23.613405\n",
      "====> Epoch: 2 Average loss: 6181.4191, bce: 99.3882, kld: 24.3281\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 5970.723633\n",
      "bce: 98.351242, kld: 23.489491\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 5828.916992\n",
      "bce: 97.271935, kld: 22.926580\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 5669.823730\n",
      "bce: 96.704994, kld: 22.292475\n",
      "====> Epoch: 3 Average loss: 5823.2702, bce: 97.4481, kld: 22.9033\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 5645.020020\n",
      "bce: 96.312622, kld: 22.194830\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 5486.989258\n",
      "bce: 95.896591, kld: 21.564371\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 5315.918945\n",
      "bce: 95.361740, kld: 20.882229\n",
      "====> Epoch: 4 Average loss: 5481.5375, bce: 95.9032, kld: 21.5425\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 5288.139160\n",
      "bce: 95.334366, kld: 20.771219\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 5108.964355\n",
      "bce: 94.933113, kld: 20.056126\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 4921.764648\n",
      "bce: 94.704803, kld: 19.308241\n",
      "====> Epoch: 5 Average loss: 5107.3372, bce: 94.8520, kld: 20.0499\n",
      "====> Testing Average Loss: 77.14117627479696\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 4882.908203\n",
      "bce: 94.542427, kld: 19.153463\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 4682.315430\n",
      "bce: 93.941185, kld: 18.353497\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 4481.026855\n",
      "bce: 93.831711, kld: 17.548780\n",
      "====> Epoch: 6 Average loss: 4683.2338, bce: 94.0157, kld: 18.3569\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 4432.522461\n",
      "bce: 93.522957, kld: 17.355997\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 4209.403809\n",
      "bce: 93.092712, kld: 16.465244\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 3982.164307\n",
      "bce: 92.964790, kld: 15.556798\n",
      "====> Epoch: 7 Average loss: 4208.9263, bce: 93.2609, kld: 16.4627\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 3938.567871\n",
      "bce: 93.085220, kld: 15.381930\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 3702.026611\n",
      "bce: 92.567802, kld: 14.437835\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 3470.428711\n",
      "bce: 92.476135, kld: 13.511810\n",
      "====> Epoch: 8 Average loss: 3702.7719, bce: 92.5858, kld: 14.4407\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 3417.229492\n",
      "bce: 92.221985, kld: 13.300031\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 3194.290039\n",
      "bce: 91.918137, kld: 12.409488\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 2971.661865\n",
      "bce: 91.432755, kld: 11.520916\n",
      "====> Epoch: 9 Average loss: 3194.8369, bce: 91.9294, kld: 12.4116\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 2928.490723\n",
      "bce: 91.838310, kld: 11.346609\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 2712.911621\n",
      "bce: 91.355721, kld: 10.486223\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 2511.830566\n",
      "bce: 91.182510, kld: 9.682591\n",
      "====> Epoch: 10 Average loss: 2716.0808, bce: 91.2859, kld: 10.4992\n",
      "====> Testing Average Loss: 74.33793769138596\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 2473.687744\n",
      "bce: 91.166763, kld: 9.530084\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 2284.645752\n",
      "bce: 90.676056, kld: 8.775879\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 2111.423828\n",
      "bce: 90.401909, kld: 8.084087\n",
      "====> Epoch: 11 Average loss: 2288.9627, bce: 90.6521, kld: 8.7932\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 2080.655273\n",
      "bce: 90.323540, kld: 7.961327\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 1922.012085\n",
      "bce: 89.997185, kld: 7.328060\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 1775.632568\n",
      "bce: 89.834946, kld: 6.743190\n",
      "====> Epoch: 12 Average loss: 1924.3760, bce: 90.0325, kld: 7.3374\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 1749.978027\n",
      "bce: 89.578842, kld: 6.641597\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 1621.502319\n",
      "bce: 89.280396, kld: 6.128888\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 1502.585083\n",
      "bce: 89.146637, kld: 5.653754\n",
      "====> Epoch: 13 Average loss: 1622.4251, bce: 89.4139, kld: 6.1320\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 1479.375610\n",
      "bce: 89.170494, kld: 5.560820\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 1374.572144\n",
      "bce: 88.609550, kld: 5.143851\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 1279.255737\n",
      "bce: 88.545403, kld: 4.762841\n",
      "====> Epoch: 14 Average loss: 1376.7686, bce: 88.8177, kld: 5.1518\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 1261.190918\n",
      "bce: 88.368263, kld: 4.691290\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 1177.105835\n",
      "bce: 88.445076, kld: 4.354643\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 1100.822998\n",
      "bce: 88.159981, kld: 4.050652\n",
      "====> Epoch: 15 Average loss: 1178.5913, bce: 88.2242, kld: 4.3615\n",
      "====> Testing Average Loss: 71.87628145386766\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 1086.955444\n",
      "bce: 88.147285, kld: 3.995232\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 1018.998291\n",
      "bce: 87.633148, kld: 3.725461\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 956.032043\n",
      "bce: 87.409447, kld: 3.474490\n",
      "====> Epoch: 16 Average loss: 1018.7379, bce: 87.6362, kld: 3.7244\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 944.114685\n",
      "bce: 87.462410, kld: 3.426609\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 889.458435\n",
      "bce: 87.121338, kld: 3.209348\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 838.254883\n",
      "bce: 86.809944, kld: 3.005780\n",
      "====> Epoch: 17 Average loss: 889.3609, bce: 87.0657, kld: 3.2092\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 829.298950\n",
      "bce: 86.764854, kld: 2.970136\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 783.818420\n",
      "bce: 86.850647, kld: 2.787871\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 742.132324\n",
      "bce: 86.106964, kld: 2.624101\n",
      "====> Epoch: 18 Average loss: 783.8261, bce: 86.4980, kld: 2.7893\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 734.065857\n",
      "bce: 86.213913, kld: 2.591408\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 697.128296\n",
      "bce: 85.805710, kld: 2.445290\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 662.474915\n",
      "bce: 85.691666, kld: 2.307133\n",
      "====> Epoch: 19 Average loss: 697.0214, bce: 85.9397, kld: 2.4443\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 656.131531\n",
      "bce: 86.012589, kld: 2.280476\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 624.978882\n",
      "bce: 85.267555, kld: 2.158845\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 595.822632\n",
      "bce: 85.193535, kld: 2.042516\n",
      "====> Epoch: 20 Average loss: 624.9971, bce: 85.3901, kld: 2.1584\n",
      "====> Testing Average Loss: 69.59935636067101\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 590.612671\n",
      "bce: 84.990234, kld: 2.022490\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 564.478821\n",
      "bce: 84.746933, kld: 1.918928\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 539.855408\n",
      "bce: 84.428764, kld: 1.821707\n",
      "====> Epoch: 21 Average loss: 564.6210, bce: 84.8467, kld: 1.9191\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 535.291382\n",
      "bce: 84.594719, kld: 1.802787\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 513.367188\n",
      "bce: 84.334373, kld: 1.716131\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 493.212006\n",
      "bce: 84.128326, kld: 1.636335\n",
      "====> Epoch: 22 Average loss: 513.5904, bce: 84.3064, kld: 1.7171\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 489.087402\n",
      "bce: 84.260925, kld: 1.619306\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 469.817963\n",
      "bce: 83.640511, kld: 1.544710\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 452.388977\n",
      "bce: 83.399368, kld: 1.475958\n",
      "====> Epoch: 23 Average loss: 470.1158, bce: 83.7741, kld: 1.5454\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 448.787994\n",
      "bce: 83.619850, kld: 1.460673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 433.085358\n",
      "bce: 83.193634, kld: 1.399567\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 417.704834\n",
      "bce: 83.047562, kld: 1.338629\n",
      "====> Epoch: 24 Average loss: 432.7688, bce: 83.2501, kld: 1.3981\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 414.017944\n",
      "bce: 82.971153, kld: 1.324187\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 400.334991\n",
      "bce: 82.764000, kld: 1.270284\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 387.446259\n",
      "bce: 82.703613, kld: 1.218971\n",
      "====> Epoch: 25 Average loss: 400.4447, bce: 82.7336, kld: 1.2708\n",
      "====> Testing Average Loss: 67.4688644155239\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 383.905212\n",
      "bce: 82.353027, kld: 1.206209\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 372.260559\n",
      "bce: 82.230759, kld: 1.160119\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 360.231689\n",
      "bce: 81.888962, kld: 1.113371\n",
      "====> Epoch: 26 Average loss: 372.2902, bce: 82.2183, kld: 1.1603\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 358.575714\n",
      "bce: 82.057037, kld: 1.106075\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 347.830719\n",
      "bce: 81.781891, kld: 1.064195\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 337.519440\n",
      "bce: 81.300842, kld: 1.024874\n",
      "====> Epoch: 27 Average loss: 347.6063, bce: 81.7102, kld: 1.0636\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 335.316650\n",
      "bce: 81.604065, kld: 1.014850\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 325.216217\n",
      "bce: 81.154877, kld: 0.976245\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 317.036499\n",
      "bce: 81.126038, kld: 0.943642\n",
      "====> Epoch: 28 Average loss: 325.8163, bce: 81.2118, kld: 0.9784\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 314.895142\n",
      "bce: 80.832886, kld: 0.936249\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 307.030945\n",
      "bce: 80.706184, kld: 0.905299\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 298.424347\n",
      "bce: 80.434273, kld: 0.871960\n",
      "====> Epoch: 29 Average loss: 306.5240, bce: 80.7163, kld: 0.9032\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 297.280792\n",
      "bce: 80.585281, kld: 0.866782\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 289.278412\n",
      "bce: 80.288177, kld: 0.835961\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 282.128754\n",
      "bce: 80.229126, kld: 0.807599\n",
      "====> Epoch: 30 Average loss: 289.3178, bce: 80.2284, kld: 0.8364\n",
      "====> Testing Average Loss: 65.46463936226867\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 280.228882\n",
      "bce: 79.875473, kld: 0.801414\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 273.966919\n",
      "bce: 79.703171, kld: 0.777055\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 267.129364\n",
      "bce: 79.581718, kld: 0.750191\n",
      "====> Epoch: 31 Average loss: 273.9146, bce: 79.7420, kld: 0.7767\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 266.114899\n",
      "bce: 79.379250, kld: 0.746943\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 260.540710\n",
      "bce: 79.436066, kld: 0.724419\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 254.386765\n",
      "bce: 78.868988, kld: 0.702071\n",
      "====> Epoch: 32 Average loss: 260.0670, bce: 79.2676, kld: 0.7232\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 253.109329\n",
      "bce: 79.128433, kld: 0.695924\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 247.489639\n",
      "bce: 78.792740, kld: 0.674788\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 242.453445\n",
      "bce: 78.819595, kld: 0.654535\n",
      "====> Epoch: 33 Average loss: 247.5534, bce: 78.7940, kld: 0.6750\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 241.326416\n",
      "bce: 78.499580, kld: 0.651307\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 236.089630\n",
      "bce: 78.354118, kld: 0.630942\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 231.475082\n",
      "bce: 78.166367, kld: 0.613235\n",
      "====> Epoch: 34 Average loss: 236.2305, bce: 78.3284, kld: 0.6316\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 230.449127\n",
      "bce: 78.258163, kld: 0.608764\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 225.963852\n",
      "bce: 77.835190, kld: 0.592515\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 221.555634\n",
      "bce: 77.656158, kld: 0.575598\n",
      "====> Epoch: 35 Average loss: 225.9138, bce: 77.8665, kld: 0.5922\n",
      "====> Testing Average Loss: 63.57390410730928\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 220.301895\n",
      "bce: 77.501450, kld: 0.571202\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 216.991608\n",
      "bce: 77.541969, kld: 0.557799\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 212.619263\n",
      "bce: 77.299316, kld: 0.541280\n",
      "====> Epoch: 36 Average loss: 216.5132, bce: 77.4116, kld: 0.5564\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 211.921387\n",
      "bce: 77.307549, kld: 0.538455\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 208.136963\n",
      "bce: 77.103233, kld: 0.524135\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 203.927094\n",
      "bce: 76.639755, kld: 0.509149\n",
      "====> Epoch: 37 Average loss: 207.9053, bce: 76.9612, kld: 0.5238\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 203.622681\n",
      "bce: 76.819550, kld: 0.507213\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 200.012329\n",
      "bce: 76.484261, kld: 0.494112\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 196.634247\n",
      "bce: 76.112740, kld: 0.482086\n",
      "====> Epoch: 38 Average loss: 200.0008, bce: 76.5184, kld: 0.4939\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 195.733444\n",
      "bce: 76.260376, kld: 0.477892\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 192.585358\n",
      "bce: 75.985786, kld: 0.466398\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 189.760361\n",
      "bce: 75.969818, kld: 0.455162\n",
      "====> Epoch: 39 Average loss: 192.7176, bce: 76.0750, kld: 0.4666\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 188.857208\n",
      "bce: 75.905991, kld: 0.451805\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 186.134995\n",
      "bce: 75.719742, kld: 0.441661\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 182.909210\n",
      "bce: 75.347855, kld: 0.430245\n",
      "====> Epoch: 40 Average loss: 185.9870, bce: 75.6400, kld: 0.4414\n",
      "====> Testing Average Loss: 61.78661920849421\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 182.876099\n",
      "bce: 75.517258, kld: 0.429435\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 179.712738\n",
      "bce: 75.354340, kld: 0.417434\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 177.449005\n",
      "bce: 75.003113, kld: 0.409784\n",
      "====> Epoch: 41 Average loss: 179.7674, bce: 75.2080, kld: 0.4182\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 176.733551\n",
      "bce: 75.084091, kld: 0.406598\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 173.819778\n",
      "bce: 74.823349, kld: 0.395986\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 171.655731\n",
      "bce: 74.654587, kld: 0.388005\n",
      "====> Epoch: 42 Average loss: 173.9977, bce: 74.7803, kld: 0.3969\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 170.931732\n",
      "bce: 74.599426, kld: 0.385329\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 168.652756\n",
      "bce: 74.412613, kld: 0.376961\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 166.282471\n",
      "bce: 74.233376, kld: 0.368196\n",
      "====> Epoch: 43 Average loss: 168.6173, bce: 74.3587, kld: 0.3770\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 165.805542\n",
      "bce: 74.229599, kld: 0.366304\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 163.954987\n",
      "bce: 73.940125, kld: 0.360059\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 161.476868\n",
      "bce: 73.782074, kld: 0.350779\n",
      "====> Epoch: 44 Average loss: 163.6266, bce: 73.9433, kld: 0.3587\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 160.990295\n",
      "bce: 73.627380, kld: 0.349452\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 158.859436\n",
      "bce: 73.606194, kld: 0.341013\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 156.722748\n",
      "bce: 73.277924, kld: 0.333779\n",
      "====> Epoch: 45 Average loss: 158.9531, bce: 73.5306, kld: 0.3417\n",
      "====> Testing Average Loss: 60.10215642058314\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 156.765472\n",
      "bce: 73.406212, kld: 0.333437\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 154.611267\n",
      "bce: 73.104240, kld: 0.326028\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 152.904572\n",
      "bce: 73.074295, kld: 0.319321\n",
      "====> Epoch: 46 Average loss: 154.5797, bce: 73.1222, kld: 0.3258\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 152.402603\n",
      "bce: 72.919952, kld: 0.317931\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 150.549530\n",
      "bce: 72.804123, kld: 0.310982\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 148.521515\n",
      "bce: 72.444046, kld: 0.304310\n",
      "====> Epoch: 47 Average loss: 150.4867, bce: 72.7187, kld: 0.3111\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 148.453339\n",
      "bce: 72.499016, kld: 0.303817\n",
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 146.539154\n",
      "bce: 72.216042, kld: 0.297292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 145.037003\n",
      "bce: 72.264191, kld: 0.291091\n",
      "====> Epoch: 48 Average loss: 146.6363, bce: 72.3187, kld: 0.2973\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 144.822510\n",
      "bce: 72.249748, kld: 0.290291\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 143.186127\n",
      "bce: 71.919167, kld: 0.285068\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 141.183044\n",
      "bce: 71.633682, kld: 0.278197\n",
      "====> Epoch: 49 Average loss: 143.0181, bce: 71.9215, kld: 0.2844\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 141.054749\n",
      "bce: 71.538651, kld: 0.278064\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 139.456909\n",
      "bce: 71.556778, kld: 0.271601\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 138.139313\n",
      "bce: 71.414963, kld: 0.266897\n",
      "====> Epoch: 50 Average loss: 139.6049, bce: 71.5303, kld: 0.2723\n",
      "====> Testing Average Loss: 58.49849387564905\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 137.822250\n",
      "bce: 71.284882, kld: 0.266149\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 136.241241\n",
      "bce: 71.044373, kld: 0.260788\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 135.068665\n",
      "bce: 70.989975, kld: 0.256315\n",
      "====> Epoch: 51 Average loss: 136.3829, bce: 71.1423, kld: 0.2610\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 135.013367\n",
      "bce: 71.028450, kld: 0.255940\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 133.791183\n",
      "bce: 71.033043, kld: 0.251033\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 131.611954\n",
      "bce: 70.328049, kld: 0.245136\n",
      "====> Epoch: 52 Average loss: 133.3407, bce: 70.7608, kld: 0.2503\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 131.628937\n",
      "bce: 70.492256, kld: 0.244547\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 130.573563\n",
      "bce: 70.418884, kld: 0.240619\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 129.193634\n",
      "bce: 70.198326, kld: 0.235981\n",
      "====> Epoch: 53 Average loss: 130.4672, bce: 70.3821, kld: 0.2403\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 129.112152\n",
      "bce: 70.332619, kld: 0.235118\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 127.765854\n",
      "bce: 69.953979, kld: 0.231247\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 126.638588\n",
      "bce: 69.933105, kld: 0.226822\n",
      "====> Epoch: 54 Average loss: 127.7350, bce: 70.0067, kld: 0.2309\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 126.335030\n",
      "bce: 69.785698, kld: 0.226197\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 125.183975\n",
      "bce: 69.731430, kld: 0.221810\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 123.945198\n",
      "bce: 69.488022, kld: 0.217829\n",
      "====> Epoch: 55 Average loss: 125.1475, bce: 69.6411, kld: 0.2220\n",
      "====> Testing Average Loss: 56.989850302889096\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 123.719940\n",
      "bce: 69.485039, kld: 0.216940\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 122.446503\n",
      "bce: 69.136322, kld: 0.213241\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 121.554108\n",
      "bce: 69.098541, kld: 0.209822\n",
      "====> Epoch: 56 Average loss: 122.6968, bce: 69.2774, kld: 0.2137\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 121.301086\n",
      "bce: 68.954018, kld: 0.209388\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 120.273552\n",
      "bce: 68.985428, kld: 0.205152\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 119.386833\n",
      "bce: 68.911179, kld: 0.201903\n",
      "====> Epoch: 57 Average loss: 120.3574, bce: 68.9189, kld: 0.2058\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 119.112930\n",
      "bce: 68.783897, kld: 0.201316\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 118.238968\n",
      "bce: 68.597588, kld: 0.198566\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 117.188934\n",
      "bce: 68.339546, kld: 0.195398\n",
      "====> Epoch: 58 Average loss: 118.1336, bce: 68.5673, kld: 0.1983\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 117.045563\n",
      "bce: 68.417358, kld: 0.194513\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 115.886795\n",
      "bce: 68.191345, kld: 0.190782\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 114.962479\n",
      "bce: 68.054199, kld: 0.187633\n",
      "====> Epoch: 59 Average loss: 116.0101, bce: 68.2167, kld: 0.1912\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 114.766457\n",
      "bce: 68.035049, kld: 0.186926\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 114.127930\n",
      "bce: 68.003952, kld: 0.184496\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 112.978516\n",
      "bce: 67.637733, kld: 0.181363\n",
      "====> Epoch: 60 Average loss: 113.9805, bce: 67.8686, kld: 0.1844\n",
      "====> Testing Average Loss: 55.57447618492877\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 113.001785\n",
      "bce: 67.669472, kld: 0.181329\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 112.047829\n",
      "bce: 67.574852, kld: 0.177892\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 111.215363\n",
      "bce: 67.367157, kld: 0.175393\n",
      "====> Epoch: 61 Average loss: 112.0515, bce: 67.5284, kld: 0.1781\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 111.094139\n",
      "bce: 67.333603, kld: 0.175042\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 109.964653\n",
      "bce: 67.102745, kld: 0.171448\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 109.474823\n",
      "bce: 67.125854, kld: 0.169396\n",
      "====> Epoch: 62 Average loss: 110.1993, bce: 67.1920, kld: 0.1720\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 109.402863\n",
      "bce: 67.138008, kld: 0.169059\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 108.417374\n",
      "bce: 66.930389, kld: 0.165948\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 107.583389\n",
      "bce: 66.669151, kld: 0.163657\n",
      "====> Epoch: 63 Average loss: 108.4355, bce: 66.8605, kld: 0.1663\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 107.413666\n",
      "bce: 66.584732, kld: 0.163316\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 106.671616\n",
      "bce: 66.437805, kld: 0.160935\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 106.028290\n",
      "bce: 66.448990, kld: 0.158317\n",
      "====> Epoch: 64 Average loss: 106.7366, bce: 66.5296, kld: 0.1608\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 105.847382\n",
      "bce: 66.384087, kld: 0.157853\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 105.124535\n",
      "bce: 66.148956, kld: 0.155902\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 104.299683\n",
      "bce: 65.963409, kld: 0.153345\n",
      "====> Epoch: 65 Average loss: 105.1045, bce: 66.2033, kld: 0.1556\n",
      "====> Testing Average Loss: 54.242201021834646\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 104.109390\n",
      "bce: 65.863121, kld: 0.152985\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 103.702477\n",
      "bce: 65.998581, kld: 0.150816\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 102.821526\n",
      "bce: 65.718529, kld: 0.148412\n",
      "====> Epoch: 66 Average loss: 103.5462, bce: 65.8813, kld: 0.1507\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 102.911324\n",
      "bce: 65.925102, kld: 0.147945\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 101.866287\n",
      "bce: 65.369728, kld: 0.145986\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 101.659637\n",
      "bce: 65.639664, kld: 0.144080\n",
      "====> Epoch: 67 Average loss: 102.0458, bce: 65.5640, kld: 0.1459\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 101.257217\n",
      "bce: 65.463501, kld: 0.143175\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 100.518410\n",
      "bce: 65.143341, kld: 0.141500\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 100.140244\n",
      "bce: 65.266930, kld: 0.139493\n",
      "====> Epoch: 68 Average loss: 100.6015, bce: 65.2483, kld: 0.1414\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 99.615280\n",
      "bce: 64.957230, kld: 0.138632\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 99.328232\n",
      "bce: 64.999191, kld: 0.137316\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 98.724358\n",
      "bce: 64.848473, kld: 0.135504\n",
      "====> Epoch: 69 Average loss: 99.2078, bce: 64.9348, kld: 0.1371\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 98.603226\n",
      "bce: 64.869781, kld: 0.134934\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 98.190819\n",
      "bce: 64.871887, kld: 0.133276\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 97.272812\n",
      "bce: 64.525772, kld: 0.130988\n",
      "====> Epoch: 70 Average loss: 97.8770, bce: 64.6283, kld: 0.1330\n",
      "====> Testing Average Loss: 52.98565853414991\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 97.117065\n",
      "bce: 64.404610, kld: 0.130850\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 96.781563\n",
      "bce: 64.572281, kld: 0.128837\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 95.939980\n",
      "bce: 64.099411, kld: 0.127362\n",
      "====> Epoch: 71 Average loss: 96.5814, bce: 64.3219, kld: 0.1290\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 96.178848\n",
      "bce: 64.387672, kld: 0.127165\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 95.542648\n",
      "bce: 64.184494, kld: 0.125433\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 94.756844\n",
      "bce: 63.878841, kld: 0.123512\n",
      "====> Epoch: 72 Average loss: 95.3385, bce: 64.0198, kld: 0.1253\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 94.811020\n",
      "bce: 64.026482, kld: 0.123138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 94.047165\n",
      "bce: 63.676392, kld: 0.121483\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 93.534027\n",
      "bce: 63.469543, kld: 0.120258\n",
      "====> Epoch: 73 Average loss: 94.1381, bce: 63.7218, kld: 0.1217\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 93.191437\n",
      "bce: 63.315483, kld: 0.119504\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 93.083199\n",
      "bce: 63.492168, kld: 0.118364\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 92.316444\n",
      "bce: 63.168785, kld: 0.116591\n",
      "====> Epoch: 74 Average loss: 92.9806, bce: 63.4287, kld: 0.1182\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 92.351662\n",
      "bce: 63.288254, kld: 0.116254\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 91.742645\n",
      "bce: 63.046391, kld: 0.114785\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 91.192284\n",
      "bce: 62.923393, kld: 0.113076\n",
      "====> Epoch: 75 Average loss: 91.8630, bce: 63.1375, kld: 0.1149\n",
      "====> Testing Average Loss: 51.796614964718415\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 91.054398\n",
      "bce: 62.825855, kld: 0.112914\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 91.199417\n",
      "bce: 63.243416, kld: 0.111824\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 90.079597\n",
      "bce: 62.595348, kld: 0.109937\n",
      "====> Epoch: 76 Average loss: 90.7754, bce: 62.8454, kld: 0.1117\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 90.360184\n",
      "bce: 62.908783, kld: 0.109806\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 89.774620\n",
      "bce: 62.648869, kld: 0.108503\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 89.107910\n",
      "bce: 62.257439, kld: 0.107402\n",
      "====> Epoch: 77 Average loss: 89.7293, bce: 62.5629, kld: 0.1087\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 89.184906\n",
      "bce: 62.393520, kld: 0.107166\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 88.699249\n",
      "bce: 62.281822, kld: 0.105670\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 88.066452\n",
      "bce: 61.973217, kld: 0.104373\n",
      "====> Epoch: 78 Average loss: 88.7133, bce: 62.2781, kld: 0.1057\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 88.247589\n",
      "bce: 62.189510, kld: 0.104232\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 87.667450\n",
      "bce: 61.975647, kld: 0.102767\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 87.234291\n",
      "bce: 61.778133, kld: 0.101825\n",
      "====> Epoch: 79 Average loss: 87.7274, bce: 61.9955, kld: 0.1029\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 87.377533\n",
      "bce: 61.935196, kld: 0.101769\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 86.704910\n",
      "bce: 61.610863, kld: 0.100376\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 86.172791\n",
      "bce: 61.507202, kld: 0.098662\n",
      "====> Epoch: 80 Average loss: 86.7736, bce: 61.7198, kld: 0.1002\n",
      "====> Testing Average Loss: 50.66569552156837\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 86.486771\n",
      "bce: 61.748932, kld: 0.098951\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 85.980103\n",
      "bce: 61.596420, kld: 0.097535\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 85.375732\n",
      "bce: 61.261242, kld: 0.096458\n",
      "====> Epoch: 81 Average loss: 85.8563, bce: 61.4479, kld: 0.0976\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 85.303970\n",
      "bce: 61.238335, kld: 0.096263\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 85.045197\n",
      "bce: 61.238346, kld: 0.095227\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 84.489532\n",
      "bce: 60.967033, kld: 0.094090\n",
      "====> Epoch: 82 Average loss: 84.9553, bce: 61.1717, kld: 0.0951\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 84.631950\n",
      "bce: 61.116028, kld: 0.094064\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 84.225456\n",
      "bce: 61.005493, kld: 0.092880\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 83.699509\n",
      "bce: 60.741806, kld: 0.091831\n",
      "====> Epoch: 83 Average loss: 84.0827, bce: 60.9018, kld: 0.0927\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 83.901611\n",
      "bce: 61.018223, kld: 0.091534\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 83.179832\n",
      "bce: 60.609856, kld: 0.090280\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 82.732834\n",
      "bce: 60.423431, kld: 0.089238\n",
      "====> Epoch: 84 Average loss: 83.2399, bce: 60.6362, kld: 0.0904\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 82.548950\n",
      "bce: 60.247581, kld: 0.089205\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 82.829918\n",
      "bce: 60.702335, kld: 0.088510\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 81.928192\n",
      "bce: 60.121944, kld: 0.087225\n",
      "====> Epoch: 85 Average loss: 82.4048, bce: 60.3547, kld: 0.0882\n",
      "====> Testing Average Loss: 49.561363125748905\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 82.260117\n",
      "bce: 60.510143, kld: 0.087000\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 81.505783\n",
      "bce: 59.988728, kld: 0.086068\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 81.434792\n",
      "bce: 60.095325, kld: 0.085358\n",
      "====> Epoch: 86 Average loss: 81.6024, bce: 60.0778, kld: 0.0861\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 81.302917\n",
      "bce: 60.041126, kld: 0.085047\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 80.807938\n",
      "bce: 59.721821, kld: 0.084344\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 80.239288\n",
      "bce: 59.299728, kld: 0.083758\n",
      "====> Epoch: 87 Average loss: 80.7973, bce: 59.7607, kld: 0.0841\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 80.439713\n",
      "bce: 59.687553, kld: 0.083009\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 80.052765\n",
      "bce: 59.377632, kld: 0.082701\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 79.591438\n",
      "bce: 59.017384, kld: 0.082296\n",
      "====> Epoch: 88 Average loss: 79.9538, bce: 59.2915, kld: 0.0826\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 79.544128\n",
      "bce: 58.998844, kld: 0.082181\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 78.938980\n",
      "bce: 58.561790, kld: 0.081509\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 78.577835\n",
      "bce: 58.305782, kld: 0.081088\n",
      "====> Epoch: 89 Average loss: 79.0153, bce: 58.6061, kld: 0.0816\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 78.485382\n",
      "bce: 58.244545, kld: 0.080963\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 78.161125\n",
      "bce: 58.074139, kld: 0.080348\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 77.740341\n",
      "bce: 57.900074, kld: 0.079361\n",
      "====> Epoch: 90 Average loss: 78.1625, bce: 58.1333, kld: 0.0801\n",
      "====> Testing Average Loss: 47.46370531553721\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 77.871658\n",
      "bce: 58.084114, kld: 0.079150\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 77.378830\n",
      "bce: 57.727440, kld: 0.078606\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 76.895546\n",
      "bce: 57.566872, kld: 0.077315\n",
      "====> Epoch: 91 Average loss: 77.3673, bce: 57.7510, kld: 0.0785\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 76.934418\n",
      "bce: 57.637562, kld: 0.077187\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 76.711708\n",
      "bce: 57.571712, kld: 0.076560\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 76.498573\n",
      "bce: 57.426727, kld: 0.076287\n",
      "====> Epoch: 92 Average loss: 76.5797, bce: 57.3942, kld: 0.0767\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 76.360947\n",
      "bce: 57.364407, kld: 0.075986\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 75.520889\n",
      "bce: 56.813858, kld: 0.074828\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 75.649185\n",
      "bce: 57.074997, kld: 0.074297\n",
      "====> Epoch: 93 Average loss: 75.7982, bce: 57.0376, kld: 0.0750\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 75.415398\n",
      "bce: 56.970806, kld: 0.073778\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 75.360596\n",
      "bce: 57.043587, kld: 0.073268\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 74.714310\n",
      "bce: 56.552822, kld: 0.072646\n",
      "====> Epoch: 94 Average loss: 75.1093, bce: 56.7547, kld: 0.0734\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 74.924797\n",
      "bce: 56.829498, kld: 0.072381\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 74.171120\n",
      "bce: 56.314018, kld: 0.071428\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 74.086517\n",
      "bce: 56.252159, kld: 0.071337\n",
      "====> Epoch: 95 Average loss: 74.3937, bce: 56.4284, kld: 0.0719\n",
      "====> Testing Average Loss: 46.05257081280788\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 73.823410\n",
      "bce: 56.089157, kld: 0.070937\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 73.611847\n",
      "bce: 56.056091, kld: 0.070223\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 73.383087\n",
      "bce: 56.000015, kld: 0.069532\n",
      "====> Epoch: 96 Average loss: 73.7199, bce: 56.1355, kld: 0.0703\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 73.467361\n",
      "bce: 56.147102, kld: 0.069281\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 73.016068\n",
      "bce: 55.828773, kld: 0.068749\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 72.678299\n",
      "bce: 55.547913, kld: 0.068522\n",
      "====> Epoch: 97 Average loss: 73.0254, bce: 55.8202, kld: 0.0688\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 72.521751\n",
      "bce: 55.480049, kld: 0.068167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 72.144508\n",
      "bce: 55.299576, kld: 0.067380\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 72.117142\n",
      "bce: 55.459908, kld: 0.066629\n",
      "====> Epoch: 98 Average loss: 72.4021, bce: 55.5520, kld: 0.0674\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 71.936371\n",
      "bce: 55.415916, kld: 0.066082\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 71.456596\n",
      "bce: 55.060486, kld: 0.065584\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 71.483475\n",
      "bce: 55.115005, kld: 0.065474\n",
      "====> Epoch: 99 Average loss: 71.7648, bce: 55.2748, kld: 0.0660\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 71.423569\n",
      "bce: 55.174870, kld: 0.064995\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 71.093979\n",
      "bce: 55.069401, kld: 0.064098\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 70.956467\n",
      "bce: 54.975304, kld: 0.063925\n",
      "====> Epoch: 100 Average loss: 71.1523, bce: 55.0072, kld: 0.0646\n",
      "====> Testing Average Loss: 44.77536280122487\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 71.079170\n",
      "bce: 55.080597, kld: 0.063994\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 70.534332\n",
      "bce: 54.799122, kld: 0.062941\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 70.399025\n",
      "bce: 54.777016, kld: 0.062488\n",
      "====> Epoch: 101 Average loss: 70.5552, bce: 54.7394, kld: 0.0633\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 70.219460\n",
      "bce: 54.601200, kld: 0.062473\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 70.190552\n",
      "bce: 54.658070, kld: 0.062130\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 69.994675\n",
      "bce: 54.641617, kld: 0.061412\n",
      "====> Epoch: 102 Average loss: 69.9861, bce: 54.4952, kld: 0.0620\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 69.972977\n",
      "bce: 54.578453, kld: 0.061578\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 69.537888\n",
      "bce: 54.294731, kld: 0.060973\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 69.372955\n",
      "bce: 54.263676, kld: 0.060437\n",
      "====> Epoch: 103 Average loss: 69.3958, bce: 54.2254, kld: 0.0607\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 69.513969\n",
      "bce: 54.362415, kld: 0.060606\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 68.923355\n",
      "bce: 54.055450, kld: 0.059472\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 68.599777\n",
      "bce: 53.930264, kld: 0.058678\n",
      "====> Epoch: 104 Average loss: 68.8635, bce: 53.9952, kld: 0.0595\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 68.891327\n",
      "bce: 54.229881, kld: 0.058646\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 68.568398\n",
      "bce: 54.074379, kld: 0.057976\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 68.095001\n",
      "bce: 53.654202, kld: 0.057763\n",
      "====> Epoch: 105 Average loss: 68.3079, bce: 53.7400, kld: 0.0583\n",
      "====> Testing Average Loss: 43.659694947410465\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 68.147690\n",
      "bce: 53.666985, kld: 0.057923\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 67.540787\n",
      "bce: 53.147629, kld: 0.057573\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 67.544487\n",
      "bce: 53.222343, kld: 0.057289\n",
      "====> Epoch: 106 Average loss: 67.7683, bce: 53.4922, kld: 0.0571\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 67.461746\n",
      "bce: 53.155262, kld: 0.057226\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 67.630287\n",
      "bce: 53.596352, kld: 0.056136\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 67.201752\n",
      "bce: 53.299629, kld: 0.055609\n",
      "====> Epoch: 107 Average loss: 67.2779, bce: 53.2766, kld: 0.0560\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 67.070236\n",
      "bce: 53.215168, kld: 0.055420\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 66.902321\n",
      "bce: 53.226784, kld: 0.054702\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 66.540749\n",
      "bce: 52.891769, kld: 0.054596\n",
      "====> Epoch: 108 Average loss: 66.7693, bce: 53.0560, kld: 0.0549\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 66.340050\n",
      "bce: 52.711380, kld: 0.054515\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=250,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn_onemany.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
