{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 10054.846680\n",
      "bce: 105.991013, kld: 39.795422\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 6916.924316\n",
      "bce: 104.656639, kld: 27.249071\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 6249.882324\n",
      "bce: 103.843643, kld: 24.584154\n",
      "====> Epoch: 0 Average loss: 7318.1446, bce: 104.7852, kld: 28.8534\n",
      "====> Testing Average Loss: 84.64123244241779\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 6170.058594\n",
      "bce: 103.497704, kld: 24.266245\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 5887.739746\n",
      "bce: 102.436249, kld: 23.141214\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 5710.903320\n",
      "bce: 101.620483, kld: 22.437130\n",
      "====> Epoch: 1 Average loss: 5908.8146, bce: 102.5221, kld: 23.2252\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 5676.620117\n",
      "bce: 101.487961, kld: 22.300529\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 5497.576172\n",
      "bce: 100.478271, kld: 21.588392\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 5314.696289\n",
      "bce: 99.630226, kld: 20.860264\n",
      "====> Epoch: 2 Average loss: 5492.5660, bce: 100.5129, kld: 21.5682\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 5280.091309\n",
      "bce: 99.210495, kld: 20.723524\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 5105.042480\n",
      "bce: 98.512772, kld: 20.026119\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 4918.326660\n",
      "bce: 97.534805, kld: 19.283169\n",
      "====> Epoch: 3 Average loss: 5099.2578, bce: 98.2436, kld: 20.0041\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 4875.380371\n",
      "bce: 97.075249, kld: 19.113220\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 4672.228027\n",
      "bce: 96.363235, kld: 18.303459\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 4450.283203\n",
      "bce: 95.671936, kld: 17.418446\n",
      "====> Epoch: 4 Average loss: 4665.9275, bce: 96.2872, kld: 18.2786\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 4402.851562\n",
      "bce: 95.434990, kld: 17.229666\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 4164.461914\n",
      "bce: 94.249008, kld: 16.280851\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 3913.876953\n",
      "bce: 93.763145, kld: 15.280455\n",
      "====> Epoch: 5 Average loss: 4161.8565, bce: 94.5053, kld: 16.2694\n",
      "====> Testing Average Loss: 76.14851343030222\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 3864.300293\n",
      "bce: 93.766464, kld: 15.082136\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 3602.987305\n",
      "bce: 93.202019, kld: 14.039142\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 3342.354980\n",
      "bce: 92.371902, kld: 12.999932\n",
      "====> Epoch: 6 Average loss: 3603.2304, bce: 93.0422, kld: 14.0408\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 3290.211914\n",
      "bce: 92.439774, kld: 12.791089\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 3032.417969\n",
      "bce: 91.814201, kld: 11.762415\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 2779.932617\n",
      "bce: 90.896317, kld: 10.756145\n",
      "====> Epoch: 7 Average loss: 3032.2594, bce: 91.6509, kld: 11.7624\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 2730.888916\n",
      "bce: 90.799576, kld: 10.560357\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 2492.251221\n",
      "bce: 90.106575, kld: 9.608578\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 2270.317139\n",
      "bce: 89.314468, kld: 8.724010\n",
      "====> Epoch: 8 Average loss: 2495.0210, bce: 90.0561, kld: 9.6199\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 2226.611328\n",
      "bce: 88.747955, kld: 8.551454\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 2021.410156\n",
      "bce: 88.388336, kld: 7.732088\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 1834.947998\n",
      "bce: 86.855957, kld: 6.992368\n",
      "====> Epoch: 9 Average loss: 2025.0704, bce: 88.0809, kld: 7.7480\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 1800.231201\n",
      "bce: 86.722992, kld: 6.854033\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 1633.913818\n",
      "bce: 85.794235, kld: 6.192479\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 1485.519287\n",
      "bce: 85.147102, kld: 5.601489\n",
      "====> Epoch: 10 Average loss: 1637.2206, bce: 85.9617, kld: 6.2050\n",
      "====> Testing Average Loss: 66.8914342297963\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 1457.160034\n",
      "bce: 85.076187, kld: 5.488336\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 1327.281250\n",
      "bce: 84.154846, kld: 4.972506\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 1211.278320\n",
      "bce: 83.468613, kld: 4.511239\n",
      "====> Epoch: 11 Average loss: 1329.5985, bce: 84.1603, kld: 4.9818\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 1189.600464\n",
      "bce: 83.557449, kld: 4.424172\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 1089.007812\n",
      "bce: 82.727509, kld: 4.025121\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 1000.284607\n",
      "bce: 81.906555, kld: 3.673512\n",
      "====> Epoch: 12 Average loss: 1090.8374, bce: 82.6457, kld: 4.0328\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 983.120667\n",
      "bce: 82.071854, kld: 3.604195\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 906.618042\n",
      "bce: 81.622131, kld: 3.299984\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 836.052124\n",
      "bce: 80.658478, kld: 3.021574\n",
      "====> Epoch: 13 Average loss: 906.8990, bce: 81.3482, kld: 3.3022\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 823.849609\n",
      "bce: 80.867020, kld: 2.971931\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 763.868896\n",
      "bce: 80.122963, kld: 2.734984\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 709.887634\n",
      "bce: 79.833023, kld: 2.520219\n",
      "====> Epoch: 14 Average loss: 764.9202, bce: 80.2663, kld: 2.7386\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 700.320801\n",
      "bce: 79.934624, kld: 2.481545\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 653.967712\n",
      "bce: 79.456413, kld: 2.298045\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 611.302856\n",
      "bce: 78.657379, kld: 2.130582\n",
      "====> Epoch: 15 Average loss: 654.4244, bce: 79.3236, kld: 2.3004\n",
      "====> Testing Average Loss: 60.17359539342298\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 603.274658\n",
      "bce: 78.804901, kld: 2.097879\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 566.869385\n",
      "bce: 78.330597, kld: 1.954155\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 533.298889\n",
      "bce: 78.201561, kld: 1.820389\n",
      "====> Epoch: 16 Average loss: 567.4158, bce: 78.4609, kld: 1.9558\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 526.604126\n",
      "bce: 77.769287, kld: 1.795339\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 497.733582\n",
      "bce: 77.733536, kld: 1.680000\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 470.812012\n",
      "bce: 77.154297, kld: 1.574631\n",
      "====> Epoch: 17 Average loss: 497.9803, bce: 77.6519, kld: 1.6813\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 465.375732\n",
      "bce: 76.910362, kld: 1.553861\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 441.480194\n",
      "bce: 76.836639, kld: 1.458574\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 419.462769\n",
      "bce: 76.649704, kld: 1.371252\n",
      "====> Epoch: 18 Average loss: 441.8759, bce: 76.8870, kld: 1.4600\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 415.401367\n",
      "bce: 76.255112, kld: 1.356585\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 395.666290\n",
      "bce: 76.299721, kld: 1.277466\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 377.922852\n",
      "bce: 76.039970, kld: 1.207531\n",
      "====> Epoch: 19 Average loss: 395.9511, bce: 76.1574, kld: 1.2792\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 374.208160\n",
      "bce: 75.977196, kld: 1.192924\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 358.257355\n",
      "bce: 75.861145, kld: 1.129585\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 342.477631\n",
      "bce: 75.065132, kld: 1.069650\n",
      "====> Epoch: 20 Average loss: 357.9026, bce: 75.4459, kld: 1.1298\n",
      "====> Testing Average Loss: 56.443990480628415\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 339.841034\n",
      "bce: 75.412453, kld: 1.057714\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 325.989441\n",
      "bce: 74.641846, kld: 1.005390\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 313.598633\n",
      "bce: 74.795471, kld: 0.955213\n",
      "====> Epoch: 21 Average loss: 326.0387, bce: 74.7582, kld: 1.0051\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 310.698303\n",
      "bce: 74.304642, kld: 0.945575\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 299.365875\n",
      "bce: 74.411652, kld: 0.899817\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 287.961426\n",
      "bce: 73.803894, kld: 0.856630\n",
      "====> Epoch: 22 Average loss: 299.0925, bce: 74.0823, kld: 0.9000\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 285.955811\n",
      "bce: 73.866684, kld: 0.848357\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 275.611450\n",
      "bce: 72.946350, kld: 0.810660\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 266.305359\n",
      "bce: 72.886444, kld: 0.773676\n",
      "====> Epoch: 23 Average loss: 276.0893, bce: 73.4316, kld: 0.8106\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 264.571350\n",
      "bce: 72.937607, kld: 0.766535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 256.191284\n",
      "bce: 72.616615, kld: 0.734299\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 248.152344\n",
      "bce: 72.543404, kld: 0.702436\n",
      "====> Epoch: 24 Average loss: 256.2766, bce: 72.7873, kld: 0.7340\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 246.204926\n",
      "bce: 72.201729, kld: 0.696013\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 239.256332\n",
      "bce: 72.400360, kld: 0.667424\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 231.959946\n",
      "bce: 71.734055, kld: 0.640904\n",
      "====> Epoch: 25 Average loss: 239.0826, bce: 72.1593, kld: 0.6677\n",
      "====> Testing Average Loss: 53.33787528291839\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 230.866104\n",
      "bce: 72.128754, kld: 0.634949\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 224.279999\n",
      "bce: 71.670319, kld: 0.610439\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 217.608521\n",
      "bce: 71.252518, kld: 0.585424\n",
      "====> Epoch: 26 Average loss: 224.0642, bce: 71.5450, kld: 0.6101\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 216.480133\n",
      "bce: 71.242317, kld: 0.580951\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 211.209824\n",
      "bce: 71.109604, kld: 0.560401\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 205.445801\n",
      "bce: 70.706047, kld: 0.538959\n",
      "====> Epoch: 27 Average loss: 210.8554, bce: 70.9371, kld: 0.5597\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 204.314590\n",
      "bce: 70.713379, kld: 0.534405\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 199.223831\n",
      "bce: 70.544022, kld: 0.514719\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 194.440796\n",
      "bce: 70.239952, kld: 0.496803\n",
      "====> Epoch: 28 Average loss: 199.1619, bce: 70.3430, kld: 0.5153\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 193.520096\n",
      "bce: 70.303307, kld: 0.492867\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 188.981262\n",
      "bce: 69.979317, kld: 0.476008\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 183.908676\n",
      "bce: 69.167831, kld: 0.458963\n",
      "====> Epoch: 29 Average loss: 188.7603, bce: 69.7600, kld: 0.4760\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 183.732346\n",
      "bce: 69.588539, kld: 0.456575\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 179.633179\n",
      "bce: 69.488770, kld: 0.440578\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 175.394791\n",
      "bce: 68.879967, kld: 0.426059\n",
      "====> Epoch: 30 Average loss: 179.4578, bce: 69.1848, kld: 0.4411\n",
      "====> Testing Average Loss: 50.571264229130605\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 175.185135\n",
      "bce: 69.244255, kld: 0.423764\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 170.790009\n",
      "bce: 68.202621, kld: 0.410350\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 167.144958\n",
      "bce: 67.761513, kld: 0.397534\n",
      "====> Epoch: 31 Average loss: 171.0993, bce: 68.6207, kld: 0.4099\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 167.051422\n",
      "bce: 68.600464, kld: 0.393804\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 163.887085\n",
      "bce: 68.430695, kld: 0.381826\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 160.124985\n",
      "bce: 67.695786, kld: 0.369717\n",
      "====> Epoch: 32 Average loss: 163.5441, bce: 68.0646, kld: 0.3819\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 159.700668\n",
      "bce: 67.707977, kld: 0.367971\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 156.360413\n",
      "bce: 67.144661, kld: 0.356863\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 153.810272\n",
      "bce: 67.325027, kld: 0.345941\n",
      "====> Epoch: 33 Average loss: 156.7097, bce: 67.5201, kld: 0.3568\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 153.348633\n",
      "bce: 67.195694, kld: 0.344612\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 150.413239\n",
      "bce: 66.856468, kld: 0.334227\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 147.661499\n",
      "bce: 66.503067, kld: 0.324634\n",
      "====> Epoch: 34 Average loss: 150.4732, bce: 66.9762, kld: 0.3340\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 147.605637\n",
      "bce: 67.020752, kld: 0.322340\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 144.825424\n",
      "bce: 66.517494, kld: 0.313232\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 142.074005\n",
      "bce: 65.999397, kld: 0.304298\n",
      "====> Epoch: 35 Average loss: 144.7906, bce: 66.4483, kld: 0.3134\n",
      "====> Testing Average Loss: 48.03244304187192\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 142.189743\n",
      "bce: 66.509293, kld: 0.302722\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 139.829330\n",
      "bce: 66.215157, kld: 0.294457\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 137.239609\n",
      "bce: 65.533264, kld: 0.286825\n",
      "====> Epoch: 36 Average loss: 139.5800, bce: 65.9313, kld: 0.2946\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 136.303253\n",
      "bce: 64.986343, kld: 0.285268\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 134.656097\n",
      "bce: 65.237541, kld: 0.277674\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 132.955872\n",
      "bce: 65.337524, kld: 0.270473\n",
      "====> Epoch: 37 Average loss: 134.7762, bce: 65.4141, kld: 0.2774\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 132.447021\n",
      "bce: 65.195107, kld: 0.269008\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 130.582153\n",
      "bce: 65.102074, kld: 0.261920\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 128.559448\n",
      "bce: 64.757393, kld: 0.255208\n",
      "====> Epoch: 38 Average loss: 130.3583, bce: 64.9096, kld: 0.2618\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 128.164444\n",
      "bce: 64.720512, kld: 0.253776\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 126.383034\n",
      "bce: 64.575165, kld: 0.247231\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 124.543358\n",
      "bce: 64.229797, kld: 0.241254\n",
      "====> Epoch: 39 Average loss: 126.2643, bce: 64.4087, kld: 0.2474\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 123.797150\n",
      "bce: 63.770546, kld: 0.240106\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 122.922867\n",
      "bce: 64.417953, kld: 0.234020\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 120.852463\n",
      "bce: 63.709469, kld: 0.228572\n",
      "====> Epoch: 40 Average loss: 122.4796, bce: 63.9228, kld: 0.2342\n",
      "====> Testing Average Loss: 45.72322780754893\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 120.656006\n",
      "bce: 63.810371, kld: 0.227383\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 118.950752\n",
      "bce: 63.428066, kld: 0.222091\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 117.821823\n",
      "bce: 63.595627, kld: 0.216905\n",
      "====> Epoch: 41 Average loss: 118.9468, bce: 63.4372, kld: 0.2220\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 117.236870\n",
      "bce: 63.235176, kld: 0.216007\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 115.653862\n",
      "bce: 62.942005, kld: 0.210847\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 113.959381\n",
      "bce: 62.543247, kld: 0.205665\n",
      "====> Epoch: 42 Average loss: 115.6527, bce: 62.9571, kld: 0.2108\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 113.820396\n",
      "bce: 62.512428, kld: 0.205232\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 112.843498\n",
      "bce: 62.820946, kld: 0.200090\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 111.411758\n",
      "bce: 62.499229, kld: 0.195650\n",
      "====> Epoch: 43 Average loss: 112.5886, bce: 62.4916, kld: 0.2004\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 111.019623\n",
      "bce: 62.300468, kld: 0.194877\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 110.156525\n",
      "bce: 62.465500, kld: 0.190764\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 107.976570\n",
      "bce: 61.355637, kld: 0.186484\n",
      "====> Epoch: 44 Average loss: 109.7043, bce: 62.0237, kld: 0.1907\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 108.295029\n",
      "bce: 61.908817, kld: 0.185545\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 107.251198\n",
      "bce: 61.830917, kld: 0.181681\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 105.701385\n",
      "bce: 61.199516, kld: 0.178007\n",
      "====> Epoch: 45 Average loss: 107.0037, bce: 61.5659, kld: 0.1818\n",
      "====> Testing Average Loss: 43.58612160497936\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 105.722351\n",
      "bce: 61.369286, kld: 0.177412\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 104.529816\n",
      "bce: 61.233494, kld: 0.173185\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 103.241539\n",
      "bce: 60.801895, kld: 0.169759\n",
      "====> Epoch: 46 Average loss: 104.4619, bce: 61.1128, kld: 0.1734\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 103.410576\n",
      "bce: 61.162674, kld: 0.168992\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 101.997879\n",
      "bce: 60.639458, kld: 0.165434\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 100.861328\n",
      "bce: 60.281837, kld: 0.162318\n",
      "====> Epoch: 47 Average loss: 102.0703, bce: 60.6662, kld: 0.1656\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 100.534729\n",
      "bce: 60.107285, kld: 0.161710\n",
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 99.582184\n",
      "bce: 59.947502, kld: 0.158539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 99.007584\n",
      "bce: 60.219666, kld: 0.155152\n",
      "====> Epoch: 48 Average loss: 99.8129, bce: 60.2323, kld: 0.1583\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 98.684845\n",
      "bce: 60.030239, kld: 0.154618\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 97.631271\n",
      "bce: 59.692902, kld: 0.151753\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 96.435333\n",
      "bce: 59.315544, kld: 0.148479\n",
      "====> Epoch: 49 Average loss: 97.6745, bce: 59.7953, kld: 0.1515\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 96.866180\n",
      "bce: 59.874908, kld: 0.147965\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 95.699219\n",
      "bce: 59.438412, kld: 0.145043\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 94.920326\n",
      "bce: 59.311211, kld: 0.142436\n",
      "====> Epoch: 50 Average loss: 95.6584, bce: 59.3692, kld: 0.1452\n",
      "====> Testing Average Loss: 41.58815196045799\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 94.576866\n",
      "bce: 59.153175, kld: 0.141695\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 93.623001\n",
      "bce: 58.877918, kld: 0.138980\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 92.973061\n",
      "bce: 58.872200, kld: 0.136403\n",
      "====> Epoch: 51 Average loss: 93.7392, bce: 58.9485, kld: 0.1392\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 92.369354\n",
      "bce: 58.368713, kld: 0.136003\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 91.975769\n",
      "bce: 58.583836, kld: 0.133568\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 90.950165\n",
      "bce: 58.228821, kld: 0.130885\n",
      "====> Epoch: 52 Average loss: 91.9184, bce: 58.5346, kld: 0.1335\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 91.153427\n",
      "bce: 58.462215, kld: 0.130765\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 90.211365\n",
      "bce: 58.169235, kld: 0.128169\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 89.323128\n",
      "bce: 57.877575, kld: 0.125782\n",
      "====> Epoch: 53 Average loss: 90.1866, bce: 58.1226, kld: 0.1283\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 89.657036\n",
      "bce: 58.309753, kld: 0.125389\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 88.335854\n",
      "bce: 57.487457, kld: 0.123394\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 87.864243\n",
      "bce: 57.549370, kld: 0.121259\n",
      "====> Epoch: 54 Average loss: 88.5311, bce: 57.7155, kld: 0.1233\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 87.765541\n",
      "bce: 57.573299, kld: 0.120769\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 87.342621\n",
      "bce: 57.727238, kld: 0.118462\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 86.133820\n",
      "bce: 57.027855, kld: 0.116424\n",
      "====> Epoch: 55 Average loss: 86.9583, bce: 57.3163, kld: 0.1186\n",
      "====> Testing Average Loss: 39.75615555518573\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 86.367760\n",
      "bce: 57.320450, kld: 0.116189\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 85.599594\n",
      "bce: 57.056290, kld: 0.114173\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 84.601593\n",
      "bce: 56.512280, kld: 0.112357\n",
      "====> Epoch: 56 Average loss: 85.4525, bce: 56.9184, kld: 0.1141\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 84.541260\n",
      "bce: 56.541473, kld: 0.111999\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 84.492371\n",
      "bce: 57.024849, kld: 0.109870\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 83.279327\n",
      "bce: 56.231567, kld: 0.108191\n",
      "====> Epoch: 57 Average loss: 84.0159, bce: 56.5286, kld: 0.1099\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 83.711731\n",
      "bce: 56.676414, kld: 0.108141\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 82.473679\n",
      "bce: 55.973503, kld: 0.106001\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 82.155365\n",
      "bce: 56.105171, kld: 0.104201\n",
      "====> Epoch: 58 Average loss: 82.6407, bce: 56.1472, kld: 0.1060\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 82.133286\n",
      "bce: 56.119148, kld: 0.104057\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 81.741089\n",
      "bce: 56.174011, kld: 0.102268\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 80.766663\n",
      "bce: 55.618671, kld: 0.100592\n",
      "====> Epoch: 59 Average loss: 81.3201, bce: 55.7639, kld: 0.1022\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 80.741722\n",
      "bce: 55.657951, kld: 0.100335\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 79.918030\n",
      "bce: 55.253258, kld: 0.098659\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 79.617889\n",
      "bce: 55.265255, kld: 0.097411\n",
      "====> Epoch: 60 Average loss: 80.0594, bce: 55.3903, kld: 0.0987\n",
      "====> Testing Average Loss: 38.06939717580882\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 79.006805\n",
      "bce: 54.872971, kld: 0.096535\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 79.163879\n",
      "bce: 55.278721, kld: 0.095541\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 78.215179\n",
      "bce: 54.764915, kld: 0.093801\n",
      "====> Epoch: 61 Average loss: 78.8398, bce: 55.0191, kld: 0.0953\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 78.047020\n",
      "bce: 54.721947, kld: 0.093300\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 77.598938\n",
      "bce: 54.597351, kld: 0.092006\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 77.603699\n",
      "bce: 54.926880, kld: 0.090707\n",
      "====> Epoch: 62 Average loss: 77.6699, bce: 54.6513, kld: 0.0921\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 77.076096\n",
      "bce: 54.475471, kld: 0.090403\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 76.667160\n",
      "bce: 54.409977, kld: 0.089029\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 76.204086\n",
      "bce: 54.262077, kld: 0.087768\n",
      "====> Epoch: 63 Average loss: 76.5456, bce: 54.2890, kld: 0.0890\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 75.716873\n",
      "bce: 53.838356, kld: 0.087514\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 75.229340\n",
      "bce: 53.725830, kld: 0.086014\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 75.637955\n",
      "bce: 54.422318, kld: 0.084863\n",
      "====> Epoch: 64 Average loss: 75.4653, bce: 53.9345, kld: 0.0861\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 75.128876\n",
      "bce: 54.000050, kld: 0.084515\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 74.536194\n",
      "bce: 53.707275, kld: 0.083316\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 73.962364\n",
      "bce: 53.410465, kld: 0.082208\n",
      "====> Epoch: 65 Average loss: 74.4161, bce: 53.5773, kld: 0.0834\n",
      "====> Testing Average Loss: 36.46634519371588\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 73.995621\n",
      "bce: 53.506401, kld: 0.081957\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 73.255035\n",
      "bce: 53.084755, kld: 0.080681\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 72.475136\n",
      "bce: 52.595856, kld: 0.079517\n",
      "====> Epoch: 66 Average loss: 73.4060, bce: 53.2273, kld: 0.0807\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 72.743698\n",
      "bce: 52.915573, kld: 0.079312\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 72.539452\n",
      "bce: 52.954506, kld: 0.078340\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 72.213577\n",
      "bce: 52.898029, kld: 0.077262\n",
      "====> Epoch: 67 Average loss: 72.4377, bce: 52.8877, kld: 0.0782\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 71.376022\n",
      "bce: 52.155838, kld: 0.076881\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 71.755814\n",
      "bce: 52.826797, kld: 0.075716\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 70.885834\n",
      "bce: 52.189705, kld: 0.074785\n",
      "====> Epoch: 68 Average loss: 71.4960, bce: 52.5460, kld: 0.0758\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 71.401535\n",
      "bce: 52.753429, kld: 0.074592\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 70.533836\n",
      "bce: 52.150810, kld: 0.073532\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 70.030655\n",
      "bce: 51.923882, kld: 0.072427\n",
      "====> Epoch: 69 Average loss: 70.5956, bce: 52.2166, kld: 0.0735\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 70.172325\n",
      "bce: 52.123154, kld: 0.072197\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 69.562943\n",
      "bce: 51.712494, kld: 0.071402\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 69.257599\n",
      "bce: 51.660122, kld: 0.070390\n",
      "====> Epoch: 70 Average loss: 69.7125, bce: 51.8831, kld: 0.0713\n",
      "====> Testing Average Loss: 34.995535714285715\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 69.678154\n",
      "bce: 52.129707, kld: 0.070194\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 68.918182\n",
      "bce: 51.619255, kld: 0.069196\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 68.055351\n",
      "bce: 50.990646, kld: 0.068259\n",
      "====> Epoch: 71 Average loss: 68.8642, bce: 51.5560, kld: 0.0692\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 68.385796\n",
      "bce: 51.367863, kld: 0.068072\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 68.026222\n",
      "bce: 51.239143, kld: 0.067148\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 68.147270\n",
      "bce: 51.568657, kld: 0.066314\n",
      "====> Epoch: 72 Average loss: 68.0372, bce: 51.2326, kld: 0.0672\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 67.168388\n",
      "bce: 50.588150, kld: 0.066321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 66.966919\n",
      "bce: 50.629105, kld: 0.065351\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 66.670425\n",
      "bce: 50.561241, kld: 0.064437\n",
      "====> Epoch: 73 Average loss: 67.2379, bce: 50.9128, kld: 0.0653\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 66.775887\n",
      "bce: 50.696686, kld: 0.064317\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 66.870270\n",
      "bce: 50.987957, kld: 0.063529\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 65.862770\n",
      "bce: 50.164581, kld: 0.062793\n",
      "====> Epoch: 74 Average loss: 66.4717, bce: 50.6055, kld: 0.0635\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 66.294975\n",
      "bce: 50.628113, kld: 0.062667\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 65.642014\n",
      "bce: 50.153740, kld: 0.061953\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 65.504326\n",
      "bce: 50.270065, kld: 0.060937\n",
      "====> Epoch: 75 Average loss: 65.7141, bce: 50.2913, kld: 0.0617\n",
      "====> Testing Average Loss: 33.61269929103981\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 65.685921\n",
      "bce: 50.458477, kld: 0.060910\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 64.896919\n",
      "bce: 49.942177, kld: 0.059819\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 65.091248\n",
      "bce: 50.274193, kld: 0.059268\n",
      "====> Epoch: 76 Average loss: 64.9851, bce: 49.9864, kld: 0.0600\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 64.565010\n",
      "bce: 49.795891, kld: 0.059076\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 64.821068\n",
      "bce: 50.236561, kld: 0.058338\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 64.187416\n",
      "bce: 49.766556, kld: 0.057683\n",
      "====> Epoch: 77 Average loss: 64.2754, bce: 49.6824, kld: 0.0584\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 63.589420\n",
      "bce: 49.183590, kld: 0.057623\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 63.415489\n",
      "bce: 49.241859, kld: 0.056695\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 63.031231\n",
      "bce: 49.003330, kld: 0.056112\n",
      "====> Epoch: 78 Average loss: 63.5897, bce: 49.3874, kld: 0.0568\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 63.582382\n",
      "bce: 49.555611, kld: 0.056107\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 62.873192\n",
      "bce: 49.043167, kld: 0.055320\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 62.495613\n",
      "bce: 48.800453, kld: 0.054781\n",
      "====> Epoch: 79 Average loss: 62.9205, bce: 49.0924, kld: 0.0553\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 62.439869\n",
      "bce: 48.798969, kld: 0.054564\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 61.766544\n",
      "bce: 48.318893, kld: 0.053791\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 61.995770\n",
      "bce: 48.691784, kld: 0.053216\n",
      "====> Epoch: 80 Average loss: 62.2651, bce: 48.7994, kld: 0.0539\n",
      "====> Testing Average Loss: 32.28826783217947\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 62.055351\n",
      "bce: 48.719963, kld: 0.053342\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 62.043663\n",
      "bce: 48.866165, kld: 0.052710\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 61.591057\n",
      "bce: 48.625637, kld: 0.051862\n",
      "====> Epoch: 81 Average loss: 61.6320, bce: 48.5120, kld: 0.0525\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 61.118317\n",
      "bce: 48.177929, kld: 0.051762\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 61.563057\n",
      "bce: 48.781475, kld: 0.051126\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 60.451424\n",
      "bce: 47.818058, kld: 0.050533\n",
      "====> Epoch: 82 Average loss: 61.0072, bce: 48.2233, kld: 0.0511\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 60.792252\n",
      "bce: 48.183029, kld: 0.050437\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 60.041229\n",
      "bce: 47.573959, kld: 0.049869\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 60.054840\n",
      "bce: 47.733803, kld: 0.049284\n",
      "====> Epoch: 83 Average loss: 60.4095, bce: 47.9452, kld: 0.0499\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 60.180473\n",
      "bce: 47.892700, kld: 0.049151\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 59.924721\n",
      "bce: 47.755943, kld: 0.048675\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 60.572830\n",
      "bce: 48.549004, kld: 0.048095\n",
      "====> Epoch: 84 Average loss: 59.8214, bce: 47.6666, kld: 0.0486\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 59.648270\n",
      "bce: 47.639050, kld: 0.048037\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 59.877617\n",
      "bce: 48.013390, kld: 0.047457\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 58.860912\n",
      "bce: 47.137634, kld: 0.046893\n",
      "====> Epoch: 85 Average loss: 59.2472, bce: 47.3926, kld: 0.0474\n",
      "====> Testing Average Loss: 31.10368646818\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 59.016926\n",
      "bce: 47.312820, kld: 0.046816\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 58.247673\n",
      "bce: 46.698433, kld: 0.046197\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 58.938461\n",
      "bce: 47.487358, kld: 0.045804\n",
      "====> Epoch: 86 Average loss: 58.6890, bce: 47.1235, kld: 0.0463\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 59.191803\n",
      "bce: 47.783375, kld: 0.045634\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 57.997906\n",
      "bce: 46.686249, kld: 0.045247\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 58.758587\n",
      "bce: 47.563652, kld: 0.044780\n",
      "====> Epoch: 87 Average loss: 58.1400, bce: 46.8516, kld: 0.0452\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 58.149876\n",
      "bce: 47.002483, kld: 0.044590\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 57.339600\n",
      "bce: 46.331371, kld: 0.044033\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 57.431160\n",
      "bce: 46.552048, kld: 0.043516\n",
      "====> Epoch: 88 Average loss: 57.5976, bce: 46.5796, kld: 0.0441\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 57.429539\n",
      "bce: 46.555244, kld: 0.043497\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 56.709412\n",
      "bce: 45.972157, kld: 0.042949\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 57.027126\n",
      "bce: 46.394012, kld: 0.042532\n",
      "====> Epoch: 89 Average loss: 57.0842, bce: 46.3248, kld: 0.0430\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 56.264511\n",
      "bce: 45.631706, kld: 0.042531\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 57.035408\n",
      "bce: 46.532616, kld: 0.042011\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 56.594513\n",
      "bce: 46.166901, kld: 0.041710\n",
      "====> Epoch: 90 Average loss: 56.5831, bce: 46.0737, kld: 0.0420\n",
      "====> Testing Average Loss: 29.941670965916657\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 56.228706\n",
      "bce: 45.851154, kld: 0.041510\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 56.373600\n",
      "bce: 46.150986, kld: 0.040890\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 55.799778\n",
      "bce: 45.628372, kld: 0.040686\n",
      "====> Epoch: 91 Average loss: 56.0763, bce: 45.8101, kld: 0.0411\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 55.048229\n",
      "bce: 44.927925, kld: 0.040481\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 55.446083\n",
      "bce: 45.405266, kld: 0.040163\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 54.903316\n",
      "bce: 45.006794, kld: 0.039586\n",
      "====> Epoch: 92 Average loss: 55.5938, bce: 45.5594, kld: 0.0401\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 55.001701\n",
      "bce: 45.108845, kld: 0.039571\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 55.704048\n",
      "bce: 45.920479, kld: 0.039134\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 54.921494\n",
      "bce: 45.195492, kld: 0.038904\n",
      "====> Epoch: 93 Average loss: 55.1121, bce: 45.3038, kld: 0.0392\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 55.212112\n",
      "bce: 45.499313, kld: 0.038851\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 55.084709\n",
      "bce: 45.469376, kld: 0.038461\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 54.736916\n",
      "bce: 45.252266, kld: 0.037939\n",
      "====> Epoch: 94 Average loss: 54.6463, bce: 45.0590, kld: 0.0383\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 54.715813\n",
      "bce: 45.242313, kld: 0.037894\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 53.862488\n",
      "bce: 44.509941, kld: 0.037410\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 53.645340\n",
      "bce: 44.362335, kld: 0.037132\n",
      "====> Epoch: 95 Average loss: 54.1937, bce: 44.8194, kld: 0.0375\n",
      "====> Testing Average Loss: 28.864152368193317\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 54.006943\n",
      "bce: 44.725471, kld: 0.037126\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 54.115513\n",
      "bce: 44.937828, kld: 0.036711\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 53.888905\n",
      "bce: 44.791306, kld: 0.036390\n",
      "====> Epoch: 96 Average loss: 53.7438, bce: 44.5743, kld: 0.0367\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 53.998119\n",
      "bce: 44.909187, kld: 0.036356\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 53.402153\n",
      "bce: 44.424740, kld: 0.035910\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 52.775906\n",
      "bce: 43.896088, kld: 0.035519\n",
      "====> Epoch: 97 Average loss: 53.3185, bce: 44.3456, kld: 0.0359\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 52.809227\n",
      "bce: 43.933853, kld: 0.035501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 53.428780\n",
      "bce: 44.649342, kld: 0.035118\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 52.473904\n",
      "bce: 43.772171, kld: 0.034807\n",
      "====> Epoch: 98 Average loss: 52.8793, bce: 44.1010, kld: 0.0351\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 52.584438\n",
      "bce: 43.907845, kld: 0.034706\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 52.193108\n",
      "bce: 43.587433, kld: 0.034423\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 52.803658\n",
      "bce: 44.289764, kld: 0.034056\n",
      "====> Epoch: 99 Average loss: 52.4579, bce: 43.8667, kld: 0.0344\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 51.915802\n",
      "bce: 43.424294, kld: 0.033966\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 52.198257\n",
      "bce: 43.776688, kld: 0.033686\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 51.736458\n",
      "bce: 43.427551, kld: 0.033236\n",
      "====> Epoch: 100 Average loss: 52.0466, bce: 43.6348, kld: 0.0336\n",
      "====> Testing Average Loss: 27.87789055219012\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 52.221905\n",
      "bce: 43.916622, kld: 0.033221\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 52.096291\n",
      "bce: 43.870632, kld: 0.032903\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 51.215431\n",
      "bce: 43.066505, kld: 0.032596\n",
      "====> Epoch: 101 Average loss: 51.6477, bce: 43.4121, kld: 0.0329\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 50.894085\n",
      "bce: 42.763748, kld: 0.032521\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 51.514179\n",
      "bce: 43.459671, kld: 0.032218\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 51.210171\n",
      "bce: 43.215778, kld: 0.031978\n",
      "====> Epoch: 102 Average loss: 51.2437, bce: 43.1791, kld: 0.0323\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 51.167576\n",
      "bce: 43.195724, kld: 0.031887\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 50.807262\n",
      "bce: 42.891148, kld: 0.031664\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 51.563316\n",
      "bce: 43.751282, kld: 0.031248\n",
      "====> Epoch: 103 Average loss: 50.8554, bce: 42.9537, kld: 0.0316\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 50.665939\n",
      "bce: 42.838554, kld: 0.031310\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 50.822105\n",
      "bce: 43.100464, kld: 0.030887\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 50.682648\n",
      "bce: 43.014351, kld: 0.030673\n",
      "====> Epoch: 104 Average loss: 50.4792, bce: 42.7388, kld: 0.0310\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 50.581944\n",
      "bce: 42.930168, kld: 0.030607\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 49.835571\n",
      "bce: 42.264923, kld: 0.030283\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 49.891640\n",
      "bce: 42.394958, kld: 0.029987\n",
      "====> Epoch: 105 Average loss: 50.1052, bce: 42.5215, kld: 0.0303\n",
      "====> Testing Average Loss: 26.89485421381973\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 49.910000\n",
      "bce: 42.429615, kld: 0.029922\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 49.771069\n",
      "bce: 42.341125, kld: 0.029720\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 49.510555\n",
      "bce: 42.129028, kld: 0.029526\n",
      "====> Epoch: 106 Average loss: 49.7378, bce: 42.3056, kld: 0.0297\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 49.300678\n",
      "bce: 41.931175, kld: 0.029478\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 49.615665\n",
      "bce: 42.340614, kld: 0.029100\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 48.690449\n",
      "bce: 41.457375, kld: 0.028932\n",
      "====> Epoch: 107 Average loss: 49.3720, bce: 42.0858, kld: 0.0291\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 49.005424\n",
      "bce: 41.786034, kld: 0.028878\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 49.007744\n",
      "bce: 41.873726, kld: 0.028536\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 48.960655\n",
      "bce: 41.869083, kld: 0.028366\n",
      "====> Epoch: 108 Average loss: 49.0104, bce: 41.8684, kld: 0.0286\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 48.678112\n",
      "bce: 41.594604, kld: 0.028334\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 48.154404\n",
      "bce: 41.141129, kld: 0.028053\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 48.664070\n",
      "bce: 41.707664, kld: 0.027826\n",
      "====> Epoch: 109 Average loss: 48.6635, bce: 41.6598, kld: 0.0280\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 48.108772\n",
      "bce: 41.177956, kld: 0.027723\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 48.068871\n",
      "bce: 41.195824, kld: 0.027492\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 47.880817\n",
      "bce: 41.084663, kld: 0.027185\n",
      "====> Epoch: 110 Average loss: 48.3201, bce: 41.4505, kld: 0.0275\n",
      "====> Testing Average Loss: 26.020619757688724\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 48.036263\n",
      "bce: 41.225170, kld: 0.027244\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 48.300671\n",
      "bce: 41.559113, kld: 0.026966\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 47.792564\n",
      "bce: 41.114017, kld: 0.026714\n",
      "====> Epoch: 111 Average loss: 47.9848, bce: 41.2482, kld: 0.0269\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 48.203388\n",
      "bce: 41.556141, kld: 0.026589\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 48.046589\n",
      "bce: 41.428703, kld: 0.026472\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 47.344292\n",
      "bce: 40.781418, kld: 0.026252\n",
      "====> Epoch: 112 Average loss: 47.6572, bce: 41.0466, kld: 0.0264\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 47.897423\n",
      "bce: 41.377998, kld: 0.026078\n",
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 47.496357\n",
      "bce: 41.006897, kld: 0.025958\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 47.377098\n",
      "bce: 40.943035, kld: 0.025736\n",
      "====> Epoch: 113 Average loss: 47.3335, bce: 40.8480, kld: 0.0259\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 47.768166\n",
      "bce: 41.369789, kld: 0.025594\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 46.346882\n",
      "bce: 39.997780, kld: 0.025396\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 47.054348\n",
      "bce: 40.753788, kld: 0.025202\n",
      "====> Epoch: 114 Average loss: 47.0151, bce: 40.6515, kld: 0.0255\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 46.807655\n",
      "bce: 40.505474, kld: 0.025209\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 46.727192\n",
      "bce: 40.484951, kld: 0.024969\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 46.612526\n",
      "bce: 40.417694, kld: 0.024779\n",
      "====> Epoch: 115 Average loss: 46.6980, bce: 40.4511, kld: 0.0250\n",
      "====> Testing Average Loss: 25.172167279656502\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 46.767380\n",
      "bce: 40.580360, kld: 0.024748\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 46.521286\n",
      "bce: 40.393227, kld: 0.024512\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 46.510475\n",
      "bce: 40.420361, kld: 0.024360\n",
      "====> Epoch: 116 Average loss: 46.3869, bce: 40.2550, kld: 0.0245\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 45.840519\n",
      "bce: 39.759186, kld: 0.024325\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 46.192146\n",
      "bce: 40.161350, kld: 0.024123\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 45.918472\n",
      "bce: 39.965267, kld: 0.023813\n",
      "====> Epoch: 117 Average loss: 46.0813, bce: 40.0605, kld: 0.0241\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 46.024979\n",
      "bce: 40.078415, kld: 0.023786\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 45.903385\n",
      "bce: 40.000763, kld: 0.023610\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 45.634106\n",
      "bce: 39.760612, kld: 0.023494\n",
      "====> Epoch: 118 Average loss: 45.7797, bce: 39.8679, kld: 0.0236\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 45.802055\n",
      "bce: 39.947647, kld: 0.023418\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 45.456535\n",
      "bce: 39.651848, kld: 0.023219\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 45.555912\n",
      "bce: 39.774017, kld: 0.023128\n",
      "====> Epoch: 119 Average loss: 45.4867, bce: 39.6800, kld: 0.0232\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 45.682259\n",
      "bce: 39.928020, kld: 0.023017\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 44.873909\n",
      "bce: 39.182091, kld: 0.022767\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 44.919895\n",
      "bce: 39.273125, kld: 0.022587\n",
      "====> Epoch: 120 Average loss: 45.2010, bce: 39.4976, kld: 0.0228\n",
      "====> Testing Average Loss: 24.42673661962455\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 45.055149\n",
      "bce: 39.400703, kld: 0.022618\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 45.058617\n",
      "bce: 39.451485, kld: 0.022429\n",
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 44.676079\n",
      "bce: 39.113140, kld: 0.022252\n",
      "====> Epoch: 121 Average loss: 44.9133, bce: 39.3118, kld: 0.0224\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 44.511066\n",
      "bce: 38.969639, kld: 0.022166\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 44.860641\n",
      "bce: 39.346725, kld: 0.022056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 44.503792\n",
      "bce: 39.048466, kld: 0.021821\n",
      "====> Epoch: 122 Average loss: 44.6360, bce: 39.1328, kld: 0.0220\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 43.767258\n",
      "bce: 38.306091, kld: 0.021845\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 44.199871\n",
      "bce: 38.790688, kld: 0.021637\n",
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 44.510792\n",
      "bce: 39.146782, kld: 0.021456\n",
      "====> Epoch: 123 Average loss: 44.3475, bce: 38.9401, kld: 0.0216\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 44.233582\n",
      "bce: 38.884583, kld: 0.021396\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 43.820999\n",
      "bce: 38.494194, kld: 0.021307\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 44.595127\n",
      "bce: 39.324554, kld: 0.021082\n",
      "====> Epoch: 124 Average loss: 44.0661, bce: 38.7517, kld: 0.0213\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 44.178341\n",
      "bce: 38.898933, kld: 0.021118\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 44.136707\n",
      "bce: 38.921959, kld: 0.020859\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 43.837528\n",
      "bce: 38.650124, kld: 0.020750\n",
      "====> Epoch: 125 Average loss: 43.8077, bce: 38.5835, kld: 0.0209\n",
      "====> Testing Average Loss: 23.764736719478098\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 44.333031\n",
      "bce: 39.151375, kld: 0.020727\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 43.150257\n",
      "bce: 37.997597, kld: 0.020611\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 43.382210\n",
      "bce: 38.262939, kld: 0.020477\n",
      "====> Epoch: 126 Average loss: 43.5458, bce: 38.4113, kld: 0.0205\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 43.545757\n",
      "bce: 38.470482, kld: 0.020301\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 43.774776\n",
      "bce: 38.725143, kld: 0.020199\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 43.384132\n",
      "bce: 38.375034, kld: 0.020036\n",
      "====> Epoch: 127 Average loss: 43.2765, bce: 38.2281, kld: 0.0202\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 42.968399\n",
      "bce: 37.960640, kld: 0.020031\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 42.987938\n",
      "bce: 38.038963, kld: 0.019796\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 43.332890\n",
      "bce: 38.391220, kld: 0.019767\n",
      "====> Epoch: 128 Average loss: 43.0297, bce: 38.0667, kld: 0.0199\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 42.460777\n",
      "bce: 37.543022, kld: 0.019671\n",
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 42.950352\n",
      "bce: 38.060661, kld: 0.019559\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 42.624393\n",
      "bce: 37.784622, kld: 0.019359\n",
      "====> Epoch: 129 Average loss: 42.7764, bce: 37.8956, kld: 0.0195\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 42.351532\n",
      "bce: 37.516792, kld: 0.019339\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 42.306404\n",
      "bce: 37.516273, kld: 0.019161\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 42.342308\n",
      "bce: 37.573830, kld: 0.019074\n",
      "====> Epoch: 130 Average loss: 42.5151, bce: 37.7157, kld: 0.0192\n",
      "====> Testing Average Loss: 22.954092851318066\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 42.867062\n",
      "bce: 38.109806, kld: 0.019029\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 42.683365\n",
      "bce: 37.960236, kld: 0.018893\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 42.633644\n",
      "bce: 37.932743, kld: 0.018804\n",
      "====> Epoch: 131 Average loss: 42.2783, bce: 37.5576, kld: 0.0189\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 42.243034\n",
      "bce: 37.549206, kld: 0.018775\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 41.376701\n",
      "bce: 36.732826, kld: 0.018575\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 42.281788\n",
      "bce: 37.659256, kld: 0.018490\n",
      "====> Epoch: 132 Average loss: 42.0315, bce: 37.3878, kld: 0.0186\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 42.006748\n",
      "bce: 37.406151, kld: 0.018402\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 41.848080\n",
      "bce: 37.279961, kld: 0.018272\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 42.176933\n",
      "bce: 37.634129, kld: 0.018171\n",
      "====> Epoch: 133 Average loss: 41.7957, bce: 37.2260, kld: 0.0183\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 42.049671\n",
      "bce: 37.518379, kld: 0.018125\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 40.993549\n",
      "bce: 36.503044, kld: 0.017962\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 41.894455\n",
      "bce: 37.427540, kld: 0.017868\n",
      "====> Epoch: 134 Average loss: 41.5535, bce: 37.0575, kld: 0.0180\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 41.050491\n",
      "bce: 36.592064, kld: 0.017834\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 41.640961\n",
      "bce: 37.216419, kld: 0.017698\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 41.183628\n",
      "bce: 36.795799, kld: 0.017551\n",
      "====> Epoch: 135 Average loss: 41.3243, bce: 36.9012, kld: 0.0177\n",
      "====> Testing Average Loss: 22.265959925442683\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 40.991596\n",
      "bce: 36.603523, kld: 0.017552\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 41.155750\n",
      "bce: 36.798367, kld: 0.017430\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 40.788670\n",
      "bce: 36.470749, kld: 0.017272\n",
      "====> Epoch: 136 Average loss: 41.0976, bce: 36.7446, kld: 0.0174\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 40.772369\n",
      "bce: 36.469131, kld: 0.017213\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 41.402325\n",
      "bce: 37.115166, kld: 0.017149\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 40.779816\n",
      "bce: 36.532234, kld: 0.016990\n",
      "====> Epoch: 137 Average loss: 40.8769, bce: 36.5910, kld: 0.0171\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 41.035496\n",
      "bce: 36.779755, kld: 0.017023\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 40.908493\n",
      "bce: 36.692596, kld: 0.016864\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 40.559242\n",
      "bce: 36.376286, kld: 0.016732\n",
      "====> Epoch: 138 Average loss: 40.6549, bce: 36.4365, kld: 0.0169\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 40.668488\n",
      "bce: 36.485733, kld: 0.016731\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 40.535294\n",
      "bce: 36.389008, kld: 0.016585\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 39.817139\n",
      "bce: 35.705132, kld: 0.016448\n",
      "====> Epoch: 139 Average loss: 40.4292, bce: 36.2770, kld: 0.0166\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 40.009781\n",
      "bce: 35.884594, kld: 0.016501\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 40.986401\n",
      "bce: 36.887680, kld: 0.016395\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 40.790668\n",
      "bce: 36.733204, kld: 0.016230\n",
      "====> Epoch: 140 Average loss: 40.2126, bce: 36.1257, kld: 0.0163\n",
      "====> Testing Average Loss: 21.626057823525496\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 40.722088\n",
      "bce: 36.653980, kld: 0.016272\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 39.315422\n",
      "bce: 35.279549, kld: 0.016143\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 40.441216\n",
      "bce: 36.441330, kld: 0.016000\n",
      "====> Epoch: 141 Average loss: 39.9996, bce: 35.9745, kld: 0.0161\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 40.006702\n",
      "bce: 36.018974, kld: 0.015951\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 40.400948\n",
      "bce: 36.431007, kld: 0.015880\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 39.777824\n",
      "bce: 35.847855, kld: 0.015720\n",
      "====> Epoch: 142 Average loss: 39.7864, bce: 35.8209, kld: 0.0159\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 39.666275\n",
      "bce: 35.746960, kld: 0.015677\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 39.972710\n",
      "bce: 36.069328, kld: 0.015614\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 39.776905\n",
      "bce: 35.893883, kld: 0.015532\n",
      "====> Epoch: 143 Average loss: 39.5784, bce: 35.6754, kld: 0.0156\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 39.330658\n",
      "bce: 35.449741, kld: 0.015524\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 38.906815\n",
      "bce: 35.069988, kld: 0.015347\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 39.387806\n",
      "bce: 35.559399, kld: 0.015314\n",
      "====> Epoch: 144 Average loss: 39.3657, bce: 35.5204, kld: 0.0154\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 38.745510\n",
      "bce: 34.929070, kld: 0.015266\n",
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 39.488461\n",
      "bce: 35.699104, kld: 0.015157\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 39.128082\n",
      "bce: 35.363686, kld: 0.015058\n",
      "====> Epoch: 145 Average loss: 39.1629, bce: 35.3754, kld: 0.0151\n",
      "====> Testing Average Loss: 21.095207237718014\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 39.094513\n",
      "bce: 35.338570, kld: 0.015024\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 38.935425\n",
      "bce: 35.195370, kld: 0.014960\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 38.418423\n",
      "bce: 34.725079, kld: 0.014773\n",
      "====> Epoch: 146 Average loss: 38.9662, bce: 35.2351, kld: 0.0149\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 39.613564\n",
      "bce: 35.915001, kld: 0.014794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 38.927452\n",
      "bce: 35.245533, kld: 0.014728\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 38.810001\n",
      "bce: 35.170357, kld: 0.014559\n",
      "====> Epoch: 147 Average loss: 38.7604, bce: 35.0849, kld: 0.0147\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 38.967827\n",
      "bce: 35.326698, kld: 0.014565\n",
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 38.797497\n",
      "bce: 35.172325, kld: 0.014501\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 38.484074\n",
      "bce: 34.892620, kld: 0.014366\n",
      "====> Epoch: 148 Average loss: 38.5683, bce: 34.9470, kld: 0.0145\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 38.596317\n",
      "bce: 34.998543, kld: 0.014391\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 38.338326\n",
      "bce: 34.760052, kld: 0.014313\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 38.522717\n",
      "bce: 34.977219, kld: 0.014182\n",
      "====> Epoch: 149 Average loss: 38.3747, bce: 34.8070, kld: 0.0143\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 38.448257\n",
      "bce: 34.915955, kld: 0.014129\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 38.070145\n",
      "bce: 34.569595, kld: 0.014002\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 37.981724\n",
      "bce: 34.485012, kld: 0.013987\n",
      "====> Epoch: 150 Average loss: 38.1835, bce: 34.6671, kld: 0.0141\n",
      "====> Testing Average Loss: 20.446160735088537\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 37.557346\n",
      "bce: 34.079716, kld: 0.013911\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 38.403271\n",
      "bce: 34.934082, kld: 0.013877\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 38.199234\n",
      "bce: 34.766228, kld: 0.013732\n",
      "====> Epoch: 151 Average loss: 38.0114, bce: 34.5446, kld: 0.0139\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 38.160450\n",
      "bce: 34.724533, kld: 0.013744\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 38.022327\n",
      "bce: 34.596443, kld: 0.013704\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 37.525448\n",
      "bce: 34.125393, kld: 0.013600\n",
      "====> Epoch: 152 Average loss: 37.8208, bce: 34.4035, kld: 0.0137\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 37.941990\n",
      "bce: 34.545197, kld: 0.013587\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 37.345043\n",
      "bce: 33.976959, kld: 0.013472\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 37.415787\n",
      "bce: 34.070335, kld: 0.013382\n",
      "====> Epoch: 153 Average loss: 37.6359, bce: 34.2665, kld: 0.0135\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 37.437778\n",
      "bce: 34.096054, kld: 0.013367\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 37.379646\n",
      "bce: 34.055546, kld: 0.013296\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 37.052269\n",
      "bce: 33.748295, kld: 0.013216\n",
      "====> Epoch: 154 Average loss: 37.4449, bce: 34.1239, kld: 0.0133\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 37.122635\n",
      "bce: 33.831524, kld: 0.013164\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 37.389893\n",
      "bce: 34.101562, kld: 0.013153\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 36.629528\n",
      "bce: 33.376465, kld: 0.013012\n",
      "====> Epoch: 155 Average loss: 37.2558, bce: 33.9830, kld: 0.0131\n",
      "====> Testing Average Loss: 19.853388987817866\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 36.838169\n",
      "bce: 33.584496, kld: 0.013015\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 37.178661\n",
      "bce: 33.942356, kld: 0.012945\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 37.031345\n",
      "bce: 33.824036, kld: 0.012829\n",
      "====> Epoch: 156 Average loss: 37.0786, bce: 33.8510, kld: 0.0129\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 36.548492\n",
      "bce: 33.344597, kld: 0.012816\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 37.049084\n",
      "bce: 33.859261, kld: 0.012759\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 36.252239\n",
      "bce: 33.090118, kld: 0.012648\n",
      "====> Epoch: 157 Average loss: 36.9088, bce: 33.7263, kld: 0.0127\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 36.745613\n",
      "bce: 33.580044, kld: 0.012662\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 36.947002\n",
      "bce: 33.791813, kld: 0.012621\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 36.402138\n",
      "bce: 33.286194, kld: 0.012464\n",
      "====> Epoch: 158 Average loss: 36.7427, bce: 33.6050, kld: 0.0126\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 36.469738\n",
      "bce: 33.346710, kld: 0.012492\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 36.701000\n",
      "bce: 33.607113, kld: 0.012376\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 36.361912\n",
      "bce: 33.277561, kld: 0.012337\n",
      "====> Epoch: 159 Average loss: 36.5663, bce: 33.4692, kld: 0.0124\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 36.438862\n",
      "bce: 33.370033, kld: 0.012275\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 36.443470\n",
      "bce: 33.366325, kld: 0.012309\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 36.260410\n",
      "bce: 33.236168, kld: 0.012097\n",
      "====> Epoch: 160 Average loss: 36.4063, bce: 33.3497, kld: 0.0122\n",
      "====> Testing Average Loss: 19.45610864482093\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 35.818146\n",
      "bce: 32.792030, kld: 0.012104\n",
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 36.135490\n",
      "bce: 33.121986, kld: 0.012054\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 35.937462\n",
      "bce: 32.939411, kld: 0.011992\n",
      "====> Epoch: 161 Average loss: 36.2430, bce: 33.2294, kld: 0.0121\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 36.004288\n",
      "bce: 33.019444, kld: 0.011939\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 35.542141\n",
      "bce: 32.562973, kld: 0.011917\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 36.272362\n",
      "bce: 33.308987, kld: 0.011854\n",
      "====> Epoch: 162 Average loss: 36.0796, bce: 33.1061, kld: 0.0119\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 35.805431\n",
      "bce: 32.859406, kld: 0.011784\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 36.531677\n",
      "bce: 33.595074, kld: 0.011746\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 36.174141\n",
      "bce: 33.256958, kld: 0.011669\n",
      "====> Epoch: 163 Average loss: 35.9038, bce: 32.9700, kld: 0.0117\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 36.120564\n",
      "bce: 33.194401, kld: 0.011705\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 35.977951\n",
      "bce: 33.081009, kld: 0.011588\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 35.897427\n",
      "bce: 33.027374, kld: 0.011480\n",
      "====> Epoch: 164 Average loss: 35.7438, bce: 32.8506, kld: 0.0116\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 35.568916\n",
      "bce: 32.697552, kld: 0.011485\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 35.874756\n",
      "bce: 33.029686, kld: 0.011380\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 35.965752\n",
      "bce: 33.119263, kld: 0.011386\n",
      "====> Epoch: 165 Average loss: 35.5833, bce: 32.7282, kld: 0.0114\n",
      "====> Testing Average Loss: 19.015575073225936\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 35.375690\n",
      "bce: 32.536167, kld: 0.011358\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 35.780994\n",
      "bce: 32.961769, kld: 0.011277\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 34.944092\n",
      "bce: 32.143219, kld: 0.011203\n",
      "====> Epoch: 166 Average loss: 35.4214, bce: 32.6037, kld: 0.0113\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 35.348671\n",
      "bce: 32.550560, kld: 0.011192\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 34.694065\n",
      "bce: 31.922695, kld: 0.011085\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 35.169071\n",
      "bce: 32.403114, kld: 0.011064\n",
      "====> Epoch: 167 Average loss: 35.2725, bce: 32.4911, kld: 0.0111\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 35.345470\n",
      "bce: 32.587570, kld: 0.011032\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 34.986954\n",
      "bce: 32.234962, kld: 0.011008\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 35.266254\n",
      "bce: 32.538143, kld: 0.010912\n",
      "====> Epoch: 168 Average loss: 35.1162, bce: 32.3724, kld: 0.0110\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 35.437805\n",
      "bce: 32.713707, kld: 0.010896\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 34.998795\n",
      "bce: 32.277832, kld: 0.010884\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 34.801140\n",
      "bce: 32.119282, kld: 0.010727\n",
      "====> Epoch: 169 Average loss: 34.9527, bce: 32.2440, kld: 0.0108\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 34.792713\n",
      "bce: 32.114014, kld: 0.010715\n",
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 34.827507\n",
      "bce: 32.152290, kld: 0.010701\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 34.666889\n",
      "bce: 32.012920, kld: 0.010616\n",
      "====> Epoch: 170 Average loss: 34.8108, bce: 32.1368, kld: 0.0107\n",
      "====> Testing Average Loss: 18.546214510384768\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 35.255043\n",
      "bce: 32.598881, kld: 0.010625\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 34.299839\n",
      "bce: 31.661156, kld: 0.010555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 34.907192\n",
      "bce: 32.277817, kld: 0.010517\n",
      "====> Epoch: 171 Average loss: 34.6583, bce: 32.0187, kld: 0.0106\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 34.874031\n",
      "bce: 32.261375, kld: 0.010451\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 34.676193\n",
      "bce: 32.075596, kld: 0.010402\n",
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 34.857159\n",
      "bce: 32.270908, kld: 0.010345\n",
      "====> Epoch: 172 Average loss: 34.5078, bce: 31.9028, kld: 0.0104\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 34.212997\n",
      "bce: 31.619892, kld: 0.010372\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 34.438667\n",
      "bce: 31.869186, kld: 0.010278\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 33.566734\n",
      "bce: 31.000622, kld: 0.010264\n",
      "====> Epoch: 173 Average loss: 34.3715, bce: 31.7994, kld: 0.0103\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 34.150616\n",
      "bce: 31.612923, kld: 0.010151\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 33.838184\n",
      "bce: 31.288006, kld: 0.010201\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 34.394646\n",
      "bce: 31.866505, kld: 0.010113\n",
      "====> Epoch: 174 Average loss: 34.2313, bce: 31.6899, kld: 0.0102\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 33.535351\n",
      "bce: 31.000462, kld: 0.010140\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 34.041016\n",
      "bce: 31.516029, kld: 0.010100\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 34.026821\n",
      "bce: 31.540648, kld: 0.009945\n",
      "====> Epoch: 175 Average loss: 34.0749, bce: 31.5636, kld: 0.0100\n",
      "====> Testing Average Loss: 18.105508795433366\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 33.633541\n",
      "bce: 31.130554, kld: 0.010012\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 33.931160\n",
      "bce: 31.448231, kld: 0.009932\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 34.414124\n",
      "bce: 31.933456, kld: 0.009923\n",
      "====> Epoch: 176 Average loss: 33.9377, bce: 31.4579, kld: 0.0099\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 33.934559\n",
      "bce: 31.470669, kld: 0.009856\n",
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 34.278984\n",
      "bce: 31.826000, kld: 0.009812\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 33.303185\n",
      "bce: 30.875780, kld: 0.009710\n",
      "====> Epoch: 177 Average loss: 33.8027, bce: 31.3564, kld: 0.0098\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 33.590595\n",
      "bce: 31.174160, kld: 0.009666\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 33.768158\n",
      "bce: 31.347122, kld: 0.009684\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 32.985016\n",
      "bce: 30.585972, kld: 0.009596\n",
      "====> Epoch: 178 Average loss: 33.6526, bce: 31.2361, kld: 0.0097\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 33.495842\n",
      "bce: 31.094742, kld: 0.009604\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 33.486187\n",
      "bce: 31.069492, kld: 0.009667\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 33.063435\n",
      "bce: 30.688290, kld: 0.009501\n",
      "====> Epoch: 179 Average loss: 33.5214, bce: 31.1338, kld: 0.0096\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 33.535927\n",
      "bce: 31.153887, kld: 0.009528\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 33.571976\n",
      "bce: 31.217598, kld: 0.009418\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 33.298058\n",
      "bce: 30.954464, kld: 0.009374\n",
      "====> Epoch: 180 Average loss: 33.3784, bce: 31.0200, kld: 0.0094\n",
      "====> Testing Average Loss: 17.637721966116363\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 33.672722\n",
      "bce: 31.341923, kld: 0.009323\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 32.466682\n",
      "bce: 30.145546, kld: 0.009285\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 33.255886\n",
      "bce: 30.940405, kld: 0.009262\n",
      "====> Epoch: 181 Average loss: 33.2571, bce: 30.9255, kld: 0.0093\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 33.041763\n",
      "bce: 30.720724, kld: 0.009284\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 32.776226\n",
      "bce: 30.485796, kld: 0.009162\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 33.225826\n",
      "bce: 30.942644, kld: 0.009133\n",
      "====> Epoch: 182 Average loss: 33.1172, bce: 30.8151, kld: 0.0092\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 32.927860\n",
      "bce: 30.646446, kld: 0.009126\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 32.550465\n",
      "bce: 30.278582, kld: 0.009088\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 33.219917\n",
      "bce: 30.958286, kld: 0.009047\n",
      "====> Epoch: 183 Average loss: 32.9837, bce: 30.7097, kld: 0.0091\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 32.583660\n",
      "bce: 30.327839, kld: 0.009023\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 33.527004\n",
      "bce: 31.286825, kld: 0.008961\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 32.788750\n",
      "bce: 30.553400, kld: 0.008941\n",
      "====> Epoch: 184 Average loss: 32.8651, bce: 30.6162, kld: 0.0090\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 32.596611\n",
      "bce: 30.349501, kld: 0.008988\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 32.461647\n",
      "bce: 30.239479, kld: 0.008889\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 32.325912\n",
      "bce: 30.126207, kld: 0.008799\n",
      "====> Epoch: 185 Average loss: 32.7401, bce: 30.5165, kld: 0.0089\n",
      "====> Testing Average Loss: 17.125242872953002\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 32.971897\n",
      "bce: 30.767235, kld: 0.008819\n",
      "Train Epoch: 186 [10240/22533 (45%)]      Loss: 31.704041\n",
      "bce: 29.503891, kld: 0.008801\n",
      "Train Epoch: 186 [20480/22533 (91%)]      Loss: 32.654392\n",
      "bce: 30.471306, kld: 0.008732\n",
      "====> Epoch: 186 Average loss: 32.5904, bce: 30.3967, kld: 0.0088\n",
      "Train Epoch: 187 [   0/22533 ( 0%)]      Loss: 32.937508\n",
      "bce: 30.751202, kld: 0.008745\n",
      "Train Epoch: 187 [10240/22533 (45%)]      Loss: 32.836773\n",
      "bce: 30.677113, kld: 0.008639\n",
      "Train Epoch: 187 [20480/22533 (91%)]      Loss: 32.244385\n",
      "bce: 30.087822, kld: 0.008626\n",
      "====> Epoch: 187 Average loss: 32.4685, bce: 30.3001, kld: 0.0087\n",
      "Train Epoch: 188 [   0/22533 ( 0%)]      Loss: 32.397293\n",
      "bce: 30.243193, kld: 0.008616\n",
      "Train Epoch: 188 [10240/22533 (45%)]      Loss: 31.790869\n",
      "bce: 29.664930, kld: 0.008504\n",
      "Train Epoch: 188 [20480/22533 (91%)]      Loss: 32.981014\n",
      "bce: 30.847404, kld: 0.008534\n",
      "====> Epoch: 188 Average loss: 32.3755, bce: 30.2288, kld: 0.0086\n",
      "Train Epoch: 189 [   0/22533 ( 0%)]      Loss: 32.022778\n",
      "bce: 29.893147, kld: 0.008519\n",
      "Train Epoch: 189 [10240/22533 (45%)]      Loss: 32.156315\n",
      "bce: 30.013245, kld: 0.008572\n",
      "Train Epoch: 189 [20480/22533 (91%)]      Loss: 32.125839\n",
      "bce: 29.998684, kld: 0.008509\n",
      "====> Epoch: 189 Average loss: 32.2262, bce: 30.1059, kld: 0.0085\n",
      "Train Epoch: 190 [   0/22533 ( 0%)]      Loss: 32.307404\n",
      "bce: 30.181313, kld: 0.008504\n",
      "Train Epoch: 190 [10240/22533 (45%)]      Loss: 32.572586\n",
      "bce: 30.475830, kld: 0.008387\n",
      "Train Epoch: 190 [20480/22533 (91%)]      Loss: 32.134449\n",
      "bce: 30.034401, kld: 0.008400\n",
      "====> Epoch: 190 Average loss: 32.1233, bce: 30.0270, kld: 0.0084\n",
      "====> Testing Average Loss: 16.885244870023964\n",
      "Train Epoch: 191 [   0/22533 ( 0%)]      Loss: 32.499687\n",
      "bce: 30.422092, kld: 0.008310\n",
      "Train Epoch: 191 [10240/22533 (45%)]      Loss: 32.472691\n",
      "bce: 30.391085, kld: 0.008326\n",
      "Train Epoch: 191 [20480/22533 (91%)]      Loss: 32.004971\n",
      "bce: 29.948277, kld: 0.008227\n",
      "====> Epoch: 191 Average loss: 31.9840, bce: 29.9156, kld: 0.0083\n",
      "Train Epoch: 192 [   0/22533 ( 0%)]      Loss: 31.833025\n",
      "bce: 29.782391, kld: 0.008203\n",
      "Train Epoch: 192 [10240/22533 (45%)]      Loss: 31.660528\n",
      "bce: 29.599062, kld: 0.008246\n",
      "Train Epoch: 192 [20480/22533 (91%)]      Loss: 31.926823\n",
      "bce: 29.897869, kld: 0.008116\n",
      "====> Epoch: 192 Average loss: 31.8786, bce: 29.8328, kld: 0.0082\n",
      "Train Epoch: 193 [   0/22533 ( 0%)]      Loss: 31.668211\n",
      "bce: 29.636614, kld: 0.008126\n",
      "Train Epoch: 193 [10240/22533 (45%)]      Loss: 31.886135\n",
      "bce: 29.875484, kld: 0.008043\n",
      "Train Epoch: 193 [20480/22533 (91%)]      Loss: 31.900721\n",
      "bce: 29.887379, kld: 0.008053\n",
      "====> Epoch: 193 Average loss: 31.7564, bce: 29.7368, kld: 0.0081\n",
      "Train Epoch: 194 [   0/22533 ( 0%)]      Loss: 31.808422\n",
      "bce: 29.801796, kld: 0.008027\n",
      "Train Epoch: 194 [10240/22533 (45%)]      Loss: 31.594913\n",
      "bce: 29.600451, kld: 0.007978\n",
      "Train Epoch: 194 [20480/22533 (91%)]      Loss: 31.838232\n",
      "bce: 29.836567, kld: 0.008007\n",
      "====> Epoch: 194 Average loss: 31.6453, bce: 29.6492, kld: 0.0080\n",
      "Train Epoch: 195 [   0/22533 ( 0%)]      Loss: 31.274107\n",
      "bce: 29.299213, kld: 0.007900\n",
      "Train Epoch: 195 [10240/22533 (45%)]      Loss: 31.853586\n",
      "bce: 29.865992, kld: 0.007950\n",
      "Train Epoch: 195 [20480/22533 (91%)]      Loss: 31.649956\n",
      "bce: 29.696907, kld: 0.007812\n",
      "====> Epoch: 195 Average loss: 31.5208, bce: 29.5479, kld: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Testing Average Loss: 16.44215671182266\n",
      "Train Epoch: 196 [   0/22533 ( 0%)]      Loss: 31.126793\n",
      "bce: 29.174330, kld: 0.007810\n",
      "Train Epoch: 196 [10240/22533 (45%)]      Loss: 31.739449\n",
      "bce: 29.782480, kld: 0.007828\n",
      "Train Epoch: 196 [20480/22533 (91%)]      Loss: 31.230747\n",
      "bce: 29.272327, kld: 0.007834\n",
      "====> Epoch: 196 Average loss: 31.4204, bce: 29.4533, kld: 0.0079\n",
      "Train Epoch: 197 [   0/22533 ( 0%)]      Loss: 31.689806\n",
      "bce: 29.654402, kld: 0.008142\n",
      "Train Epoch: 197 [10240/22533 (45%)]      Loss: 31.603790\n",
      "bce: 29.651241, kld: 0.007810\n",
      "Train Epoch: 197 [20480/22533 (91%)]      Loss: 30.697536\n",
      "bce: 28.756966, kld: 0.007762\n",
      "====> Epoch: 197 Average loss: 31.3359, bce: 29.3669, kld: 0.0079\n",
      "Train Epoch: 198 [   0/22533 ( 0%)]      Loss: 31.655815\n",
      "bce: 29.730576, kld: 0.007701\n",
      "Train Epoch: 198 [10240/22533 (45%)]      Loss: 31.420824\n",
      "bce: 29.510983, kld: 0.007639\n",
      "Train Epoch: 198 [20480/22533 (91%)]      Loss: 30.728300\n",
      "bce: 28.831459, kld: 0.007587\n",
      "====> Epoch: 198 Average loss: 31.2012, bce: 29.2841, kld: 0.0077\n",
      "Train Epoch: 199 [   0/22533 ( 0%)]      Loss: 31.041716\n",
      "bce: 29.140905, kld: 0.007603\n",
      "Train Epoch: 199 [10240/22533 (45%)]      Loss: 31.319397\n",
      "bce: 29.454906, kld: 0.007458\n",
      "Train Epoch: 199 [20480/22533 (91%)]      Loss: 30.935139\n",
      "bce: 29.067730, kld: 0.007470\n",
      "====> Epoch: 199 Average loss: 31.0602, bce: 29.1757, kld: 0.0075\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=250,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
