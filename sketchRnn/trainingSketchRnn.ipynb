{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 133.897964\n",
      "bce: 105.559753, kld: 56.676426\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 118.909401\n",
      "bce: 102.640007, kld: 32.538784\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 115.179604\n",
      "bce: 100.503799, kld: 29.351603\n",
      "====> Epoch: 0 Average loss: 120.2152, bce: 102.7920, kld: 34.8464\n",
      "====> Testing Average Loss: 81.17565487285314\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 114.439400\n",
      "bce: 99.964485, kld: 28.949827\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 111.391808\n",
      "bce: 97.407761, kld: 27.968100\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 109.863930\n",
      "bce: 96.264114, kld: 27.199633\n",
      "====> Epoch: 1 Average loss: 111.8336, bce: 97.8167, kld: 28.0337\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 109.592331\n",
      "bce: 96.111221, kld: 26.962215\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 108.283768\n",
      "bce: 95.419861, kld: 25.727819\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 106.452126\n",
      "bce: 94.149796, kld: 24.604658\n",
      "====> Epoch: 2 Average loss: 107.9901, bce: 95.1186, kld: 25.7430\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 106.491112\n",
      "bce: 94.280518, kld: 24.421190\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 105.466606\n",
      "bce: 93.626816, kld: 23.679577\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 104.508904\n",
      "bce: 92.997940, kld: 23.021931\n",
      "====> Epoch: 3 Average loss: 105.5010, bce: 93.6612, kld: 23.6795\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 104.474098\n",
      "bce: 93.047638, kld: 22.852921\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 103.331879\n",
      "bce: 92.273346, kld: 22.117062\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 102.895653\n",
      "bce: 92.263542, kld: 21.264221\n",
      "====> Epoch: 4 Average loss: 103.5767, bce: 92.5320, kld: 22.0894\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 102.313286\n",
      "bce: 91.763618, kld: 21.099333\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 102.197151\n",
      "bce: 92.033737, kld: 20.326822\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 100.784729\n",
      "bce: 91.060562, kld: 19.448326\n",
      "====> Epoch: 5 Average loss: 101.6672, bce: 91.5168, kld: 20.3009\n",
      "====> Testing Average Loss: 73.49281678538144\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 100.762695\n",
      "bce: 91.132179, kld: 19.261034\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 99.656601\n",
      "bce: 90.456696, kld: 18.399803\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 99.077332\n",
      "bce: 90.323906, kld: 17.506851\n",
      "====> Epoch: 6 Average loss: 99.7126, bce: 90.5214, kld: 18.3825\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 98.561012\n",
      "bce: 89.911484, kld: 17.299053\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 97.612946\n",
      "bce: 89.445625, kld: 16.334644\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 96.389748\n",
      "bce: 88.665634, kld: 15.448222\n",
      "====> Epoch: 7 Average loss: 97.6257, bce: 89.4493, kld: 16.3528\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 96.096069\n",
      "bce: 88.472435, kld: 15.247276\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 95.438797\n",
      "bce: 88.293533, kld: 14.290534\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 94.158470\n",
      "bce: 87.483673, kld: 13.349591\n",
      "====> Epoch: 8 Average loss: 95.3232, bce: 88.1854, kld: 14.2756\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 94.291428\n",
      "bce: 87.718430, kld: 13.145994\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 92.996780\n",
      "bce: 86.913857, kld: 12.165854\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 91.559425\n",
      "bce: 85.903183, kld: 11.312488\n",
      "====> Epoch: 9 Average loss: 92.8188, bce: 86.7178, kld: 12.2018\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 91.077431\n",
      "bce: 85.508606, kld: 11.137650\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 89.900818\n",
      "bce: 84.801125, kld: 10.199388\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 88.956841\n",
      "bce: 84.248413, kld: 9.416850\n",
      "====> Epoch: 10 Average loss: 89.9564, bce: 84.8369, kld: 10.2390\n",
      "====> Testing Average Loss: 65.60721774730395\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 88.267540\n",
      "bce: 83.633156, kld: 9.268767\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 86.905823\n",
      "bce: 82.647141, kld: 8.517365\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 85.522072\n",
      "bce: 81.635445, kld: 7.773261\n",
      "====> Epoch: 11 Average loss: 86.8833, bce: 82.6257, kld: 8.5152\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 85.082390\n",
      "bce: 81.257141, kld: 7.650491\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 84.753822\n",
      "bce: 81.226898, kld: 7.053848\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 83.465561\n",
      "bce: 80.233200, kld: 6.464714\n",
      "====> Epoch: 12 Average loss: 84.2686, bce: 80.7447, kld: 7.0480\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 83.145058\n",
      "bce: 79.971512, kld: 6.347091\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 82.590317\n",
      "bce: 79.679039, kld: 5.822553\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 81.890114\n",
      "bce: 79.214249, kld: 5.351725\n",
      "====> Epoch: 13 Average loss: 82.2656, bce: 79.3472, kld: 5.8368\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 81.157593\n",
      "bce: 78.517418, kld: 5.280346\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 80.904915\n",
      "bce: 78.466675, kld: 4.876485\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 80.277153\n",
      "bce: 78.010956, kld: 4.532399\n",
      "====> Epoch: 14 Average loss: 80.7067, bce: 78.2620, kld: 4.8893\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 80.158806\n",
      "bce: 77.925812, kld: 4.465982\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 79.171867\n",
      "bce: 77.086403, kld: 4.170933\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 78.861862\n",
      "bce: 76.906876, kld: 3.909981\n",
      "====> Epoch: 15 Average loss: 79.4414, bce: 77.3533, kld: 4.1761\n",
      "====> Testing Average Loss: 57.39210408068167\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 78.720627\n",
      "bce: 76.791428, kld: 3.858404\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 78.440376\n",
      "bce: 76.627205, kld: 3.626341\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 77.910454\n",
      "bce: 76.212410, kld: 3.396082\n",
      "====> Epoch: 16 Average loss: 78.3280, bce: 76.5168, kld: 3.6222\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 77.883583\n",
      "bce: 76.204002, kld: 3.359168\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 77.794144\n",
      "bce: 76.213104, kld: 3.162071\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 77.255623\n",
      "bce: 75.761261, kld: 2.988721\n",
      "====> Epoch: 17 Average loss: 77.3383, bce: 75.7529, kld: 3.1708\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 76.662300\n",
      "bce: 75.181885, kld: 2.960829\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 76.320404\n",
      "bce: 74.919098, kld: 2.802607\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 76.442009\n",
      "bce: 75.114326, kld: 2.655359\n",
      "====> Epoch: 18 Average loss: 76.4257, bce: 75.0243, kld: 2.8028\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 75.548294\n",
      "bce: 74.235016, kld: 2.626549\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 75.497673\n",
      "bce: 74.247025, kld: 2.501295\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 75.370903\n",
      "bce: 74.185257, kld: 2.371297\n",
      "====> Epoch: 19 Average loss: 75.5731, bce: 74.3246, kld: 2.4968\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 75.598755\n",
      "bce: 74.423294, kld: 2.350923\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 74.735260\n",
      "bce: 73.612152, kld: 2.246223\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 74.176567\n",
      "bce: 73.106094, kld: 2.140944\n",
      "====> Epoch: 20 Average loss: 74.7561, bce: 73.6342, kld: 2.2438\n",
      "====> Testing Average Loss: 53.81926715816802\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 73.822083\n",
      "bce: 72.759048, kld: 2.126063\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 74.348900\n",
      "bce: 73.331177, kld: 2.035440\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 73.571014\n",
      "bce: 72.598076, kld: 1.945881\n",
      "====> Epoch: 21 Average loss: 73.9853, bce: 72.9681, kld: 2.0342\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 73.647224\n",
      "bce: 72.682724, kld: 1.929000\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 73.707314\n",
      "bce: 72.782913, kld: 1.848796\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 72.897919\n",
      "bce: 72.012848, kld: 1.770148\n",
      "====> Epoch: 22 Average loss: 73.2489, bce: 72.3253, kld: 1.8471\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 72.999199\n",
      "bce: 72.119644, kld: 1.759109\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 72.588905\n",
      "bce: 71.740059, kld: 1.697687\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 72.369484\n",
      "bce: 71.560020, kld: 1.618927\n",
      "====> Epoch: 23 Average loss: 72.5290, bce: 71.6828, kld: 1.6923\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 72.486740\n",
      "bce: 71.681137, kld: 1.611211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 71.510033\n",
      "bce: 70.729584, kld: 1.560898\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 71.614059\n",
      "bce: 70.867775, kld: 1.492564\n",
      "====> Epoch: 24 Average loss: 71.8410, bce: 71.0630, kld: 1.5559\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 71.447144\n",
      "bce: 70.705582, kld: 1.483119\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 70.985107\n",
      "bce: 70.268303, kld: 1.433608\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 70.647415\n",
      "bce: 69.952972, kld: 1.388890\n",
      "====> Epoch: 25 Average loss: 71.1726, bce: 70.4556, kld: 1.4339\n",
      "====> Testing Average Loss: 50.92928288510185\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 70.688133\n",
      "bce: 69.998322, kld: 1.379623\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 70.769867\n",
      "bce: 70.101395, kld: 1.336946\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 70.105392\n",
      "bce: 69.453285, kld: 1.304218\n",
      "====> Epoch: 26 Average loss: 70.5122, bce: 69.8424, kld: 1.3397\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 70.398766\n",
      "bce: 69.752884, kld: 1.291770\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 69.905380\n",
      "bce: 69.279167, kld: 1.252429\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 69.613327\n",
      "bce: 69.006371, kld: 1.213913\n",
      "====> Epoch: 27 Average loss: 69.8601, bce: 69.2337, kld: 1.2529\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 69.339622\n",
      "bce: 68.738792, kld: 1.201662\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 69.680382\n",
      "bce: 69.089767, kld: 1.181230\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 68.687012\n",
      "bce: 68.109993, kld: 1.154033\n",
      "====> Epoch: 28 Average loss: 69.2311, bce: 68.6398, kld: 1.1825\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 68.465302\n",
      "bce: 67.892395, kld: 1.145819\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 68.452789\n",
      "bce: 67.897812, kld: 1.109959\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 68.802689\n",
      "bce: 68.258018, kld: 1.089347\n",
      "====> Epoch: 29 Average loss: 68.6044, bce: 68.0472, kld: 1.1143\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 68.654503\n",
      "bce: 68.120880, kld: 1.067244\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 67.978195\n",
      "bce: 67.451843, kld: 1.052705\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 67.868164\n",
      "bce: 67.352707, kld: 1.030920\n",
      "====> Epoch: 30 Average loss: 68.0031, bce: 67.4735, kld: 1.0593\n",
      "====> Testing Average Loss: 48.33336523099454\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 67.409775\n",
      "bce: 66.902328, kld: 1.014887\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 67.249359\n",
      "bce: 66.748894, kld: 1.000931\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 66.816406\n",
      "bce: 66.308762, kld: 1.015296\n",
      "====> Epoch: 31 Average loss: 67.3821, bce: 66.8771, kld: 1.0101\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 67.137001\n",
      "bce: 66.647964, kld: 0.978067\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 66.945190\n",
      "bce: 66.451508, kld: 0.987360\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 66.418610\n",
      "bce: 65.940460, kld: 0.956298\n",
      "====> Epoch: 32 Average loss: 66.7669, bce: 66.2853, kld: 0.9633\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 66.442146\n",
      "bce: 65.963409, kld: 0.957473\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 66.231277\n",
      "bce: 65.768845, kld: 0.924865\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 65.445946\n",
      "bce: 64.985489, kld: 0.920921\n",
      "====> Epoch: 33 Average loss: 66.1699, bce: 65.7080, kld: 0.9238\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 65.726173\n",
      "bce: 65.271057, kld: 0.910230\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 65.297569\n",
      "bce: 64.846939, kld: 0.901262\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 65.483582\n",
      "bce: 65.064468, kld: 0.838228\n",
      "====> Epoch: 34 Average loss: 65.5891, bce: 65.1507, kld: 0.8766\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 65.227089\n",
      "bce: 64.788315, kld: 0.877552\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 65.303345\n",
      "bce: 64.894516, kld: 0.817660\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 64.708679\n",
      "bce: 64.303894, kld: 0.809566\n",
      "====> Epoch: 35 Average loss: 65.0165, bce: 64.5905, kld: 0.8519\n",
      "====> Testing Average Loss: 46.05287973472241\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 64.671005\n",
      "bce: 64.274918, kld: 0.792170\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 64.584755\n",
      "bce: 64.173447, kld: 0.822618\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 64.054314\n",
      "bce: 63.669682, kld: 0.769270\n",
      "====> Epoch: 36 Average loss: 64.4400, bce: 64.0431, kld: 0.7937\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 64.223755\n",
      "bce: 63.829487, kld: 0.788543\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 63.340897\n",
      "bce: 62.951313, kld: 0.779167\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 64.008873\n",
      "bce: 63.643692, kld: 0.730368\n",
      "====> Epoch: 37 Average loss: 63.8579, bce: 63.4777, kld: 0.7604\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 63.492153\n",
      "bce: 63.120373, kld: 0.743562\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 63.739975\n",
      "bce: 63.373211, kld: 0.733530\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 63.089134\n",
      "bce: 62.737583, kld: 0.703101\n",
      "====> Epoch: 38 Average loss: 63.3032, bce: 62.9417, kld: 0.7231\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 62.795597\n",
      "bce: 62.442905, kld: 0.705387\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 63.016079\n",
      "bce: 62.675163, kld: 0.681830\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 62.692318\n",
      "bce: 62.348400, kld: 0.687839\n",
      "====> Epoch: 39 Average loss: 62.7352, bce: 62.3906, kld: 0.6892\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 62.334412\n",
      "bce: 61.994865, kld: 0.679089\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 62.139198\n",
      "bce: 61.811134, kld: 0.656128\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 62.030266\n",
      "bce: 61.714832, kld: 0.630867\n",
      "====> Epoch: 40 Average loss: 62.1952, bce: 61.8648, kld: 0.6609\n",
      "====> Testing Average Loss: 44.09770877712688\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 61.575920\n",
      "bce: 61.255337, kld: 0.641168\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 61.957195\n",
      "bce: 61.642376, kld: 0.629639\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 61.797909\n",
      "bce: 61.494881, kld: 0.606059\n",
      "====> Epoch: 41 Average loss: 61.6421, bce: 61.3269, kld: 0.6304\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 61.377560\n",
      "bce: 61.057774, kld: 0.639571\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 61.121384\n",
      "bce: 60.806023, kld: 0.630723\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 61.257965\n",
      "bce: 60.952732, kld: 0.610465\n",
      "====> Epoch: 42 Average loss: 61.1263, bce: 60.8197, kld: 0.6133\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 61.250690\n",
      "bce: 60.947174, kld: 0.607035\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 59.862793\n",
      "bce: 59.560753, kld: 0.604078\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 60.595467\n",
      "bce: 60.299892, kld: 0.591150\n",
      "====> Epoch: 43 Average loss: 60.5755, bce: 60.2828, kld: 0.5855\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 60.243202\n",
      "bce: 59.956459, kld: 0.573486\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 60.216053\n",
      "bce: 59.922009, kld: 0.588089\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 59.774529\n",
      "bce: 59.490211, kld: 0.568637\n",
      "====> Epoch: 44 Average loss: 60.0461, bce: 59.7626, kld: 0.5671\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 59.820415\n",
      "bce: 59.542492, kld: 0.555850\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 59.791122\n",
      "bce: 59.512409, kld: 0.557425\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 58.901817\n",
      "bce: 58.631104, kld: 0.541424\n",
      "====> Epoch: 45 Average loss: 59.5257, bce: 59.2523, kld: 0.5468\n",
      "====> Testing Average Loss: 42.36329737218746\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 59.001362\n",
      "bce: 58.732307, kld: 0.538109\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 58.895699\n",
      "bce: 58.628342, kld: 0.534715\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 58.773197\n",
      "bce: 58.497517, kld: 0.551358\n",
      "====> Epoch: 46 Average loss: 59.0091, bce: 58.7431, kld: 0.5320\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 58.815617\n",
      "bce: 58.546246, kld: 0.538739\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 58.408489\n",
      "bce: 58.143093, kld: 0.530788\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 57.959949\n",
      "bce: 57.702148, kld: 0.515605\n",
      "====> Epoch: 47 Average loss: 58.5358, bce: 58.2746, kld: 0.5223\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 57.728714\n",
      "bce: 57.480026, kld: 0.497376\n",
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 58.116642\n",
      "bce: 57.866779, kld: 0.499722\n",
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 57.643532\n",
      "bce: 57.396317, kld: 0.494428\n",
      "====> Epoch: 48 Average loss: 58.0252, bce: 57.7748, kld: 0.5008\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 58.137379\n",
      "bce: 57.887554, kld: 0.499650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 57.970566\n",
      "bce: 57.726559, kld: 0.488015\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 57.243935\n",
      "bce: 57.010506, kld: 0.466857\n",
      "====> Epoch: 49 Average loss: 57.5586, bce: 57.3146, kld: 0.4879\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 56.941757\n",
      "bce: 56.701752, kld: 0.480009\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 56.926041\n",
      "bce: 56.693939, kld: 0.464201\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 56.460045\n",
      "bce: 56.230076, kld: 0.459941\n",
      "====> Epoch: 50 Average loss: 57.0663, bce: 56.8306, kld: 0.4715\n",
      "====> Testing Average Loss: 40.5542059146585\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 56.797520\n",
      "bce: 56.552406, kld: 0.490225\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 56.794960\n",
      "bce: 56.561852, kld: 0.466217\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 56.656372\n",
      "bce: 56.422348, kld: 0.468050\n",
      "====> Epoch: 51 Average loss: 56.5913, bce: 56.3598, kld: 0.4629\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 56.470425\n",
      "bce: 56.230721, kld: 0.479408\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 56.662365\n",
      "bce: 56.429726, kld: 0.465280\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 56.290871\n",
      "bce: 56.063873, kld: 0.453993\n",
      "====> Epoch: 52 Average loss: 56.1603, bce: 55.9364, kld: 0.4477\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 55.585136\n",
      "bce: 55.357601, kld: 0.455073\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 56.331913\n",
      "bce: 56.115662, kld: 0.432504\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 55.467228\n",
      "bce: 55.241970, kld: 0.450516\n",
      "====> Epoch: 53 Average loss: 55.7184, bce: 55.4979, kld: 0.4410\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 55.074581\n",
      "bce: 54.855988, kld: 0.437190\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 55.215580\n",
      "bce: 55.004009, kld: 0.423145\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 55.427406\n",
      "bce: 55.213158, kld: 0.428500\n",
      "====> Epoch: 54 Average loss: 55.2336, bce: 55.0194, kld: 0.4284\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 54.669750\n",
      "bce: 54.457191, kld: 0.425117\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 54.611027\n",
      "bce: 54.407379, kld: 0.407298\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 54.842709\n",
      "bce: 54.637421, kld: 0.410579\n",
      "====> Epoch: 55 Average loss: 54.7836, bce: 54.5770, kld: 0.4131\n",
      "====> Testing Average Loss: 38.79041676374651\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 54.781460\n",
      "bce: 54.578812, kld: 0.405298\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 53.987724\n",
      "bce: 53.779690, kld: 0.416071\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 54.319248\n",
      "bce: 54.123550, kld: 0.391398\n",
      "====> Epoch: 56 Average loss: 54.3194, bce: 54.1183, kld: 0.4022\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 53.983372\n",
      "bce: 53.783661, kld: 0.399422\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 53.770069\n",
      "bce: 53.559383, kld: 0.421371\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 53.927292\n",
      "bce: 53.728256, kld: 0.398070\n",
      "====> Epoch: 57 Average loss: 53.8867, bce: 53.6902, kld: 0.3929\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 53.339859\n",
      "bce: 53.146317, kld: 0.387085\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 53.511135\n",
      "bce: 53.313568, kld: 0.395132\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 53.496170\n",
      "bce: 53.303875, kld: 0.384589\n",
      "====> Epoch: 58 Average loss: 53.4615, bce: 53.2705, kld: 0.3821\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 53.515533\n",
      "bce: 53.325626, kld: 0.379811\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 52.785366\n",
      "bce: 52.596210, kld: 0.378312\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 53.028416\n",
      "bce: 52.845543, kld: 0.365745\n",
      "====> Epoch: 59 Average loss: 53.0297, bce: 52.8427, kld: 0.3740\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 52.851181\n",
      "bce: 52.669518, kld: 0.363326\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 52.783592\n",
      "bce: 52.601967, kld: 0.363247\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 52.649750\n",
      "bce: 52.464455, kld: 0.370593\n",
      "====> Epoch: 60 Average loss: 52.5886, bce: 52.4066, kld: 0.3639\n",
      "====> Testing Average Loss: 37.2261006773399\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 52.149971\n",
      "bce: 51.966660, kld: 0.366627\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 52.146812\n",
      "bce: 51.973434, kld: 0.346754\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 51.873875\n",
      "bce: 51.696480, kld: 0.354792\n",
      "====> Epoch: 61 Average loss: 52.1976, bce: 52.0171, kld: 0.3610\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 51.673172\n",
      "bce: 51.499176, kld: 0.347995\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 51.209049\n",
      "bce: 51.031281, kld: 0.355540\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 51.677151\n",
      "bce: 51.503647, kld: 0.347009\n",
      "====> Epoch: 62 Average loss: 51.7926, bce: 51.6184, kld: 0.3485\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 51.531910\n",
      "bce: 51.358803, kld: 0.346212\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 51.725948\n",
      "bce: 51.557373, kld: 0.337150\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 51.734020\n",
      "bce: 51.565956, kld: 0.336126\n",
      "====> Epoch: 63 Average loss: 51.3967, bce: 51.2236, kld: 0.3463\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 51.109371\n",
      "bce: 50.936016, kld: 0.346709\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 51.426163\n",
      "bce: 51.254627, kld: 0.343070\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 50.783394\n",
      "bce: 50.616348, kld: 0.334093\n",
      "====> Epoch: 64 Average loss: 51.0240, bce: 50.8541, kld: 0.3400\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 50.575424\n",
      "bce: 50.409420, kld: 0.332006\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 51.223537\n",
      "bce: 51.054741, kld: 0.337593\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 50.947048\n",
      "bce: 50.780876, kld: 0.332343\n",
      "====> Epoch: 65 Average loss: 50.6467, bce: 50.4802, kld: 0.3329\n",
      "====> Testing Average Loss: 35.66171386133671\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 50.140755\n",
      "bce: 49.972820, kld: 0.335866\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 50.138836\n",
      "bce: 49.970284, kld: 0.337106\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 50.097485\n",
      "bce: 49.939514, kld: 0.315943\n",
      "====> Epoch: 66 Average loss: 50.2306, bce: 50.0656, kld: 0.3300\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 49.764408\n",
      "bce: 49.596893, kld: 0.335028\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 50.341572\n",
      "bce: 50.180107, kld: 0.322927\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 50.143379\n",
      "bce: 49.977459, kld: 0.331840\n",
      "====> Epoch: 67 Average loss: 49.8708, bce: 49.7061, kld: 0.3293\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 49.765106\n",
      "bce: 49.592651, kld: 0.344910\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 49.914646\n",
      "bce: 49.740738, kld: 0.347817\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 48.899765\n",
      "bce: 48.731483, kld: 0.336560\n",
      "====> Epoch: 68 Average loss: 49.5201, bce: 49.3554, kld: 0.3295\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 49.074001\n",
      "bce: 48.902512, kld: 0.342980\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 49.299461\n",
      "bce: 49.131073, kld: 0.336777\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 48.504490\n",
      "bce: 48.335300, kld: 0.338382\n",
      "====> Epoch: 69 Average loss: 49.1458, bce: 48.9837, kld: 0.3242\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 49.374870\n",
      "bce: 49.208698, kld: 0.332343\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 48.830055\n",
      "bce: 48.669426, kld: 0.321255\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 47.785568\n",
      "bce: 47.627224, kld: 0.316690\n",
      "====> Epoch: 70 Average loss: 48.7525, bce: 48.5934, kld: 0.3184\n",
      "====> Testing Average Loss: 34.46574711256823\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 48.282970\n",
      "bce: 48.119537, kld: 0.326863\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 48.189922\n",
      "bce: 48.027866, kld: 0.324109\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 48.181286\n",
      "bce: 48.029152, kld: 0.304268\n",
      "====> Epoch: 71 Average loss: 48.3953, bce: 48.2386, kld: 0.3135\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 48.399017\n",
      "bce: 48.245438, kld: 0.307159\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 47.762436\n",
      "bce: 47.609509, kld: 0.305857\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 47.694714\n",
      "bce: 47.537888, kld: 0.313653\n",
      "====> Epoch: 72 Average loss: 48.0020, bce: 47.8481, kld: 0.3079\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 47.527588\n",
      "bce: 47.373055, kld: 0.309069\n",
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 47.710457\n",
      "bce: 47.556740, kld: 0.307436\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 47.573936\n",
      "bce: 47.425636, kld: 0.296597\n",
      "====> Epoch: 73 Average loss: 47.6473, bce: 47.4968, kld: 0.3009\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 46.776176\n",
      "bce: 46.624710, kld: 0.302936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 46.956902\n",
      "bce: 46.806343, kld: 0.301119\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 46.672180\n",
      "bce: 46.523888, kld: 0.296587\n",
      "====> Epoch: 74 Average loss: 47.2900, bce: 47.1405, kld: 0.2991\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 47.561569\n",
      "bce: 47.414272, kld: 0.294596\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 46.704548\n",
      "bce: 46.555176, kld: 0.298747\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 46.337833\n",
      "bce: 46.194466, kld: 0.286735\n",
      "====> Epoch: 75 Average loss: 46.9542, bce: 46.8067, kld: 0.2950\n",
      "====> Testing Average Loss: 33.052584334642525\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 46.746414\n",
      "bce: 46.607452, kld: 0.277926\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 46.399155\n",
      "bce: 46.254471, kld: 0.289368\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 46.538769\n",
      "bce: 46.394196, kld: 0.289144\n",
      "====> Epoch: 76 Average loss: 46.6143, bce: 46.4697, kld: 0.2893\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 46.077354\n",
      "bce: 45.928844, kld: 0.297020\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 45.834518\n",
      "bce: 45.695507, kld: 0.278023\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 46.082069\n",
      "bce: 45.937660, kld: 0.288816\n",
      "====> Epoch: 77 Average loss: 46.3053, bce: 46.1619, kld: 0.2869\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 45.829819\n",
      "bce: 45.687557, kld: 0.284525\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 46.193573\n",
      "bce: 46.047279, kld: 0.292591\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 45.849018\n",
      "bce: 45.708836, kld: 0.280362\n",
      "====> Epoch: 78 Average loss: 45.9787, bce: 45.8348, kld: 0.2878\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 45.917900\n",
      "bce: 45.775543, kld: 0.284711\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 45.729694\n",
      "bce: 45.591934, kld: 0.275522\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 46.044250\n",
      "bce: 45.904202, kld: 0.280100\n",
      "====> Epoch: 79 Average loss: 45.7074, bce: 45.5658, kld: 0.2833\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 45.774422\n",
      "bce: 45.637108, kld: 0.274627\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 45.556850\n",
      "bce: 45.414387, kld: 0.284930\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 45.147240\n",
      "bce: 45.002789, kld: 0.288903\n",
      "====> Epoch: 80 Average loss: 45.3276, bce: 45.1862, kld: 0.2827\n",
      "====> Testing Average Loss: 32.0289762514978\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 45.206123\n",
      "bce: 45.062534, kld: 0.287175\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 44.667503\n",
      "bce: 44.526871, kld: 0.281264\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 44.586323\n",
      "bce: 44.438923, kld: 0.294801\n",
      "====> Epoch: 81 Average loss: 45.0030, bce: 44.8614, kld: 0.2832\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 45.165276\n",
      "bce: 45.024048, kld: 0.282453\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 44.468235\n",
      "bce: 44.328697, kld: 0.279077\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 44.606987\n",
      "bce: 44.465885, kld: 0.282203\n",
      "====> Epoch: 82 Average loss: 44.6588, bce: 44.5207, kld: 0.2763\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 44.406006\n",
      "bce: 44.268127, kld: 0.275759\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 44.103230\n",
      "bce: 43.963158, kld: 0.280141\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 44.006382\n",
      "bce: 43.872620, kld: 0.267523\n",
      "====> Epoch: 83 Average loss: 44.3852, bce: 44.2471, kld: 0.2761\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 44.097721\n",
      "bce: 43.961929, kld: 0.271587\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 44.063393\n",
      "bce: 43.926308, kld: 0.274173\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 43.721432\n",
      "bce: 43.585972, kld: 0.270921\n",
      "====> Epoch: 84 Average loss: 44.0580, bce: 43.9210, kld: 0.2740\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 44.139771\n",
      "bce: 44.002148, kld: 0.275249\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 43.511459\n",
      "bce: 43.373253, kld: 0.276411\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 43.625046\n",
      "bce: 43.488811, kld: 0.272467\n",
      "====> Epoch: 85 Average loss: 43.7514, bce: 43.6154, kld: 0.2720\n",
      "====> Testing Average Loss: 30.95911725302889\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 43.286755\n",
      "bce: 43.153381, kld: 0.266750\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 43.468666\n",
      "bce: 43.335854, kld: 0.265622\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 42.884850\n",
      "bce: 42.746227, kld: 0.277245\n",
      "====> Epoch: 86 Average loss: 43.5080, bce: 43.3719, kld: 0.2721\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 43.311085\n",
      "bce: 43.175072, kld: 0.272030\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 43.453751\n",
      "bce: 43.319633, kld: 0.268237\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 43.183041\n",
      "bce: 43.054390, kld: 0.257299\n",
      "====> Epoch: 87 Average loss: 43.2142, bce: 43.0789, kld: 0.2706\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 43.496220\n",
      "bce: 43.364998, kld: 0.262440\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 43.001682\n",
      "bce: 42.869091, kld: 0.265186\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 42.784428\n",
      "bce: 42.645981, kld: 0.276893\n",
      "====> Epoch: 88 Average loss: 42.9071, bce: 42.7720, kld: 0.2702\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 42.406143\n",
      "bce: 42.270088, kld: 0.272109\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 42.639458\n",
      "bce: 42.501476, kld: 0.275962\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 42.701233\n",
      "bce: 42.566460, kld: 0.269546\n",
      "====> Epoch: 89 Average loss: 42.6086, bce: 42.4747, kld: 0.2677\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 42.480705\n",
      "bce: 42.349453, kld: 0.262502\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 41.789661\n",
      "bce: 41.657875, kld: 0.263574\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 42.341293\n",
      "bce: 42.203506, kld: 0.275571\n",
      "====> Epoch: 90 Average loss: 42.3165, bce: 42.1834, kld: 0.2663\n",
      "====> Testing Average Loss: 29.65030559346292\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 42.036163\n",
      "bce: 41.904083, kld: 0.264162\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 41.862476\n",
      "bce: 41.727501, kld: 0.269948\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 41.682140\n",
      "bce: 41.550755, kld: 0.262774\n",
      "====> Epoch: 91 Average loss: 42.0333, bce: 41.9012, kld: 0.2640\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 41.984150\n",
      "bce: 41.854790, kld: 0.258720\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 41.690594\n",
      "bce: 41.557331, kld: 0.266528\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 41.801006\n",
      "bce: 41.669453, kld: 0.263108\n",
      "====> Epoch: 92 Average loss: 41.7585, bce: 41.6266, kld: 0.2639\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 41.451328\n",
      "bce: 41.322502, kld: 0.257652\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 41.309925\n",
      "bce: 41.181580, kld: 0.256687\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 41.807652\n",
      "bce: 41.678299, kld: 0.258708\n",
      "====> Epoch: 93 Average loss: 41.5149, bce: 41.3838, kld: 0.2623\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 41.476135\n",
      "bce: 41.346722, kld: 0.258831\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 41.340363\n",
      "bce: 41.209435, kld: 0.261856\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 40.687702\n",
      "bce: 40.562500, kld: 0.250401\n",
      "====> Epoch: 94 Average loss: 41.2256, bce: 41.0960, kld: 0.2592\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 40.846443\n",
      "bce: 40.721531, kld: 0.249823\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 41.169731\n",
      "bce: 41.039589, kld: 0.260285\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 41.196869\n",
      "bce: 41.065697, kld: 0.262344\n",
      "====> Epoch: 95 Average loss: 40.9342, bce: 40.8057, kld: 0.2570\n",
      "====> Testing Average Loss: 28.97568774131274\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 40.667973\n",
      "bce: 40.541702, kld: 0.252537\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 41.055996\n",
      "bce: 40.926971, kld: 0.258049\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 40.711369\n",
      "bce: 40.580185, kld: 0.262368\n",
      "====> Epoch: 96 Average loss: 40.6802, bce: 40.5517, kld: 0.2570\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 39.934181\n",
      "bce: 39.806889, kld: 0.254587\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 40.522060\n",
      "bce: 40.395351, kld: 0.253418\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 40.364563\n",
      "bce: 40.238167, kld: 0.252789\n",
      "====> Epoch: 97 Average loss: 40.4196, bce: 40.2913, kld: 0.2567\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 40.004623\n",
      "bce: 39.882790, kld: 0.243669\n",
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 40.179543\n",
      "bce: 40.050884, kld: 0.257320\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 40.437653\n",
      "bce: 40.307972, kld: 0.259358\n",
      "====> Epoch: 98 Average loss: 40.1675, bce: 40.0412, kld: 0.2526\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 40.346348\n",
      "bce: 40.218391, kld: 0.255910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 39.739639\n",
      "bce: 39.614826, kld: 0.249626\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 40.130615\n",
      "bce: 40.006393, kld: 0.248442\n",
      "====> Epoch: 99 Average loss: 39.9586, bce: 39.8331, kld: 0.2509\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 40.240452\n",
      "bce: 40.110138, kld: 0.260626\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 39.641060\n",
      "bce: 39.520439, kld: 0.241241\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 39.421177\n",
      "bce: 39.293652, kld: 0.255048\n",
      "====> Epoch: 100 Average loss: 39.6726, bce: 39.5464, kld: 0.2523\n",
      "====> Testing Average Loss: 27.71558277027027\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 39.498894\n",
      "bce: 39.373421, kld: 0.250946\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 39.526318\n",
      "bce: 39.397301, kld: 0.258033\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 39.325928\n",
      "bce: 39.203484, kld: 0.244890\n",
      "====> Epoch: 101 Average loss: 39.4262, bce: 39.3003, kld: 0.2519\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 39.198784\n",
      "bce: 39.077938, kld: 0.241690\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 39.722450\n",
      "bce: 39.593880, kld: 0.257138\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 39.598484\n",
      "bce: 39.465561, kld: 0.265849\n",
      "====> Epoch: 102 Average loss: 39.1616, bce: 39.0359, kld: 0.2513\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 38.654968\n",
      "bce: 38.527321, kld: 0.255292\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 39.296036\n",
      "bce: 39.165009, kld: 0.262058\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 38.932045\n",
      "bce: 38.813576, kld: 0.236939\n",
      "====> Epoch: 103 Average loss: 38.9602, bce: 38.8336, kld: 0.2532\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 38.774731\n",
      "bce: 38.654083, kld: 0.241293\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 38.343693\n",
      "bce: 38.220695, kld: 0.245991\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 38.928452\n",
      "bce: 38.798393, kld: 0.260120\n",
      "====> Epoch: 104 Average loss: 38.7171, bce: 38.5926, kld: 0.2490\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 38.315075\n",
      "bce: 38.185501, kld: 0.259151\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 38.910633\n",
      "bce: 38.777969, kld: 0.265330\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 38.359100\n",
      "bce: 38.230736, kld: 0.256730\n",
      "====> Epoch: 105 Average loss: 38.4862, bce: 38.3589, kld: 0.2545\n",
      "====> Testing Average Loss: 26.938544301690854\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 37.800865\n",
      "bce: 37.678612, kld: 0.244509\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 38.102669\n",
      "bce: 37.971897, kld: 0.261547\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 38.435425\n",
      "bce: 38.307972, kld: 0.254906\n",
      "====> Epoch: 106 Average loss: 38.2244, bce: 38.0997, kld: 0.2494\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 38.111210\n",
      "bce: 37.990982, kld: 0.240456\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 37.743382\n",
      "bce: 37.619137, kld: 0.248492\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 38.008224\n",
      "bce: 37.887009, kld: 0.242435\n",
      "====> Epoch: 107 Average loss: 37.9896, bce: 37.8655, kld: 0.2482\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 37.955349\n",
      "bce: 37.831974, kld: 0.246751\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 37.726009\n",
      "bce: 37.606827, kld: 0.238368\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 37.552177\n",
      "bce: 37.428444, kld: 0.247468\n",
      "====> Epoch: 108 Average loss: 37.7892, bce: 37.6665, kld: 0.2452\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 37.967175\n",
      "bce: 37.840462, kld: 0.253425\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 37.343502\n",
      "bce: 37.218872, kld: 0.249262\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 37.424931\n",
      "bce: 37.300838, kld: 0.248184\n",
      "====> Epoch: 109 Average loss: 37.5422, bce: 37.4184, kld: 0.2476\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 37.395393\n",
      "bce: 37.273102, kld: 0.244587\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 37.998676\n",
      "bce: 37.875389, kld: 0.246577\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 36.651550\n",
      "bce: 36.524002, kld: 0.255096\n",
      "====> Epoch: 110 Average loss: 37.3080, bce: 37.1838, kld: 0.2485\n",
      "====> Testing Average Loss: 26.237184421182267\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 37.153820\n",
      "bce: 37.026840, kld: 0.253957\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 37.368813\n",
      "bce: 37.246731, kld: 0.244164\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 36.999710\n",
      "bce: 36.880104, kld: 0.239213\n",
      "====> Epoch: 111 Average loss: 37.0765, bce: 36.9550, kld: 0.2431\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 37.080627\n",
      "bce: 36.961052, kld: 0.239152\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 36.911625\n",
      "bce: 36.790237, kld: 0.242777\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 36.687527\n",
      "bce: 36.564274, kld: 0.246502\n",
      "====> Epoch: 112 Average loss: 36.8804, bce: 36.7580, kld: 0.2448\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 37.068443\n",
      "bce: 36.945961, kld: 0.244965\n",
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 37.571712\n",
      "bce: 37.443123, kld: 0.257180\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 36.488464\n",
      "bce: 36.362518, kld: 0.251896\n",
      "====> Epoch: 113 Average loss: 36.6836, bce: 36.5614, kld: 0.2444\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 36.248592\n",
      "bce: 36.126373, kld: 0.244440\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 36.534576\n",
      "bce: 36.412525, kld: 0.244106\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 36.916500\n",
      "bce: 36.793339, kld: 0.246324\n",
      "====> Epoch: 114 Average loss: 36.4447, bce: 36.3218, kld: 0.2459\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 36.495667\n",
      "bce: 36.373051, kld: 0.245229\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 35.982624\n",
      "bce: 35.861198, kld: 0.242847\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 36.204067\n",
      "bce: 36.081375, kld: 0.245382\n",
      "====> Epoch: 115 Average loss: 36.2312, bce: 36.1092, kld: 0.2440\n",
      "====> Testing Average Loss: 25.410449049727067\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 36.402855\n",
      "bce: 36.277668, kld: 0.250374\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 36.120907\n",
      "bce: 35.996307, kld: 0.249197\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 36.086567\n",
      "bce: 35.964821, kld: 0.243496\n",
      "====> Epoch: 116 Average loss: 36.0203, bce: 35.8987, kld: 0.2432\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 35.503731\n",
      "bce: 35.386478, kld: 0.234503\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 35.482037\n",
      "bce: 35.361858, kld: 0.240356\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 35.777649\n",
      "bce: 35.656445, kld: 0.242409\n",
      "====> Epoch: 117 Average loss: 35.8253, bce: 35.7050, kld: 0.2407\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 35.513214\n",
      "bce: 35.391960, kld: 0.242504\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 35.705185\n",
      "bce: 35.584114, kld: 0.242142\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 35.232933\n",
      "bce: 35.112190, kld: 0.241488\n",
      "====> Epoch: 118 Average loss: 35.6095, bce: 35.4884, kld: 0.2422\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 35.406406\n",
      "bce: 35.283604, kld: 0.245605\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 35.010914\n",
      "bce: 34.890762, kld: 0.240304\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 35.934376\n",
      "bce: 35.817883, kld: 0.232989\n",
      "====> Epoch: 119 Average loss: 35.4109, bce: 35.2894, kld: 0.2430\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 35.346218\n",
      "bce: 35.230556, kld: 0.231327\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 35.483658\n",
      "bce: 35.359749, kld: 0.247817\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 35.101635\n",
      "bce: 34.979630, kld: 0.244014\n",
      "====> Epoch: 120 Average loss: 35.2393, bce: 35.1184, kld: 0.2417\n",
      "====> Testing Average Loss: 24.6481296182266\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 35.105427\n",
      "bce: 34.982552, kld: 0.245752\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 34.920845\n",
      "bce: 34.799961, kld: 0.241767\n",
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 35.135437\n",
      "bce: 35.016365, kld: 0.238144\n",
      "====> Epoch: 121 Average loss: 35.0335, bce: 34.9124, kld: 0.2424\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 35.083149\n",
      "bce: 34.964119, kld: 0.238063\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 34.909824\n",
      "bce: 34.793121, kld: 0.233402\n",
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 34.789650\n",
      "bce: 34.670105, kld: 0.239090\n",
      "====> Epoch: 122 Average loss: 34.8408, bce: 34.7199, kld: 0.2419\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 34.575062\n",
      "bce: 34.456085, kld: 0.237955\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 35.190464\n",
      "bce: 35.060966, kld: 0.258997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 34.400047\n",
      "bce: 34.277443, kld: 0.245211\n",
      "====> Epoch: 123 Average loss: 34.6942, bce: 34.5724, kld: 0.2436\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 34.793552\n",
      "bce: 34.672737, kld: 0.241631\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 34.514912\n",
      "bce: 34.394485, kld: 0.240852\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 34.301994\n",
      "bce: 34.183540, kld: 0.236906\n",
      "====> Epoch: 124 Average loss: 34.4644, bce: 34.3425, kld: 0.2437\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 34.170059\n",
      "bce: 34.049103, kld: 0.241915\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 34.081631\n",
      "bce: 33.963875, kld: 0.235509\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 33.982670\n",
      "bce: 33.863827, kld: 0.237686\n",
      "====> Epoch: 125 Average loss: 34.3087, bce: 34.1880, kld: 0.2415\n",
      "====> Testing Average Loss: 23.420573783450937\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 34.397137\n",
      "bce: 34.274307, kld: 0.245656\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 34.342121\n",
      "bce: 34.224613, kld: 0.235012\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 34.031284\n",
      "bce: 33.911430, kld: 0.239709\n",
      "====> Epoch: 126 Average loss: 34.0768, bce: 33.9561, kld: 0.2415\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 34.420612\n",
      "bce: 34.302055, kld: 0.237116\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 33.564140\n",
      "bce: 33.445190, kld: 0.237902\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 33.980125\n",
      "bce: 33.856773, kld: 0.246700\n",
      "====> Epoch: 127 Average loss: 33.9155, bce: 33.7940, kld: 0.2430\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 34.227993\n",
      "bce: 34.101646, kld: 0.252692\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 33.704315\n",
      "bce: 33.584393, kld: 0.239845\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 33.466297\n",
      "bce: 33.346733, kld: 0.239127\n",
      "====> Epoch: 128 Average loss: 33.7179, bce: 33.5968, kld: 0.2420\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 33.811687\n",
      "bce: 33.694332, kld: 0.234708\n",
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 33.656296\n",
      "bce: 33.532555, kld: 0.247481\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 33.371887\n",
      "bce: 33.256992, kld: 0.229788\n",
      "====> Epoch: 129 Average loss: 33.5131, bce: 33.3923, kld: 0.2416\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 33.408424\n",
      "bce: 33.289940, kld: 0.236966\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 33.635921\n",
      "bce: 33.516769, kld: 0.238303\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 33.348915\n",
      "bce: 33.233929, kld: 0.229972\n",
      "====> Epoch: 130 Average loss: 33.3600, bce: 33.2399, kld: 0.2401\n",
      "====> Testing Average Loss: 23.116413635001997\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 32.779396\n",
      "bce: 32.660255, kld: 0.238282\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 33.537609\n",
      "bce: 33.419655, kld: 0.235907\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 33.074642\n",
      "bce: 32.954136, kld: 0.241012\n",
      "====> Epoch: 131 Average loss: 33.1666, bce: 33.0465, kld: 0.2401\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 33.127087\n",
      "bce: 33.004601, kld: 0.244969\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 33.053623\n",
      "bce: 32.933632, kld: 0.239979\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 32.655193\n",
      "bce: 32.533714, kld: 0.242961\n",
      "====> Epoch: 132 Average loss: 32.9958, bce: 32.8754, kld: 0.2408\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 32.719913\n",
      "bce: 32.595795, kld: 0.248239\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 32.728722\n",
      "bce: 32.610092, kld: 0.237256\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 32.915974\n",
      "bce: 32.797180, kld: 0.237587\n",
      "====> Epoch: 133 Average loss: 32.8337, bce: 32.7139, kld: 0.2395\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 32.503395\n",
      "bce: 32.384926, kld: 0.236938\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 32.681000\n",
      "bce: 32.560013, kld: 0.241972\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 32.726768\n",
      "bce: 32.605381, kld: 0.242776\n",
      "====> Epoch: 134 Average loss: 32.6833, bce: 32.5622, kld: 0.2422\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 32.445202\n",
      "bce: 32.321785, kld: 0.246831\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 32.309322\n",
      "bce: 32.185814, kld: 0.247018\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 32.158318\n",
      "bce: 32.042473, kld: 0.231686\n",
      "====> Epoch: 135 Average loss: 32.4891, bce: 32.3687, kld: 0.2408\n",
      "====> Testing Average Loss: 22.53585418469578\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 32.095127\n",
      "bce: 31.978359, kld: 0.233535\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 31.852850\n",
      "bce: 31.736454, kld: 0.232792\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 32.078903\n",
      "bce: 31.959663, kld: 0.238479\n",
      "====> Epoch: 136 Average loss: 32.2975, bce: 32.1776, kld: 0.2399\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 32.068928\n",
      "bce: 31.942867, kld: 0.252122\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 31.750639\n",
      "bce: 31.626934, kld: 0.247409\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 32.127483\n",
      "bce: 32.005363, kld: 0.244243\n",
      "====> Epoch: 137 Average loss: 32.1392, bce: 32.0182, kld: 0.2420\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 32.105614\n",
      "bce: 31.982704, kld: 0.245822\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 32.270061\n",
      "bce: 32.151321, kld: 0.237482\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 31.458752\n",
      "bce: 31.335480, kld: 0.246546\n",
      "====> Epoch: 138 Average loss: 32.0145, bce: 31.8941, kld: 0.2408\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 31.739599\n",
      "bce: 31.618200, kld: 0.242797\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 31.587734\n",
      "bce: 31.465969, kld: 0.243529\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 31.254004\n",
      "bce: 31.136847, kld: 0.234316\n",
      "====> Epoch: 139 Average loss: 31.8103, bce: 31.6898, kld: 0.2411\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 31.652622\n",
      "bce: 31.534731, kld: 0.235782\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 31.698057\n",
      "bce: 31.579010, kld: 0.238094\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 31.597891\n",
      "bce: 31.479401, kld: 0.236981\n",
      "====> Epoch: 140 Average loss: 31.6409, bce: 31.5211, kld: 0.2394\n",
      "====> Testing Average Loss: 22.17344457295966\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 31.306776\n",
      "bce: 31.188269, kld: 0.237014\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 31.426975\n",
      "bce: 31.308409, kld: 0.237133\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 31.217236\n",
      "bce: 31.097940, kld: 0.238591\n",
      "====> Epoch: 141 Average loss: 31.4979, bce: 31.3786, kld: 0.2387\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 31.499243\n",
      "bce: 31.381138, kld: 0.236208\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 31.297525\n",
      "bce: 31.180248, kld: 0.234554\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 30.964956\n",
      "bce: 30.843029, kld: 0.243854\n",
      "====> Epoch: 142 Average loss: 31.3063, bce: 31.1879, kld: 0.2367\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 31.096682\n",
      "bce: 30.979740, kld: 0.233885\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 31.202194\n",
      "bce: 31.085884, kld: 0.232622\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 31.427202\n",
      "bce: 31.301121, kld: 0.252162\n",
      "====> Epoch: 143 Average loss: 31.1819, bce: 31.0617, kld: 0.2405\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 31.026503\n",
      "bce: 30.904165, kld: 0.244676\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 31.461321\n",
      "bce: 31.339581, kld: 0.243482\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 31.069416\n",
      "bce: 30.946632, kld: 0.245566\n",
      "====> Epoch: 144 Average loss: 31.0144, bce: 30.8954, kld: 0.2381\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 30.900331\n",
      "bce: 30.781816, kld: 0.237029\n",
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 31.330027\n",
      "bce: 31.212765, kld: 0.234522\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 30.468822\n",
      "bce: 30.349417, kld: 0.238810\n",
      "====> Epoch: 145 Average loss: 30.8692, bce: 30.7509, kld: 0.2366\n",
      "====> Testing Average Loss: 21.18632047996272\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 30.450184\n",
      "bce: 30.328823, kld: 0.242720\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 30.711929\n",
      "bce: 30.593052, kld: 0.237756\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 30.509890\n",
      "bce: 30.393604, kld: 0.232570\n",
      "====> Epoch: 146 Average loss: 30.7289, bce: 30.6100, kld: 0.2377\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 30.757755\n",
      "bce: 30.639124, kld: 0.237263\n",
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 30.316839\n",
      "bce: 30.198637, kld: 0.236404\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 30.525005\n",
      "bce: 30.405228, kld: 0.239556\n",
      "====> Epoch: 147 Average loss: 30.5695, bce: 30.4498, kld: 0.2394\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 30.272324\n",
      "bce: 30.154545, kld: 0.235556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 30.980770\n",
      "bce: 30.861156, kld: 0.239228\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 30.198553\n",
      "bce: 30.081032, kld: 0.235041\n",
      "====> Epoch: 148 Average loss: 30.4886, bce: 30.3697, kld: 0.2378\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 30.333570\n",
      "bce: 30.213774, kld: 0.239592\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 30.470034\n",
      "bce: 30.351553, kld: 0.236961\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 30.781857\n",
      "bce: 30.662622, kld: 0.238469\n",
      "====> Epoch: 149 Average loss: 30.3336, bce: 30.2148, kld: 0.2375\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 30.275423\n",
      "bce: 30.152225, kld: 0.246396\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 29.940208\n",
      "bce: 29.818897, kld: 0.242623\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 29.911318\n",
      "bce: 29.794497, kld: 0.233642\n",
      "====> Epoch: 150 Average loss: 30.1496, bce: 30.0290, kld: 0.2413\n",
      "====> Testing Average Loss: 20.808902151843963\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 30.256302\n",
      "bce: 30.140316, kld: 0.231971\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 29.558054\n",
      "bce: 29.432686, kld: 0.250735\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 30.356852\n",
      "bce: 30.239824, kld: 0.234056\n",
      "====> Epoch: 151 Average loss: 29.9946, bce: 29.8763, kld: 0.2368\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 30.044329\n",
      "bce: 29.925354, kld: 0.237951\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 29.659954\n",
      "bce: 29.538626, kld: 0.242655\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 29.555767\n",
      "bce: 29.437450, kld: 0.236632\n",
      "====> Epoch: 152 Average loss: 29.8594, bce: 29.7409, kld: 0.2371\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 29.703592\n",
      "bce: 29.584963, kld: 0.237259\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 29.764580\n",
      "bce: 29.649088, kld: 0.230983\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 29.356417\n",
      "bce: 29.234873, kld: 0.243088\n",
      "====> Epoch: 153 Average loss: 29.7043, bce: 29.5855, kld: 0.2376\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 29.262747\n",
      "bce: 29.143831, kld: 0.237830\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 29.588280\n",
      "bce: 29.468843, kld: 0.238873\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 29.468964\n",
      "bce: 29.347847, kld: 0.242235\n",
      "====> Epoch: 154 Average loss: 29.5567, bce: 29.4369, kld: 0.2396\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 29.724831\n",
      "bce: 29.602392, kld: 0.244876\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 29.289474\n",
      "bce: 29.168785, kld: 0.241379\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 29.224136\n",
      "bce: 29.107759, kld: 0.232755\n",
      "====> Epoch: 155 Average loss: 29.4315, bce: 29.3132, kld: 0.2367\n",
      "====> Testing Average Loss: 20.40490457745307\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 29.625978\n",
      "bce: 29.509266, kld: 0.233426\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 29.049547\n",
      "bce: 28.929550, kld: 0.239994\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 29.447042\n",
      "bce: 29.325874, kld: 0.242336\n",
      "====> Epoch: 156 Average loss: 29.3153, bce: 29.1960, kld: 0.2385\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 29.267452\n",
      "bce: 29.147236, kld: 0.240431\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 28.784082\n",
      "bce: 28.666161, kld: 0.235845\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 29.324171\n",
      "bce: 29.208149, kld: 0.232046\n",
      "====> Epoch: 157 Average loss: 29.1423, bce: 29.0248, kld: 0.2350\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 29.358805\n",
      "bce: 29.241497, kld: 0.234614\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 28.912071\n",
      "bce: 28.793388, kld: 0.237365\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 28.829895\n",
      "bce: 28.713749, kld: 0.232292\n",
      "====> Epoch: 158 Average loss: 29.0185, bce: 28.9010, kld: 0.2350\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 29.032942\n",
      "bce: 28.911129, kld: 0.243627\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 28.631424\n",
      "bce: 28.512930, kld: 0.236988\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 28.927212\n",
      "bce: 28.808384, kld: 0.237654\n",
      "====> Epoch: 159 Average loss: 28.8964, bce: 28.7785, kld: 0.2357\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 28.464504\n",
      "bce: 28.349419, kld: 0.230170\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 28.693176\n",
      "bce: 28.575233, kld: 0.235884\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 28.474701\n",
      "bce: 28.358303, kld: 0.232796\n",
      "====> Epoch: 160 Average loss: 28.7806, bce: 28.6617, kld: 0.2378\n",
      "====> Testing Average Loss: 19.52613458594062\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 28.548275\n",
      "bce: 28.425995, kld: 0.244562\n",
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 28.490553\n",
      "bce: 28.370529, kld: 0.240048\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 28.519089\n",
      "bce: 28.401131, kld: 0.235917\n",
      "====> Epoch: 161 Average loss: 28.6973, bce: 28.5788, kld: 0.2370\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 28.746319\n",
      "bce: 28.633823, kld: 0.224990\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 28.199596\n",
      "bce: 28.081139, kld: 0.236915\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 28.429308\n",
      "bce: 28.309708, kld: 0.239199\n",
      "====> Epoch: 162 Average loss: 28.5482, bce: 28.4301, kld: 0.2361\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 28.452187\n",
      "bce: 28.335396, kld: 0.233582\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 28.163071\n",
      "bce: 28.048313, kld: 0.229514\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 28.785744\n",
      "bce: 28.668257, kld: 0.234974\n",
      "====> Epoch: 163 Average loss: 28.4089, bce: 28.2925, kld: 0.2329\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 28.801582\n",
      "bce: 28.683861, kld: 0.235445\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 28.247831\n",
      "bce: 28.129028, kld: 0.237604\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 28.307234\n",
      "bce: 28.192699, kld: 0.229070\n",
      "====> Epoch: 164 Average loss: 28.2614, bce: 28.1433, kld: 0.2363\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 28.216484\n",
      "bce: 28.099583, kld: 0.233801\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 27.808775\n",
      "bce: 27.688549, kld: 0.240453\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 27.882547\n",
      "bce: 27.767483, kld: 0.230129\n",
      "====> Epoch: 165 Average loss: 28.1206, bce: 28.0032, kld: 0.2346\n",
      "====> Testing Average Loss: 19.497224903474905\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 27.914019\n",
      "bce: 27.794918, kld: 0.238200\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 27.887026\n",
      "bce: 27.767950, kld: 0.238152\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 27.528936\n",
      "bce: 27.408884, kld: 0.240106\n",
      "====> Epoch: 166 Average loss: 27.9812, bce: 27.8628, kld: 0.2367\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 27.996622\n",
      "bce: 27.877533, kld: 0.238178\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 27.652168\n",
      "bce: 27.532028, kld: 0.240279\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 28.352673\n",
      "bce: 28.234665, kld: 0.236015\n",
      "====> Epoch: 167 Average loss: 27.9150, bce: 27.7975, kld: 0.2349\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 27.715738\n",
      "bce: 27.600952, kld: 0.229573\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 27.862951\n",
      "bce: 27.747070, kld: 0.231763\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 27.690062\n",
      "bce: 27.568718, kld: 0.242688\n",
      "====> Epoch: 168 Average loss: 27.8137, bce: 27.6955, kld: 0.2362\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 27.684103\n",
      "bce: 27.569313, kld: 0.229578\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 27.557543\n",
      "bce: 27.441919, kld: 0.231247\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 27.511305\n",
      "bce: 27.393246, kld: 0.236117\n",
      "====> Epoch: 169 Average loss: 27.6529, bce: 27.5360, kld: 0.2338\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 27.544819\n",
      "bce: 27.427982, kld: 0.233673\n",
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 27.745163\n",
      "bce: 27.632584, kld: 0.225157\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 27.516390\n",
      "bce: 27.396000, kld: 0.240781\n",
      "====> Epoch: 170 Average loss: 27.5696, bce: 27.4513, kld: 0.2367\n",
      "====> Testing Average Loss: 19.410209817268008\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 27.315285\n",
      "bce: 27.205643, kld: 0.219282\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 27.362265\n",
      "bce: 27.243753, kld: 0.237021\n",
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 27.632122\n",
      "bce: 27.514849, kld: 0.234548\n",
      "====> Epoch: 171 Average loss: 27.4790, bce: 27.3613, kld: 0.2355\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 27.652275\n",
      "bce: 27.531536, kld: 0.241476\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 27.406328\n",
      "bce: 27.290035, kld: 0.232588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 27.506020\n",
      "bce: 27.392189, kld: 0.227662\n",
      "====> Epoch: 172 Average loss: 27.3471, bce: 27.2292, kld: 0.2358\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 27.183680\n",
      "bce: 27.064007, kld: 0.239347\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 26.819956\n",
      "bce: 26.701378, kld: 0.237155\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 26.840734\n",
      "bce: 26.724516, kld: 0.232437\n",
      "====> Epoch: 173 Average loss: 27.2135, bce: 27.0951, kld: 0.2367\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 27.700844\n",
      "bce: 27.578907, kld: 0.243872\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 27.559669\n",
      "bce: 27.443375, kld: 0.232590\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 26.985281\n",
      "bce: 26.867428, kld: 0.235706\n",
      "====> Epoch: 174 Average loss: 27.1181, bce: 26.9997, kld: 0.2368\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 26.926020\n",
      "bce: 26.809940, kld: 0.232160\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 26.914221\n",
      "bce: 26.795544, kld: 0.237354\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 27.058523\n",
      "bce: 26.942924, kld: 0.231196\n",
      "====> Epoch: 175 Average loss: 26.9463, bce: 26.8288, kld: 0.2349\n",
      "====> Testing Average Loss: 18.927898977333246\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 26.718012\n",
      "bce: 26.599689, kld: 0.236644\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 27.198185\n",
      "bce: 27.083315, kld: 0.229740\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 27.107197\n",
      "bce: 26.990353, kld: 0.233688\n",
      "====> Epoch: 176 Average loss: 26.8407, bce: 26.7224, kld: 0.2367\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 26.400042\n",
      "bce: 26.283539, kld: 0.233005\n",
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 26.731068\n",
      "bce: 26.609236, kld: 0.243663\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 26.945238\n",
      "bce: 26.829983, kld: 0.230510\n",
      "====> Epoch: 177 Average loss: 26.7674, bce: 26.6498, kld: 0.2350\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 26.805941\n",
      "bce: 26.685362, kld: 0.241157\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 26.464252\n",
      "bce: 26.346268, kld: 0.235969\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 26.674572\n",
      "bce: 26.559677, kld: 0.229789\n",
      "====> Epoch: 178 Average loss: 26.6446, bce: 26.5266, kld: 0.2358\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 27.028139\n",
      "bce: 26.910320, kld: 0.235638\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 26.255716\n",
      "bce: 26.138687, kld: 0.234057\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 26.603441\n",
      "bce: 26.484236, kld: 0.238409\n",
      "====> Epoch: 179 Average loss: 26.5083, bce: 26.3911, kld: 0.2345\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 26.429205\n",
      "bce: 26.309914, kld: 0.238581\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 26.389772\n",
      "bce: 26.270748, kld: 0.238049\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 26.008278\n",
      "bce: 25.892225, kld: 0.232104\n",
      "====> Epoch: 180 Average loss: 26.4034, bce: 26.2865, kld: 0.2338\n",
      "====> Testing Average Loss: 18.671837554919453\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 26.912975\n",
      "bce: 26.798073, kld: 0.229804\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 26.053648\n",
      "bce: 25.937786, kld: 0.231725\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 25.857546\n",
      "bce: 25.738722, kld: 0.237649\n",
      "====> Epoch: 181 Average loss: 26.3102, bce: 26.1929, kld: 0.2347\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 26.026394\n",
      "bce: 25.909555, kld: 0.233677\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 26.253561\n",
      "bce: 26.135895, kld: 0.235334\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 26.030859\n",
      "bce: 25.914312, kld: 0.233093\n",
      "====> Epoch: 182 Average loss: 26.2009, bce: 26.0844, kld: 0.2329\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 25.893572\n",
      "bce: 25.780226, kld: 0.226693\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 26.024466\n",
      "bce: 25.909140, kld: 0.230653\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 26.155188\n",
      "bce: 26.037432, kld: 0.235513\n",
      "====> Epoch: 183 Average loss: 26.1066, bce: 25.9900, kld: 0.2332\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 26.243366\n",
      "bce: 26.127514, kld: 0.231706\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 25.385532\n",
      "bce: 25.269932, kld: 0.231203\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 26.475721\n",
      "bce: 26.356331, kld: 0.238782\n",
      "====> Epoch: 184 Average loss: 26.0023, bce: 25.8846, kld: 0.2354\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 25.845606\n",
      "bce: 25.732853, kld: 0.225506\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 25.818319\n",
      "bce: 25.702290, kld: 0.232059\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 25.852709\n",
      "bce: 25.735146, kld: 0.235126\n",
      "====> Epoch: 185 Average loss: 25.9072, bce: 25.7914, kld: 0.2315\n",
      "====> Testing Average Loss: 17.450786242677406\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 26.326744\n",
      "bce: 26.207729, kld: 0.238029\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=0.5,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
