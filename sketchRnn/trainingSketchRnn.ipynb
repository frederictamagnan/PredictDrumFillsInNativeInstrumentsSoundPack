{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 14663.618164\n",
      "bce: 104.139320, kld: 181.993484\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 3234.355469\n",
      "bce: 102.782776, kld: 39.144661\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 2920.423096\n",
      "bce: 101.851387, kld: 35.232147\n",
      "====> Epoch: 0 Average loss: 4216.8483, bce: 102.9112, kld: 51.4242\n",
      "====> Testing Average Loss: 83.07261225203035\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 2877.102295\n",
      "bce: 101.711807, kld: 34.692379\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 2710.437256\n",
      "bce: 101.024513, kld: 32.617661\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 2570.886475\n",
      "bce: 99.842514, kld: 30.888048\n",
      "====> Epoch: 1 Average loss: 2695.9812, bce: 100.8088, kld: 32.4397\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 2515.107910\n",
      "bce: 99.689087, kld: 30.192738\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 2430.987061\n",
      "bce: 99.021637, kld: 29.149567\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 2360.149902\n",
      "bce: 97.723473, kld: 28.280333\n",
      "====> Epoch: 2 Average loss: 2429.8261, bce: 98.8046, kld: 29.1378\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 2337.077393\n",
      "bce: 97.845139, kld: 27.990402\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 2268.169434\n",
      "bce: 96.826859, kld: 27.141781\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 2212.737061\n",
      "bce: 96.080330, kld: 26.458208\n",
      "====> Epoch: 3 Average loss: 2273.0805, bce: 96.8766, kld: 27.2025\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 2204.551758\n",
      "bce: 96.183243, kld: 26.354605\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 2159.939453\n",
      "bce: 95.091187, kld: 25.810604\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 2100.588379\n",
      "bce: 94.419556, kld: 25.077110\n",
      "====> Epoch: 4 Average loss: 2153.5517, bce: 95.1949, kld: 25.7295\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 2095.094238\n",
      "bce: 94.435776, kld: 25.008232\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 2053.307129\n",
      "bce: 93.880066, kld: 24.492838\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 2006.396362\n",
      "bce: 93.520592, kld: 23.910946\n",
      "====> Epoch: 5 Average loss: 2049.1339, bce: 93.9111, kld: 24.4403\n",
      "====> Testing Average Loss: 75.88701363000932\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 1998.745728\n",
      "bce: 93.238174, kld: 23.818844\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 1958.597046\n",
      "bce: 92.862946, kld: 23.321676\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 1912.937134\n",
      "bce: 92.136543, kld: 22.760006\n",
      "====> Epoch: 6 Average loss: 1952.4005, bce: 92.7394, kld: 23.2458\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 1899.709229\n",
      "bce: 92.067787, kld: 22.595518\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 1855.059448\n",
      "bce: 91.390274, kld: 22.045864\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 1824.032959\n",
      "bce: 90.886902, kld: 21.664326\n",
      "====> Epoch: 7 Average loss: 1858.8055, bce: 91.5004, kld: 22.0913\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 1808.057373\n",
      "bce: 90.717026, kld: 21.466755\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 1763.210327\n",
      "bce: 90.037056, kld: 20.914665\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 1723.923462\n",
      "bce: 89.524521, kld: 20.429987\n",
      "====> Epoch: 8 Average loss: 1764.7909, bce: 89.9815, kld: 20.9351\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 1708.137573\n",
      "bce: 89.055374, kld: 20.238527\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 1671.761230\n",
      "bce: 88.479263, kld: 19.791025\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 1622.458618\n",
      "bce: 87.831207, kld: 19.182842\n",
      "====> Epoch: 9 Average loss: 1668.2187, bce: 88.3272, kld: 19.7486\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 1614.876343\n",
      "bce: 87.538467, kld: 19.091724\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 1569.656250\n",
      "bce: 86.882683, kld: 18.534670\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 1518.436401\n",
      "bce: 85.993645, kld: 17.905535\n",
      "====> Epoch: 10 Average loss: 1568.2089, bce: 86.6940, kld: 18.5189\n",
      "====> Testing Average Loss: 68.02755957928372\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 1512.766357\n",
      "bce: 85.903824, kld: 17.835781\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 1467.016968\n",
      "bce: 84.974594, kld: 17.275530\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 1416.264404\n",
      "bce: 84.684174, kld: 16.644753\n",
      "====> Epoch: 11 Average loss: 1464.9039, bce: 85.1300, kld: 17.2472\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 1409.383911\n",
      "bce: 84.324661, kld: 16.563240\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 1364.305664\n",
      "bce: 83.677635, kld: 16.007851\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 1308.833496\n",
      "bce: 83.217834, kld: 15.320196\n",
      "====> Epoch: 12 Average loss: 1359.3821, bce: 83.7179, kld: 15.9458\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 1299.706543\n",
      "bce: 83.030548, kld: 15.208450\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 1254.894043\n",
      "bce: 82.445114, kld: 14.655613\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 1204.161377\n",
      "bce: 82.296242, kld: 14.023314\n",
      "====> Epoch: 13 Average loss: 1253.3580, bce: 82.4672, kld: 14.6361\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 1197.198364\n",
      "bce: 82.084152, kld: 13.938928\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 1151.412231\n",
      "bce: 81.325508, kld: 13.376083\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 1100.483521\n",
      "bce: 80.824417, kld: 12.745738\n",
      "====> Epoch: 14 Average loss: 1149.1569, bce: 81.3758, kld: 13.3473\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 1092.846436\n",
      "bce: 80.864403, kld: 12.649776\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 1047.959717\n",
      "bce: 80.385201, kld: 12.094681\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 1002.387207\n",
      "bce: 79.853088, kld: 11.531676\n",
      "====> Epoch: 15 Average loss: 1049.0474, bce: 80.3870, kld: 12.1083\n",
      "====> Testing Average Loss: 61.67805759885501\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 997.126831\n",
      "bce: 79.718895, kld: 11.467600\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 959.058044\n",
      "bce: 79.536255, kld: 10.994022\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 914.265442\n",
      "bce: 79.212425, kld: 10.438163\n",
      "====> Epoch: 16 Average loss: 955.0627, bce: 79.4871, kld: 10.9447\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 910.443665\n",
      "bce: 79.261452, kld: 10.389777\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 867.900635\n",
      "bce: 78.747284, kld: 9.864417\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 835.236511\n",
      "bce: 78.209785, kld: 9.462834\n",
      "====> Epoch: 17 Average loss: 868.4459, bce: 78.6358, kld: 9.8726\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 822.719543\n",
      "bce: 78.252113, kld: 9.305842\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 791.021545\n",
      "bce: 77.726852, kld: 8.916183\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 757.188721\n",
      "bce: 77.615662, kld: 8.494663\n",
      "====> Epoch: 18 Average loss: 789.8797, bce: 77.8287, kld: 8.9006\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 752.041199\n",
      "bce: 77.398270, kld: 8.433037\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 716.010193\n",
      "bce: 77.308479, kld: 7.983771\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 689.436279\n",
      "bce: 76.895355, kld: 7.656762\n",
      "====> Epoch: 19 Average loss: 719.7744, bce: 77.0587, kld: 8.0339\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 685.181335\n",
      "bce: 76.743019, kld: 7.605479\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 653.179321\n",
      "bce: 76.330811, kld: 7.210607\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 631.937439\n",
      "bce: 76.158653, kld: 6.947235\n",
      "====> Epoch: 20 Average loss: 657.5354, bce: 76.3141, kld: 7.2653\n",
      "====> Testing Average Loss: 57.71224495739582\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 628.135742\n",
      "bce: 76.121803, kld: 6.900174\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 601.587646\n",
      "bce: 75.703735, kld: 6.573549\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 577.625977\n",
      "bce: 75.294342, kld: 6.279146\n",
      "====> Epoch: 21 Average loss: 602.8093, bce: 75.5940, kld: 6.5902\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 573.110901\n",
      "bce: 74.932419, kld: 6.227231\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 553.149292\n",
      "bce: 74.797852, kld: 5.979393\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 536.145630\n",
      "bce: 74.616501, kld: 5.769114\n",
      "====> Epoch: 22 Average loss: 554.7785, bce: 74.8928, kld: 5.9986\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 532.644409\n",
      "bce: 74.489311, kld: 5.726939\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 512.567871\n",
      "bce: 74.199272, kld: 5.479608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 495.345734\n",
      "bce: 73.762764, kld: 5.269787\n",
      "====> Epoch: 23 Average loss: 512.7850, bce: 74.2102, kld: 5.4822\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 492.522675\n",
      "bce: 73.861137, kld: 5.233269\n",
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 473.604492\n",
      "bce: 73.293152, kld: 5.003892\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 461.154083\n",
      "bce: 72.937050, kld: 4.852713\n",
      "====> Epoch: 24 Average loss: 476.0164, bce: 73.5503, kld: 5.0308\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 457.011597\n",
      "bce: 73.298264, kld: 4.796417\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 443.955627\n",
      "bce: 72.481506, kld: 4.643426\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 430.259552\n",
      "bce: 72.404030, kld: 4.473194\n",
      "====> Epoch: 25 Average loss: 443.6693, bce: 72.8958, kld: 4.6347\n",
      "====> Testing Average Loss: 54.45946778058847\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 429.034637\n",
      "bce: 72.818886, kld: 4.452697\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 414.156982\n",
      "bce: 72.008972, kld: 4.276850\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 404.007782\n",
      "bce: 72.261269, kld: 4.146832\n",
      "====> Epoch: 26 Average loss: 415.3038, bce: 72.2573, kld: 4.2881\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 400.709259\n",
      "bce: 71.895775, kld: 4.110168\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 390.545410\n",
      "bce: 71.957214, kld: 3.982352\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 379.083191\n",
      "bce: 71.415543, kld: 3.845846\n",
      "====> Epoch: 27 Average loss: 390.2786, bce: 71.6368, kld: 3.9830\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 377.549438\n",
      "bce: 71.366974, kld: 3.827281\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 367.496826\n",
      "bce: 70.859978, kld: 3.707961\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 358.954742\n",
      "bce: 70.878479, kld: 3.600953\n",
      "====> Epoch: 28 Average loss: 368.0750, bce: 71.0197, kld: 3.7132\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 356.811890\n",
      "bce: 70.333115, kld: 3.580984\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 348.744385\n",
      "bce: 70.729126, kld: 3.475191\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 339.491211\n",
      "bce: 70.509628, kld: 3.362270\n",
      "====> Epoch: 29 Average loss: 348.3624, bce: 70.4147, kld: 3.4743\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 337.993713\n",
      "bce: 69.911568, kld: 3.351027\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 330.156525\n",
      "bce: 69.673592, kld: 3.256037\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 324.572418\n",
      "bce: 69.809708, kld: 3.184534\n",
      "====> Epoch: 30 Average loss: 330.7619, bce: 69.8268, kld: 3.2617\n",
      "====> Testing Average Loss: 51.576759294701105\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 322.031799\n",
      "bce: 69.224617, kld: 3.160090\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 313.672974\n",
      "bce: 69.532501, kld: 3.051756\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 308.680908\n",
      "bce: 68.929871, kld: 2.996888\n",
      "====> Epoch: 31 Average loss: 314.9981, bce: 69.2440, kld: 3.0719\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 306.181946\n",
      "bce: 68.758514, kld: 2.967793\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 301.557983\n",
      "bce: 68.961349, kld: 2.907458\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 294.335846\n",
      "bce: 68.791656, kld: 2.819302\n",
      "====> Epoch: 32 Average loss: 300.7660, bce: 68.6731, kld: 2.9012\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 293.931824\n",
      "bce: 68.431183, kld: 2.818758\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 289.068878\n",
      "bce: 68.230743, kld: 2.760477\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 282.916504\n",
      "bce: 68.118538, kld: 2.684975\n",
      "====> Epoch: 33 Average loss: 287.9103, bce: 68.1119, kld: 2.7475\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 280.582764\n",
      "bce: 67.919312, kld: 2.658293\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 275.767029\n",
      "bce: 67.545685, kld: 2.602767\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 271.139404\n",
      "bce: 67.154488, kld: 2.549812\n",
      "====> Epoch: 34 Average loss: 276.2605, bce: 67.5611, kld: 2.6087\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 270.104767\n",
      "bce: 66.815666, kld: 2.541114\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 265.190735\n",
      "bce: 66.813835, kld: 2.479711\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 261.204559\n",
      "bce: 66.895966, kld: 2.428857\n",
      "====> Epoch: 35 Average loss: 265.6622, bce: 67.0196, kld: 2.4830\n",
      "====> Testing Average Loss: 48.94867839668486\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 260.055237\n",
      "bce: 66.663750, kld: 2.417394\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 255.834671\n",
      "bce: 66.748123, kld: 2.363582\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 251.842804\n",
      "bce: 66.122910, kld: 2.321499\n",
      "====> Epoch: 36 Average loss: 255.9443, bce: 66.4823, kld: 2.3683\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 250.604675\n",
      "bce: 65.983162, kld: 2.307769\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 246.065781\n",
      "bce: 66.026688, kld: 2.250489\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 243.256149\n",
      "bce: 65.613571, kld: 2.220532\n",
      "====> Epoch: 37 Average loss: 247.0076, bce: 65.9545, kld: 2.2632\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 242.162811\n",
      "bce: 65.517593, kld: 2.208065\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 237.904175\n",
      "bce: 65.429893, kld: 2.155928\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 235.624069\n",
      "bce: 65.186020, kld: 2.130476\n",
      "====> Epoch: 38 Average loss: 238.8163, bce: 65.4399, kld: 2.1672\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 234.104950\n",
      "bce: 65.209320, kld: 2.111195\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 233.025055\n",
      "bce: 65.496658, kld: 2.094105\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 228.136276\n",
      "bce: 64.710678, kld: 2.042820\n",
      "====> Epoch: 39 Average loss: 231.2114, bce: 64.9288, kld: 2.0785\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 227.101898\n",
      "bce: 64.639977, kld: 2.030774\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 223.557907\n",
      "bce: 64.303223, kld: 1.990684\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 221.757462\n",
      "bce: 64.377380, kld: 1.967251\n",
      "====> Epoch: 40 Average loss: 224.1719, bce: 64.4242, kld: 1.9968\n",
      "====> Testing Average Loss: 46.54238159033417\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 220.337753\n",
      "bce: 64.489395, kld: 1.948104\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 218.944595\n",
      "bce: 64.431473, kld: 1.931414\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 214.240601\n",
      "bce: 63.461128, kld: 1.884743\n",
      "====> Epoch: 41 Average loss: 217.6431, bce: 63.9304, kld: 1.9214\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 213.724976\n",
      "bce: 63.380333, kld: 1.879308\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 211.855301\n",
      "bce: 63.702526, kld: 1.851910\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 209.283234\n",
      "bce: 63.405647, kld: 1.823470\n",
      "====> Epoch: 42 Average loss: 211.5164, bce: 63.4462, kld: 1.8509\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 208.060150\n",
      "bce: 62.954033, kld: 1.813827\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 206.493988\n",
      "bce: 62.649040, kld: 1.798062\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 202.748810\n",
      "bce: 62.824097, kld: 1.749059\n",
      "====> Epoch: 43 Average loss: 205.8131, bce: 62.9642, kld: 1.7856\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 203.526260\n",
      "bce: 63.142994, kld: 1.754791\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 200.890884\n",
      "bce: 62.833958, kld: 1.725712\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 197.416168\n",
      "bce: 61.965973, kld: 1.693127\n",
      "====> Epoch: 44 Average loss: 200.4628, bce: 62.4904, kld: 1.7247\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 197.402466\n",
      "bce: 61.934662, kld: 1.693348\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 194.953217\n",
      "bce: 61.946449, kld: 1.662585\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 193.396271\n",
      "bce: 62.117294, kld: 1.640987\n",
      "====> Epoch: 45 Average loss: 195.4242, bce: 62.0189, kld: 1.6676\n",
      "====> Testing Average Loss: 44.32927539608574\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 193.315750\n",
      "bce: 62.150311, kld: 1.639568\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 190.657501\n",
      "bce: 61.501778, kld: 1.614447\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 188.279282\n",
      "bce: 61.347187, kld: 1.586651\n",
      "====> Epoch: 46 Average loss: 190.7087, bce: 61.5634, kld: 1.6143\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 188.176468\n",
      "bce: 61.685371, kld: 1.581139\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 186.308624\n",
      "bce: 61.134216, kld: 1.564680\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 183.935989\n",
      "bce: 60.495789, kld: 1.543002\n",
      "====> Epoch: 47 Average loss: 186.2321, bce: 61.1108, kld: 1.5640\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 183.456482\n",
      "bce: 60.846764, kld: 1.532622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 182.485809\n",
      "bce: 60.708969, kld: 1.522210\n",
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 180.731674\n",
      "bce: 60.834320, kld: 1.498717\n",
      "====> Epoch: 48 Average loss: 181.9858, bce: 60.6619, kld: 1.5165\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 179.417236\n",
      "bce: 59.962280, kld: 1.493187\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 178.241577\n",
      "bce: 60.354538, kld: 1.473588\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 176.824280\n",
      "bce: 60.227680, kld: 1.457457\n",
      "====> Epoch: 49 Average loss: 177.9791, bce: 60.2241, kld: 1.4719\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 175.892365\n",
      "bce: 60.138119, kld: 1.446928\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 174.126099\n",
      "bce: 59.495026, kld: 1.432888\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 172.556519\n",
      "bce: 59.794903, kld: 1.409520\n",
      "====> Epoch: 50 Average loss: 174.1806, bce: 59.7891, kld: 1.4299\n",
      "====> Testing Average Loss: 42.27257106244175\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 172.063156\n",
      "bce: 59.274223, kld: 1.409862\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 171.565857\n",
      "bce: 59.942593, kld: 1.395291\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 169.059540\n",
      "bce: 59.286789, kld: 1.372159\n",
      "====> Epoch: 51 Average loss: 170.5510, bce: 59.3588, kld: 1.3899\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 168.940765\n",
      "bce: 59.752190, kld: 1.364857\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 166.939941\n",
      "bce: 58.635460, kld: 1.353806\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 164.859161\n",
      "bce: 58.523117, kld: 1.329201\n",
      "====> Epoch: 52 Average loss: 167.0873, bce: 58.9394, kld: 1.3518\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 166.051804\n",
      "bce: 59.009598, kld: 1.338028\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 163.632355\n",
      "bce: 58.825905, kld: 1.310081\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 161.504944\n",
      "bce: 57.712830, kld: 1.297402\n",
      "====> Epoch: 53 Average loss: 163.7798, bce: 58.5169, kld: 1.3158\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 161.589996\n",
      "bce: 57.826302, kld: 1.297046\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 161.375214\n",
      "bce: 58.548943, kld: 1.285328\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 158.588348\n",
      "bce: 57.917007, kld: 1.258392\n",
      "====> Epoch: 54 Average loss: 160.6252, bce: 58.1071, kld: 1.2815\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 158.817490\n",
      "bce: 57.848965, kld: 1.262107\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 157.906525\n",
      "bce: 57.770142, kld: 1.251705\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 156.109039\n",
      "bce: 57.402302, kld: 1.233834\n",
      "====> Epoch: 55 Average loss: 157.5969, bce: 57.7017, kld: 1.2487\n",
      "====> Testing Average Loss: 40.36849079683132\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 155.781189\n",
      "bce: 57.541252, kld: 1.227999\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 154.709869\n",
      "bce: 56.903660, kld: 1.222578\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 153.307388\n",
      "bce: 57.075237, kld: 1.202902\n",
      "====> Epoch: 56 Average loss: 154.7055, bce: 57.3020, kld: 1.2175\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 153.171158\n",
      "bce: 56.982307, kld: 1.202361\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 151.760101\n",
      "bce: 56.825050, kld: 1.186688\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 150.515442\n",
      "bce: 56.568550, kld: 1.174336\n",
      "====> Epoch: 57 Average loss: 151.9142, bce: 56.9049, kld: 1.1876\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 150.571335\n",
      "bce: 56.697781, kld: 1.173419\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 149.167542\n",
      "bce: 56.485199, kld: 1.158529\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 147.487106\n",
      "bce: 56.157223, kld: 1.141624\n",
      "====> Epoch: 58 Average loss: 149.2421, bce: 56.5171, kld: 1.1591\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 147.724228\n",
      "bce: 56.071053, kld: 1.145665\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 146.748108\n",
      "bce: 56.178875, kld: 1.132115\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 145.801727\n",
      "bce: 56.355537, kld: 1.118078\n",
      "====> Epoch: 59 Average loss: 146.6533, bce: 56.1258, kld: 1.1316\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 144.889801\n",
      "bce: 55.585754, kld: 1.116301\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 143.858917\n",
      "bce: 55.181427, kld: 1.108469\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 143.756042\n",
      "bce: 56.171783, kld: 1.094803\n",
      "====> Epoch: 60 Average loss: 144.1835, bce: 55.7500, kld: 1.1054\n",
      "====> Testing Average Loss: 38.60269313340434\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 142.903198\n",
      "bce: 55.508278, kld: 1.092436\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 141.414841\n",
      "bce: 55.300411, kld: 1.076430\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 141.048615\n",
      "bce: 55.426781, kld: 1.070273\n",
      "====> Epoch: 61 Average loss: 141.7883, bce: 55.3732, kld: 1.0802\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 140.234802\n",
      "bce: 55.005299, kld: 1.065369\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 140.119598\n",
      "bce: 55.410774, kld: 1.058860\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 138.053711\n",
      "bce: 54.431900, kld: 1.045273\n",
      "====> Epoch: 62 Average loss: 139.4803, bce: 55.0018, kld: 1.0560\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 138.267334\n",
      "bce: 54.736664, kld: 1.044133\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 137.211426\n",
      "bce: 54.678131, kld: 1.031666\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 136.800049\n",
      "bce: 55.137047, kld: 1.020788\n",
      "====> Epoch: 63 Average loss: 137.2573, bce: 54.6439, kld: 1.0327\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 136.078751\n",
      "bce: 54.456909, kld: 1.020273\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 135.543243\n",
      "bce: 54.907047, kld: 1.007952\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 133.870102\n",
      "bce: 53.769588, kld: 1.001256\n",
      "====> Epoch: 64 Average loss: 135.0933, bce: 54.2782, kld: 1.0102\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 134.186676\n",
      "bce: 54.369610, kld: 0.997713\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 133.294067\n",
      "bce: 54.110519, kld: 0.989794\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 131.371872\n",
      "bce: 53.180531, kld: 0.977392\n",
      "====> Epoch: 65 Average loss: 132.9945, bce: 53.9196, kld: 0.9884\n",
      "====> Testing Average Loss: 36.97475785514579\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 131.923340\n",
      "bce: 53.878845, kld: 0.975556\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 130.772247\n",
      "bce: 53.293056, kld: 0.968490\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 130.710602\n",
      "bce: 53.792747, kld: 0.961473\n",
      "====> Epoch: 66 Average loss: 130.9642, bce: 53.5663, kld: 0.9675\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 129.768082\n",
      "bce: 53.295006, kld: 0.955913\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 128.852020\n",
      "bce: 53.168503, kld: 0.946044\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 127.971802\n",
      "bce: 52.874950, kld: 0.938711\n",
      "====> Epoch: 67 Average loss: 128.9938, bce: 53.2168, kld: 0.9472\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 128.133133\n",
      "bce: 53.118774, kld: 0.937680\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 126.870094\n",
      "bce: 52.930565, kld: 0.924244\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 126.509468\n",
      "bce: 52.789871, kld: 0.921495\n",
      "====> Epoch: 68 Average loss: 127.0896, bce: 52.8734, kld: 0.9277\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 126.345001\n",
      "bce: 52.674625, kld: 0.920880\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 125.163231\n",
      "bce: 52.548897, kld: 0.907679\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 124.599731\n",
      "bce: 52.686726, kld: 0.898913\n",
      "====> Epoch: 69 Average loss: 125.2453, bce: 52.5354, kld: 0.9089\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 124.204292\n",
      "bce: 52.239815, kld: 0.899556\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 123.942680\n",
      "bce: 52.536247, kld: 0.892580\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 122.642555\n",
      "bce: 52.005203, kld: 0.882967\n",
      "====> Epoch: 70 Average loss: 123.4423, bce: 52.1995, kld: 0.8905\n",
      "====> Testing Average Loss: 35.47500436859273\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 121.921341\n",
      "bce: 51.557400, kld: 0.879549\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 122.214302\n",
      "bce: 52.528587, kld: 0.871071\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 120.807297\n",
      "bce: 51.344891, kld: 0.868280\n",
      "====> Epoch: 71 Average loss: 121.6990, bce: 51.8717, kld: 0.8728\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 120.488724\n",
      "bce: 51.357670, kld: 0.864138\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 119.950012\n",
      "bce: 51.323238, kld: 0.857835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 119.222237\n",
      "bce: 51.248253, kld: 0.849675\n",
      "====> Epoch: 72 Average loss: 119.9941, bce: 51.5452, kld: 0.8556\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 118.845421\n",
      "bce: 51.067085, kld: 0.847229\n",
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 118.810638\n",
      "bce: 51.673561, kld: 0.839213\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 117.725990\n",
      "bce: 51.207863, kld: 0.831477\n",
      "====> Epoch: 73 Average loss: 118.3326, bce: 51.2147, kld: 0.8390\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 117.968742\n",
      "bce: 51.670387, kld: 0.828729\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 116.306984\n",
      "bce: 50.349174, kld: 0.824473\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 116.138596\n",
      "bce: 50.796520, kld: 0.816776\n",
      "====> Epoch: 74 Average loss: 116.7256, bce: 50.9032, kld: 0.8228\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 116.275383\n",
      "bce: 51.066711, kld: 0.815108\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 115.202698\n",
      "bce: 50.624756, kld: 0.807224\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 114.221184\n",
      "bce: 50.326797, kld: 0.798680\n",
      "====> Epoch: 75 Average loss: 115.1500, bce: 50.5813, kld: 0.8071\n",
      "====> Testing Average Loss: 34.04562995107176\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 114.070732\n",
      "bce: 50.226906, kld: 0.798048\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 113.668640\n",
      "bce: 50.554974, kld: 0.788921\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 113.120926\n",
      "bce: 50.237202, kld: 0.786047\n",
      "====> Epoch: 76 Average loss: 113.6195, bce: 50.2723, kld: 0.7918\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 112.525383\n",
      "bce: 49.781235, kld: 0.784302\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 112.422882\n",
      "bce: 50.267509, kld: 0.776942\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 111.918228\n",
      "bce: 50.197357, kld: 0.771511\n",
      "====> Epoch: 77 Average loss: 112.1208, bce: 49.9639, kld: 0.7770\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 111.688065\n",
      "bce: 50.129959, kld: 0.769476\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 110.857819\n",
      "bce: 49.768517, kld: 0.763616\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 109.346085\n",
      "bce: 48.992043, kld: 0.754425\n",
      "====> Epoch: 78 Average loss: 110.6669, bce: 49.6613, kld: 0.7626\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 110.017746\n",
      "bce: 49.511887, kld: 0.756323\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 109.260544\n",
      "bce: 49.457222, kld: 0.747541\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 108.986565\n",
      "bce: 49.724403, kld: 0.740777\n",
      "====> Epoch: 79 Average loss: 109.2484, bce: 49.3643, kld: 0.7486\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 108.396179\n",
      "bce: 49.079144, kld: 0.741463\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 107.870071\n",
      "bce: 49.169411, kld: 0.733758\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 107.492577\n",
      "bce: 49.042435, kld: 0.730627\n",
      "====> Epoch: 80 Average loss: 107.8566, bce: 49.0656, kld: 0.7349\n",
      "====> Testing Average Loss: 32.76114303188657\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 106.775490\n",
      "bce: 48.507072, kld: 0.728355\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 106.249405\n",
      "bce: 48.609276, kld: 0.720502\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 106.564011\n",
      "bce: 49.212833, kld: 0.716890\n",
      "====> Epoch: 81 Average loss: 106.5007, bce: 48.7723, kld: 0.7216\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 106.182770\n",
      "bce: 48.947098, kld: 0.715446\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 105.237221\n",
      "bce: 48.506844, kld: 0.709130\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 104.720673\n",
      "bce: 48.669647, kld: 0.700638\n",
      "====> Epoch: 82 Average loss: 105.1742, bce: 48.4843, kld: 0.7086\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 104.498459\n",
      "bce: 48.264271, kld: 0.702927\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 104.365036\n",
      "bce: 48.705856, kld: 0.695740\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 103.175056\n",
      "bce: 47.763943, kld: 0.692639\n",
      "====> Epoch: 83 Average loss: 103.8862, bce: 48.2038, kld: 0.6960\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 103.302055\n",
      "bce: 48.152832, kld: 0.689365\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 102.935806\n",
      "bce: 48.324852, kld: 0.682637\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 102.221458\n",
      "bce: 47.862984, kld: 0.679481\n",
      "====> Epoch: 84 Average loss: 102.6086, bce: 47.9143, kld: 0.6837\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 102.044655\n",
      "bce: 47.913979, kld: 0.676633\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 101.265953\n",
      "bce: 47.555237, kld: 0.671384\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 100.677979\n",
      "bce: 47.298851, kld: 0.667239\n",
      "====> Epoch: 85 Average loss: 101.3800, bce: 47.6416, kld: 0.6717\n",
      "====> Testing Average Loss: 31.474701687524963\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 101.064613\n",
      "bce: 47.741173, kld: 0.666543\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 99.621056\n",
      "bce: 46.873222, kld: 0.659348\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 99.677673\n",
      "bce: 47.419754, kld: 0.653224\n",
      "====> Epoch: 86 Average loss: 100.1636, bce: 47.3633, kld: 0.6600\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 99.046707\n",
      "bce: 46.809387, kld: 0.652967\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 99.487610\n",
      "bce: 47.436237, kld: 0.650642\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 98.337929\n",
      "bce: 46.894608, kld: 0.643041\n",
      "====> Epoch: 87 Average loss: 98.9752, bce: 47.0941, kld: 0.6485\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 97.954346\n",
      "bce: 46.522224, kld: 0.642901\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 97.431961\n",
      "bce: 46.561760, kld: 0.635878\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 97.719330\n",
      "bce: 47.006409, kld: 0.633911\n",
      "====> Epoch: 88 Average loss: 97.8261, bce: 46.8280, kld: 0.6375\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 96.954468\n",
      "bce: 46.383118, kld: 0.632142\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 96.768852\n",
      "bce: 46.703278, kld: 0.625820\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 95.946922\n",
      "bce: 46.330284, kld: 0.620208\n",
      "====> Epoch: 89 Average loss: 96.6774, bce: 46.5562, kld: 0.6265\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 96.374466\n",
      "bce: 46.773235, kld: 0.620015\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 95.510757\n",
      "bce: 46.223663, kld: 0.616089\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 95.207970\n",
      "bce: 46.345783, kld: 0.610777\n",
      "====> Epoch: 90 Average loss: 95.5578, bce: 46.2920, kld: 0.6158\n",
      "====> Testing Average Loss: 30.303891792038343\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 94.665604\n",
      "bce: 45.861145, kld: 0.610056\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 94.753281\n",
      "bce: 46.270142, kld: 0.606039\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 93.532623\n",
      "bce: 45.424713, kld: 0.601349\n",
      "====> Epoch: 91 Average loss: 94.4718, bce: 46.0345, kld: 0.6055\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 93.985947\n",
      "bce: 45.895908, kld: 0.601126\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 93.503830\n",
      "bce: 45.853821, kld: 0.595625\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 92.678833\n",
      "bce: 45.437912, kld: 0.590512\n",
      "====> Epoch: 92 Average loss: 93.4098, bce: 45.7870, kld: 0.5953\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 92.880577\n",
      "bce: 45.653099, kld: 0.590343\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 92.569962\n",
      "bce: 45.693123, kld: 0.585961\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 91.999062\n",
      "bce: 45.460754, kld: 0.581729\n",
      "====> Epoch: 93 Average loss: 92.3611, bce: 45.5320, kld: 0.5854\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 91.445564\n",
      "bce: 45.126755, kld: 0.578985\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 91.422699\n",
      "bce: 45.368008, kld: 0.575684\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 91.143646\n",
      "bce: 45.494972, kld: 0.570608\n",
      "====> Epoch: 94 Average loss: 91.3405, bce: 45.2862, kld: 0.5757\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 90.712936\n",
      "bce: 45.017048, kld: 0.571199\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 90.237610\n",
      "bce: 44.874290, kld: 0.567041\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 89.951660\n",
      "bce: 45.050346, kld: 0.561266\n",
      "====> Epoch: 95 Average loss: 90.3210, bce: 45.0307, kld: 0.5661\n",
      "====> Testing Average Loss: 29.21312699707096\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 89.912987\n",
      "bce: 45.018673, kld: 0.561179\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 89.357758\n",
      "bce: 44.817390, kld: 0.556755\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 88.886307\n",
      "bce: 44.751095, kld: 0.551690\n",
      "====> Epoch: 96 Average loss: 89.3363, bce: 44.7862, kld: 0.5569\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 88.635948\n",
      "bce: 44.422237, kld: 0.552671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 88.606339\n",
      "bce: 44.737534, kld: 0.548360\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 88.642548\n",
      "bce: 45.160416, kld: 0.543527\n",
      "====> Epoch: 97 Average loss: 88.3684, bce: 44.5495, kld: 0.5477\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 87.746780\n",
      "bce: 44.462795, kld: 0.541050\n",
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 87.593552\n",
      "bce: 44.477039, kld: 0.538956\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 87.118896\n",
      "bce: 44.398510, kld: 0.534005\n",
      "====> Epoch: 98 Average loss: 87.4141, bce: 44.3077, kld: 0.5388\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 86.484390\n",
      "bce: 43.782211, kld: 0.533777\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 86.705460\n",
      "bce: 44.244469, kld: 0.530762\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 86.144135\n",
      "bce: 44.036053, kld: 0.526351\n",
      "====> Epoch: 99 Average loss: 86.4815, bce: 44.0711, kld: 0.5301\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 86.106140\n",
      "bce: 44.026123, kld: 0.526000\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 85.612701\n",
      "bce: 43.785316, kld: 0.522842\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 85.128769\n",
      "bce: 43.802452, kld: 0.516579\n",
      "====> Epoch: 100 Average loss: 85.5664, bce: 43.8399, kld: 0.5216\n",
      "====> Testing Average Loss: 28.184767549261085\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 85.014954\n",
      "bce: 43.658432, kld: 0.516957\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 84.272934\n",
      "bce: 43.254311, kld: 0.512733\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 85.133667\n",
      "bce: 44.287148, kld: 0.510581\n",
      "====> Epoch: 101 Average loss: 84.6611, bce: 43.6042, kld: 0.5132\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 84.551819\n",
      "bce: 43.824543, kld: 0.509091\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 83.770325\n",
      "bce: 43.372883, kld: 0.504968\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 83.463562\n",
      "bce: 43.364464, kld: 0.501239\n",
      "====> Epoch: 102 Average loss: 83.7816, bce: 43.3788, kld: 0.5050\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 83.363052\n",
      "bce: 43.233246, kld: 0.501623\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 83.489243\n",
      "bce: 43.720207, kld: 0.497113\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 82.139694\n",
      "bce: 42.531769, kld: 0.495099\n",
      "====> Epoch: 103 Average loss: 82.9141, bce: 43.1520, kld: 0.4970\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 82.091743\n",
      "bce: 42.675320, kld: 0.492705\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 81.392380\n",
      "bce: 42.268417, kld: 0.489050\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 81.596207\n",
      "bce: 42.791145, kld: 0.485063\n",
      "====> Epoch: 104 Average loss: 82.0553, bce: 42.9227, kld: 0.4892\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 81.862778\n",
      "bce: 43.064182, kld: 0.484982\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 81.249710\n",
      "bce: 42.701950, kld: 0.481847\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 81.041641\n",
      "bce: 42.768036, kld: 0.478420\n",
      "====> Epoch: 105 Average loss: 81.2197, bce: 42.7025, kld: 0.4815\n",
      "====> Testing Average Loss: 27.205825206364\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 80.316345\n",
      "bce: 42.156094, kld: 0.477003\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 80.402817\n",
      "bce: 42.499207, kld: 0.473795\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 79.351944\n",
      "bce: 41.784912, kld: 0.469588\n",
      "====> Epoch: 106 Average loss: 80.4029, bce: 42.4876, kld: 0.4739\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 80.304489\n",
      "bce: 42.735203, kld: 0.469616\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 79.692513\n",
      "bce: 42.393486, kld: 0.466238\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 79.836761\n",
      "bce: 42.679523, kld: 0.464465\n",
      "====> Epoch: 107 Average loss: 79.5961, bce: 42.2731, kld: 0.4665\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 79.058731\n",
      "bce: 42.002922, kld: 0.463198\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 79.374214\n",
      "bce: 42.664894, kld: 0.458867\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 78.452538\n",
      "bce: 41.960472, kld: 0.456151\n",
      "====> Epoch: 108 Average loss: 78.8071, bce: 42.0622, kld: 0.4593\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 78.305794\n",
      "bce: 41.847443, kld: 0.455729\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 78.088394\n",
      "bce: 41.895531, kld: 0.452411\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 77.271225\n",
      "bce: 41.382294, kld: 0.448612\n",
      "====> Epoch: 109 Average loss: 78.0191, bce: 41.8446, kld: 0.4522\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 77.562531\n",
      "bce: 41.778797, kld: 0.447297\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 77.776642\n",
      "bce: 42.086449, kld: 0.446127\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 77.050766\n",
      "bce: 41.591923, kld: 0.443236\n",
      "====> Epoch: 110 Average loss: 77.2489, bce: 41.6335, kld: 0.4452\n",
      "====> Testing Average Loss: 26.268557157835176\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 77.203339\n",
      "bce: 41.855835, kld: 0.441844\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 76.945381\n",
      "bce: 41.834221, kld: 0.438890\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 76.248901\n",
      "bce: 41.452019, kld: 0.434961\n",
      "====> Epoch: 111 Average loss: 76.4961, bce: 41.4266, kld: 0.4384\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 75.957184\n",
      "bce: 41.170460, kld: 0.434834\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 75.788246\n",
      "bce: 41.253506, kld: 0.431684\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 75.228485\n",
      "bce: 40.896255, kld: 0.429153\n",
      "====> Epoch: 112 Average loss: 75.7573, bce: 41.2227, kld: 0.4317\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 75.169952\n",
      "bce: 40.892418, kld: 0.428469\n",
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 75.367676\n",
      "bce: 41.341873, kld: 0.425323\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 75.045212\n",
      "bce: 41.220009, kld: 0.422815\n",
      "====> Epoch: 113 Average loss: 75.0238, bce: 41.0178, kld: 0.4251\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 74.308800\n",
      "bce: 40.646538, kld: 0.420778\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 74.392212\n",
      "bce: 40.918877, kld: 0.418417\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 73.717041\n",
      "bce: 40.467163, kld: 0.415623\n",
      "====> Epoch: 114 Average loss: 74.3056, bce: 40.8131, kld: 0.4187\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 74.330627\n",
      "bce: 41.100849, kld: 0.415372\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 73.106644\n",
      "bce: 40.178234, kld: 0.411605\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 73.173943\n",
      "bce: 40.396088, kld: 0.409723\n",
      "====> Epoch: 115 Average loss: 73.6061, bce: 40.6186, kld: 0.4123\n",
      "====> Testing Average Loss: 25.41600444348289\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 73.851822\n",
      "bce: 41.116425, kld: 0.409192\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 72.962563\n",
      "bce: 40.509201, kld: 0.405667\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 72.387520\n",
      "bce: 40.134995, kld: 0.403157\n",
      "====> Epoch: 116 Average loss: 72.9119, bce: 40.4250, kld: 0.4061\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 71.782639\n",
      "bce: 39.615341, kld: 0.402091\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 72.521255\n",
      "bce: 40.542763, kld: 0.399731\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 72.625740\n",
      "bce: 40.849922, kld: 0.397198\n",
      "====> Epoch: 117 Average loss: 72.2233, bce: 40.2227, kld: 0.4000\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 72.294128\n",
      "bce: 40.488182, kld: 0.397574\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 71.764015\n",
      "bce: 40.231697, kld: 0.394154\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 70.923599\n",
      "bce: 39.591393, kld: 0.391653\n",
      "====> Epoch: 118 Average loss: 71.5550, bce: 40.0344, kld: 0.3940\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 70.500931\n",
      "bce: 39.297333, kld: 0.390045\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 71.210907\n",
      "bce: 40.118679, kld: 0.388653\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 71.000786\n",
      "bce: 40.138359, kld: 0.385780\n",
      "====> Epoch: 119 Average loss: 70.8970, bce: 39.8440, kld: 0.3882\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 70.547356\n",
      "bce: 39.771259, kld: 0.384701\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 70.560539\n",
      "bce: 39.940807, kld: 0.382747\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 70.136421\n",
      "bce: 39.698345, kld: 0.380476\n",
      "====> Epoch: 120 Average loss: 70.2396, bce: 39.6502, kld: 0.3824\n",
      "====> Testing Average Loss: 24.616965949940088\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 70.073349\n",
      "bce: 39.758801, kld: 0.378932\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 69.554878\n",
      "bce: 39.422081, kld: 0.376660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 69.206184\n",
      "bce: 39.269882, kld: 0.374204\n",
      "====> Epoch: 121 Average loss: 69.5993, bce: 39.4622, kld: 0.3767\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 69.066711\n",
      "bce: 39.155022, kld: 0.373896\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 68.712082\n",
      "bce: 38.976021, kld: 0.371701\n",
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 69.176125\n",
      "bce: 39.678883, kld: 0.368716\n",
      "====> Epoch: 122 Average loss: 68.9631, bce: 39.2703, kld: 0.3712\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 68.906357\n",
      "bce: 39.500153, kld: 0.367578\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 68.341156\n",
      "bce: 39.061241, kld: 0.365999\n",
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 67.703888\n",
      "bce: 38.638405, kld: 0.363319\n",
      "====> Epoch: 123 Average loss: 68.3527, bce: 39.0966, kld: 0.3657\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 67.563599\n",
      "bce: 38.581196, kld: 0.362280\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 67.499115\n",
      "bce: 38.640289, kld: 0.360735\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 67.538834\n",
      "bce: 38.892372, kld: 0.358081\n",
      "====> Epoch: 124 Average loss: 67.7380, bce: 38.9113, kld: 0.3603\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 66.998856\n",
      "bce: 38.393757, kld: 0.357564\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 66.966721\n",
      "bce: 38.554474, kld: 0.355153\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 66.904945\n",
      "bce: 38.692894, kld: 0.352651\n",
      "====> Epoch: 125 Average loss: 67.1398, bce: 38.7332, kld: 0.3551\n",
      "====> Testing Average Loss: 23.82811875915324\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 66.253944\n",
      "bce: 38.067970, kld: 0.352325\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 66.892838\n",
      "bce: 38.929108, kld: 0.349547\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 66.223885\n",
      "bce: 38.380135, kld: 0.348047\n",
      "====> Epoch: 126 Average loss: 66.5412, bce: 38.5508, kld: 0.3499\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 66.464844\n",
      "bce: 38.733440, kld: 0.346642\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 65.858337\n",
      "bce: 38.254707, kld: 0.345045\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 65.870728\n",
      "bce: 38.451263, kld: 0.342743\n",
      "====> Epoch: 127 Average loss: 65.9599, bce: 38.3746, kld: 0.3448\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 65.983841\n",
      "bce: 38.615784, kld: 0.342101\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 65.530502\n",
      "bce: 38.336178, kld: 0.339929\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 65.351021\n",
      "bce: 38.317131, kld: 0.337924\n",
      "====> Epoch: 128 Average loss: 65.3872, bce: 38.2006, kld: 0.3398\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 65.758545\n",
      "bce: 38.754665, kld: 0.337548\n",
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 64.462883\n",
      "bce: 37.718266, kld: 0.334308\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 65.090935\n",
      "bce: 38.440941, kld: 0.333125\n",
      "====> Epoch: 129 Average loss: 64.8264, bce: 38.0322, kld: 0.3349\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 64.421387\n",
      "bce: 37.853252, kld: 0.332102\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 64.417702\n",
      "bce: 37.996685, kld: 0.330263\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 64.012436\n",
      "bce: 37.746780, kld: 0.328321\n",
      "====> Epoch: 130 Average loss: 64.2666, bce: 37.8571, kld: 0.3301\n",
      "====> Testing Average Loss: 23.196789500399415\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 63.978714\n",
      "bce: 37.794361, kld: 0.327304\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 63.488754\n",
      "bce: 37.413193, kld: 0.325945\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 63.122719\n",
      "bce: 37.257690, kld: 0.323313\n",
      "====> Epoch: 131 Average loss: 63.7224, bce: 37.6899, kld: 0.3254\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 63.587376\n",
      "bce: 37.729927, kld: 0.323218\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 63.241554\n",
      "bce: 37.587738, kld: 0.320673\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 62.562096\n",
      "bce: 37.072067, kld: 0.318625\n",
      "====> Epoch: 132 Average loss: 63.1852, bce: 37.5265, kld: 0.3207\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 62.967758\n",
      "bce: 37.515640, kld: 0.318152\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 62.728008\n",
      "bce: 37.420517, kld: 0.316344\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 62.248611\n",
      "bce: 37.113579, kld: 0.314188\n",
      "====> Epoch: 133 Average loss: 62.6452, bce: 37.3519, kld: 0.3162\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 62.261253\n",
      "bce: 37.171257, kld: 0.313625\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 62.373146\n",
      "bce: 37.441486, kld: 0.311646\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 62.157166\n",
      "bce: 37.325104, kld: 0.310401\n",
      "====> Epoch: 134 Average loss: 62.1181, bce: 37.1841, kld: 0.3117\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 61.883083\n",
      "bce: 37.119453, kld: 0.309545\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 61.287018\n",
      "bce: 36.715546, kld: 0.307143\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 61.560440\n",
      "bce: 37.109310, kld: 0.305639\n",
      "====> Epoch: 135 Average loss: 61.6032, bce: 37.0225, kld: 0.3073\n",
      "====> Testing Average Loss: 22.452349054719743\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 61.018295\n",
      "bce: 36.600773, kld: 0.305219\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 61.066872\n",
      "bce: 36.822094, kld: 0.303060\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 61.005745\n",
      "bce: 36.911938, kld: 0.301173\n",
      "====> Epoch: 136 Average loss: 61.0932, bce: 36.8585, kld: 0.3029\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 61.562103\n",
      "bce: 37.470989, kld: 0.301139\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 60.201130\n",
      "bce: 36.297867, kld: 0.298791\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 60.118927\n",
      "bce: 36.381290, kld: 0.296720\n",
      "====> Epoch: 137 Average loss: 60.5983, bce: 36.7038, kld: 0.2987\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 60.377571\n",
      "bce: 36.657764, kld: 0.296498\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 60.065853\n",
      "bce: 36.518501, kld: 0.294342\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 59.430168\n",
      "bce: 36.018188, kld: 0.292650\n",
      "====> Epoch: 138 Average loss: 60.1130, bce: 36.5544, kld: 0.2945\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 60.022789\n",
      "bce: 36.635895, kld: 0.292336\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 60.241104\n",
      "bce: 36.976151, kld: 0.290812\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 59.646946\n",
      "bce: 36.577168, kld: 0.288372\n",
      "====> Epoch: 139 Average loss: 59.6226, bce: 36.3922, kld: 0.2904\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 59.530693\n",
      "bce: 36.465031, kld: 0.288321\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 59.352306\n",
      "bce: 36.419838, kld: 0.286656\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 58.611115\n",
      "bce: 35.860382, kld: 0.284384\n",
      "====> Epoch: 140 Average loss: 59.1302, bce: 36.2249, kld: 0.2863\n",
      "====> Testing Average Loss: 21.940131036979096\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 58.638687\n",
      "bce: 35.888729, kld: 0.284375\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 58.740345\n",
      "bce: 36.162319, kld: 0.282225\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 58.309818\n",
      "bce: 35.842865, kld: 0.280837\n",
      "====> Epoch: 141 Average loss: 58.6643, bce: 36.0779, kld: 0.2823\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 58.954453\n",
      "bce: 36.520042, kld: 0.280430\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 57.720863\n",
      "bce: 35.448448, kld: 0.278405\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 58.252995\n",
      "bce: 36.138470, kld: 0.276432\n",
      "====> Epoch: 142 Average loss: 58.1959, bce: 35.9224, kld: 0.2784\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 58.557259\n",
      "bce: 36.448708, kld: 0.276357\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 57.818508\n",
      "bce: 35.853775, kld: 0.274559\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 57.370220\n",
      "bce: 35.559151, kld: 0.272638\n",
      "====> Epoch: 143 Average loss: 57.7436, bce: 35.7765, kld: 0.2746\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 57.840427\n",
      "bce: 36.053127, kld: 0.272341\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 57.360600\n",
      "bce: 35.674698, kld: 0.271074\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 57.207611\n",
      "bce: 35.647827, kld: 0.269497\n",
      "====> Epoch: 144 Average loss: 57.2844, bce: 35.6188, kld: 0.2708\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 57.585670\n",
      "bce: 36.063297, kld: 0.269030\n",
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 57.211658\n",
      "bce: 35.861603, kld: 0.266876\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 56.921272\n",
      "bce: 35.663372, kld: 0.265724\n",
      "====> Epoch: 145 Average loss: 56.8447, bce: 35.4785, kld: 0.2671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Testing Average Loss: 21.14348434795633\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 56.284897\n",
      "bce: 35.099575, kld: 0.264816\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 56.100487\n",
      "bce: 35.019234, kld: 0.263516\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 56.274529\n",
      "bce: 35.327515, kld: 0.261838\n",
      "====> Epoch: 146 Average loss: 56.3978, bce: 35.3238, kld: 0.2634\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 55.755680\n",
      "bce: 34.837692, kld: 0.261475\n",
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 56.130905\n",
      "bce: 35.364128, kld: 0.259585\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 55.685783\n",
      "bce: 35.011971, kld: 0.258423\n",
      "====> Epoch: 147 Average loss: 55.9649, bce: 35.1779, kld: 0.2598\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 56.203659\n",
      "bce: 35.566620, kld: 0.257963\n",
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 55.228249\n",
      "bce: 34.712723, kld: 0.256444\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 55.568150\n",
      "bce: 35.202301, kld: 0.254573\n",
      "====> Epoch: 148 Average loss: 55.5350, bce: 35.0303, kld: 0.2563\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 55.772446\n",
      "bce: 35.426571, kld: 0.254323\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 55.769573\n",
      "bce: 35.520309, kld: 0.253116\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 54.828331\n",
      "bce: 34.703728, kld: 0.251558\n",
      "====> Epoch: 149 Average loss: 55.1056, bce: 34.8795, kld: 0.2528\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 55.294235\n",
      "bce: 35.222237, kld: 0.250900\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 54.931808\n",
      "bce: 34.963181, kld: 0.249608\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 54.944115\n",
      "bce: 35.098625, kld: 0.248069\n",
      "====> Epoch: 150 Average loss: 54.7003, bce: 34.7460, kld: 0.2494\n",
      "====> Testing Average Loss: 20.643994537178806\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 53.994415\n",
      "bce: 34.158733, kld: 0.247946\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 54.922310\n",
      "bce: 35.252953, kld: 0.245867\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 54.031792\n",
      "bce: 34.470337, kld: 0.244518\n",
      "====> Epoch: 151 Average loss: 54.2876, bce: 34.6036, kld: 0.2461\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 54.197941\n",
      "bce: 34.597084, kld: 0.245011\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 53.785179\n",
      "bce: 34.342453, kld: 0.243034\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 53.859512\n",
      "bce: 34.575798, kld: 0.241046\n",
      "====> Epoch: 152 Average loss: 53.8748, bce: 34.4510, kld: 0.2428\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 53.790447\n",
      "bce: 34.535770, kld: 0.240683\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 53.519211\n",
      "bce: 34.360382, kld: 0.239485\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 53.166100\n",
      "bce: 34.114449, kld: 0.238146\n",
      "====> Epoch: 153 Average loss: 53.4787, bce: 34.3182, kld: 0.2395\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 53.583241\n",
      "bce: 34.576775, kld: 0.237581\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 53.214294\n",
      "bce: 34.302010, kld: 0.236404\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 52.797615\n",
      "bce: 34.028923, kld: 0.234609\n",
      "====> Epoch: 154 Average loss: 53.0946, bce: 34.1862, kld: 0.2364\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 52.675415\n",
      "bce: 33.917099, kld: 0.234479\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 52.528477\n",
      "bce: 33.864700, kld: 0.233297\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 52.578651\n",
      "bce: 34.043247, kld: 0.231693\n",
      "====> Epoch: 155 Average loss: 52.6882, bce: 34.0336, kld: 0.2332\n",
      "====> Testing Average Loss: 20.087309966216218\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 51.904915\n",
      "bce: 33.387157, kld: 0.231472\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 52.431820\n",
      "bce: 34.037903, kld: 0.229924\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 52.540520\n",
      "bce: 34.240261, kld: 0.228753\n",
      "====> Epoch: 156 Average loss: 52.3204, bce: 33.9166, kld: 0.2300\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 52.190350\n",
      "bce: 33.892624, kld: 0.228722\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 52.204437\n",
      "bce: 34.046593, kld: 0.226973\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 51.776009\n",
      "bce: 33.702072, kld: 0.225924\n",
      "====> Epoch: 157 Average loss: 51.9327, bce: 33.7742, kld: 0.2270\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 51.658550\n",
      "bce: 33.629761, kld: 0.225360\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 51.320503\n",
      "bce: 33.401657, kld: 0.223986\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 51.300484\n",
      "bce: 33.492630, kld: 0.222598\n",
      "====> Epoch: 158 Average loss: 51.5592, bce: 33.6406, kld: 0.2240\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 51.560299\n",
      "bce: 33.767933, kld: 0.222405\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 51.592400\n",
      "bce: 33.894852, kld: 0.221219\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 51.045795\n",
      "bce: 33.452202, kld: 0.219920\n",
      "====> Epoch: 159 Average loss: 51.2086, bce: 33.5220, kld: 0.2211\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 50.817158\n",
      "bce: 33.264526, kld: 0.219408\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 50.888115\n",
      "bce: 33.411835, kld: 0.218453\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 50.834835\n",
      "bce: 33.485245, kld: 0.216870\n",
      "====> Epoch: 160 Average loss: 50.8416, bce: 33.3828, kld: 0.2182\n",
      "====> Testing Average Loss: 19.608572531121023\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 50.293968\n",
      "bce: 32.942741, kld: 0.216890\n",
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 50.435966\n",
      "bce: 33.222229, kld: 0.215172\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 49.923573\n",
      "bce: 32.785812, kld: 0.214222\n",
      "====> Epoch: 161 Average loss: 50.4738, bce: 33.2476, kld: 0.2153\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 50.343071\n",
      "bce: 33.250996, kld: 0.213651\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 49.273613\n",
      "bce: 32.265427, kld: 0.212602\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 49.746422\n",
      "bce: 32.828644, kld: 0.211472\n",
      "====> Epoch: 162 Average loss: 50.1229, bce: 33.1242, kld: 0.2125\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 50.190151\n",
      "bce: 33.321445, kld: 0.210859\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 49.888008\n",
      "bce: 33.115562, kld: 0.209656\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 49.663033\n",
      "bce: 32.977757, kld: 0.208566\n",
      "====> Epoch: 163 Average loss: 49.7704, bce: 32.9956, kld: 0.2097\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 49.232559\n",
      "bce: 32.579956, kld: 0.208158\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 49.591438\n",
      "bce: 33.014759, kld: 0.207208\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 49.283020\n",
      "bce: 32.828342, kld: 0.205683\n",
      "====> Epoch: 164 Average loss: 49.4232, bce: 32.8628, kld: 0.2070\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 49.152454\n",
      "bce: 32.689587, kld: 0.205786\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 48.893166\n",
      "bce: 32.540409, kld: 0.204409\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 49.525185\n",
      "bce: 33.284554, kld: 0.203008\n",
      "====> Epoch: 165 Average loss: 49.0949, bce: 32.7502, kld: 0.2043\n",
      "====> Testing Average Loss: 19.06541031487152\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 49.014027\n",
      "bce: 32.792549, kld: 0.202768\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 48.142063\n",
      "bce: 32.014580, kld: 0.201594\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 48.550430\n",
      "bce: 32.500458, kld: 0.200625\n",
      "====> Epoch: 166 Average loss: 48.7476, bce: 32.6158, kld: 0.2016\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 47.990368\n",
      "bce: 31.977129, kld: 0.200165\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 48.245838\n",
      "bce: 32.332561, kld: 0.198916\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 48.184181\n",
      "bce: 32.359947, kld: 0.197803\n",
      "====> Epoch: 167 Average loss: 48.4193, bce: 32.4961, kld: 0.1990\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 48.253937\n",
      "bce: 32.448483, kld: 0.197568\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 48.045364\n",
      "bce: 32.316242, kld: 0.196614\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 47.671188\n",
      "bce: 32.028927, kld: 0.195528\n",
      "====> Epoch: 168 Average loss: 48.1157, bce: 32.3980, kld: 0.1965\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 48.266426\n",
      "bce: 32.647202, kld: 0.195240\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 47.750687\n",
      "bce: 32.188931, kld: 0.194522\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 47.929680\n",
      "bce: 32.485138, kld: 0.193057\n",
      "====> Epoch: 169 Average loss: 47.7834, bce: 32.2625, kld: 0.1940\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 48.202309\n",
      "bce: 32.784458, kld: 0.192723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 47.529167\n",
      "bce: 32.203121, kld: 0.191576\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 47.309635\n",
      "bce: 32.057793, kld: 0.190648\n",
      "====> Epoch: 170 Average loss: 47.4659, bce: 32.1452, kld: 0.1915\n",
      "====> Testing Average Loss: 18.652133121421915\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 47.773415\n",
      "bce: 32.558739, kld: 0.190183\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 47.791893\n",
      "bce: 32.641991, kld: 0.189374\n",
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 46.827290\n",
      "bce: 31.788769, kld: 0.187982\n",
      "====> Epoch: 171 Average loss: 47.1325, bce: 32.0110, kld: 0.1890\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 46.883434\n",
      "bce: 31.866419, kld: 0.187713\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 46.760365\n",
      "bce: 31.819176, kld: 0.186765\n",
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 46.416405\n",
      "bce: 31.560928, kld: 0.185693\n",
      "====> Epoch: 172 Average loss: 46.8560, bce: 31.9198, kld: 0.1867\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 46.879730\n",
      "bce: 32.054649, kld: 0.185313\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 46.567619\n",
      "bce: 31.818199, kld: 0.184368\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 46.080437\n",
      "bce: 31.422615, kld: 0.183223\n",
      "====> Epoch: 173 Average loss: 46.5429, bce: 31.8010, kld: 0.1843\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 46.722755\n",
      "bce: 32.094826, kld: 0.182849\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 46.020973\n",
      "bce: 31.457531, kld: 0.182043\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 45.898537\n",
      "bce: 31.415123, kld: 0.181043\n",
      "====> Epoch: 174 Average loss: 46.2222, bce: 31.6699, kld: 0.1819\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 45.606182\n",
      "bce: 31.168209, kld: 0.180475\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 46.316643\n",
      "bce: 31.950651, kld: 0.179575\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 45.830494\n",
      "bce: 31.531361, kld: 0.178739\n",
      "====> Epoch: 175 Average loss: 45.9218, bce: 31.5554, kld: 0.1796\n",
      "====> Testing Average Loss: 18.181728256889894\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 45.751286\n",
      "bce: 31.494770, kld: 0.178206\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 45.036999\n",
      "bce: 30.855183, kld: 0.177273\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 45.367786\n",
      "bce: 31.263720, kld: 0.176301\n",
      "====> Epoch: 176 Average loss: 45.6265, bce: 31.4401, kld: 0.1773\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 45.696609\n",
      "bce: 31.603474, kld: 0.176164\n",
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 45.408279\n",
      "bce: 31.390501, kld: 0.175222\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 44.667366\n",
      "bce: 30.748747, kld: 0.173983\n",
      "====> Epoch: 177 Average loss: 45.3479, bce: 31.3385, kld: 0.1751\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 45.239864\n",
      "bce: 31.326206, kld: 0.173921\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 45.502857\n",
      "bce: 31.676861, kld: 0.172825\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 44.680977\n",
      "bce: 30.918859, kld: 0.172026\n",
      "====> Epoch: 178 Average loss: 45.0444, bce: 31.2100, kld: 0.1729\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 44.529022\n",
      "bce: 30.784679, kld: 0.171804\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 45.514999\n",
      "bce: 31.862644, kld: 0.170654\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 44.404476\n",
      "bce: 30.813835, kld: 0.169883\n",
      "====> Epoch: 179 Average loss: 44.7744, bce: 31.1146, kld: 0.1707\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 45.184944\n",
      "bce: 31.589081, kld: 0.169948\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 44.088608\n",
      "bce: 30.563538, kld: 0.169063\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 44.148880\n",
      "bce: 30.721237, kld: 0.167846\n",
      "====> Epoch: 180 Average loss: 44.5135, bce: 31.0142, kld: 0.1687\n",
      "====> Testing Average Loss: 17.886159154074026\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 44.384171\n",
      "bce: 30.979734, kld: 0.167555\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 44.289066\n",
      "bce: 30.957388, kld: 0.166646\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 44.052467\n",
      "bce: 30.811367, kld: 0.165514\n",
      "====> Epoch: 181 Average loss: 44.2006, bce: 30.8766, kld: 0.1666\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 44.210159\n",
      "bce: 30.974730, kld: 0.165443\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 44.151649\n",
      "bce: 30.998812, kld: 0.164410\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 43.637260\n",
      "bce: 30.569363, kld: 0.163349\n",
      "====> Epoch: 182 Average loss: 43.9316, bce: 30.7779, kld: 0.1644\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 43.940651\n",
      "bce: 30.877666, kld: 0.163287\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 43.051212\n",
      "bce: 30.060753, kld: 0.162381\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 43.893654\n",
      "bce: 30.977566, kld: 0.161451\n",
      "====> Epoch: 183 Average loss: 43.6573, bce: 30.6673, kld: 0.1624\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 43.843796\n",
      "bce: 30.963470, kld: 0.161004\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 43.745289\n",
      "bce: 30.904858, kld: 0.160505\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 43.593536\n",
      "bce: 30.840225, kld: 0.159416\n",
      "====> Epoch: 184 Average loss: 43.3841, bce: 30.5580, kld: 0.1603\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 43.306564\n",
      "bce: 30.563335, kld: 0.159290\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 43.498703\n",
      "bce: 30.834671, kld: 0.158300\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 42.672970\n",
      "bce: 30.066446, kld: 0.157582\n",
      "====> Epoch: 185 Average loss: 43.1431, bce: 30.4737, kld: 0.1584\n",
      "====> Testing Average Loss: 17.34490715700306\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 42.883865\n",
      "bce: 30.292332, kld: 0.157394\n",
      "Train Epoch: 186 [10240/22533 (45%)]      Loss: 43.432999\n",
      "bce: 30.897373, kld: 0.156695\n",
      "Train Epoch: 186 [20480/22533 (91%)]      Loss: 42.870441\n",
      "bce: 30.409012, kld: 0.155768\n",
      "====> Epoch: 186 Average loss: 42.8642, bce: 30.3508, kld: 0.1564\n",
      "Train Epoch: 187 [   0/22533 ( 0%)]      Loss: 42.437443\n",
      "bce: 30.001518, kld: 0.155449\n",
      "Train Epoch: 187 [10240/22533 (45%)]      Loss: 42.492065\n",
      "bce: 30.164856, kld: 0.154090\n",
      "Train Epoch: 187 [20480/22533 (91%)]      Loss: 42.382004\n",
      "bce: 30.093805, kld: 0.153602\n",
      "====> Epoch: 187 Average loss: 42.6444, bce: 30.2842, kld: 0.1545\n",
      "Train Epoch: 188 [   0/22533 ( 0%)]      Loss: 42.498123\n",
      "bce: 30.200825, kld: 0.153716\n",
      "Train Epoch: 188 [10240/22533 (45%)]      Loss: 42.291496\n",
      "bce: 30.097588, kld: 0.152424\n",
      "Train Epoch: 188 [20480/22533 (91%)]      Loss: 42.022423\n",
      "bce: 29.868979, kld: 0.151918\n",
      "====> Epoch: 188 Average loss: 42.3504, bce: 30.1405, kld: 0.1526\n",
      "Train Epoch: 189 [   0/22533 ( 0%)]      Loss: 42.406822\n",
      "bce: 30.280727, kld: 0.151576\n",
      "Train Epoch: 189 [10240/22533 (45%)]      Loss: 41.936001\n",
      "bce: 29.863354, kld: 0.150908\n",
      "Train Epoch: 189 [20480/22533 (91%)]      Loss: 42.142208\n",
      "bce: 30.167376, kld: 0.149685\n",
      "====> Epoch: 189 Average loss: 42.1181, bce: 30.0546, kld: 0.1508\n",
      "Train Epoch: 190 [   0/22533 ( 0%)]      Loss: 41.928589\n",
      "bce: 29.937019, kld: 0.149895\n",
      "Train Epoch: 190 [10240/22533 (45%)]      Loss: 41.952934\n",
      "bce: 30.046274, kld: 0.148833\n",
      "Train Epoch: 190 [20480/22533 (91%)]      Loss: 42.065529\n",
      "bce: 30.225937, kld: 0.147995\n",
      "====> Epoch: 190 Average loss: 41.8632, bce: 29.9496, kld: 0.1489\n",
      "====> Testing Average Loss: 16.81957972057649\n",
      "Train Epoch: 191 [   0/22533 ( 0%)]      Loss: 41.930569\n",
      "bce: 30.084665, kld: 0.148074\n",
      "Train Epoch: 191 [10240/22533 (45%)]      Loss: 42.156479\n",
      "bce: 30.395090, kld: 0.147017\n",
      "Train Epoch: 191 [20480/22533 (91%)]      Loss: 41.830372\n",
      "bce: 30.134968, kld: 0.146193\n",
      "====> Epoch: 191 Average loss: 41.6321, bce: 29.8594, kld: 0.1472\n",
      "Train Epoch: 192 [   0/22533 ( 0%)]      Loss: 41.294373\n",
      "bce: 29.599216, kld: 0.146189\n",
      "Train Epoch: 192 [10240/22533 (45%)]      Loss: 41.837681\n",
      "bce: 30.210117, kld: 0.145345\n",
      "Train Epoch: 192 [20480/22533 (91%)]      Loss: 41.403564\n",
      "bce: 29.847851, kld: 0.144446\n",
      "====> Epoch: 192 Average loss: 41.3791, bce: 29.7529, kld: 0.1453\n",
      "Train Epoch: 193 [   0/22533 ( 0%)]      Loss: 41.212654\n",
      "bce: 29.645041, kld: 0.144595\n",
      "Train Epoch: 193 [10240/22533 (45%)]      Loss: 41.374123\n",
      "bce: 29.880262, kld: 0.143673\n",
      "Train Epoch: 193 [20480/22533 (91%)]      Loss: 41.504269\n",
      "bce: 30.077145, kld: 0.142839\n",
      "====> Epoch: 193 Average loss: 41.1507, bce: 29.6639, kld: 0.1436\n",
      "Train Epoch: 194 [   0/22533 ( 0%)]      Loss: 41.366714\n",
      "bce: 29.916239, kld: 0.143131\n",
      "Train Epoch: 194 [10240/22533 (45%)]      Loss: 41.001305\n",
      "bce: 29.636852, kld: 0.142056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 194 [20480/22533 (91%)]      Loss: 41.093361\n",
      "bce: 29.792519, kld: 0.141261\n",
      "====> Epoch: 194 Average loss: 40.9209, bce: 29.5658, kld: 0.1419\n",
      "Train Epoch: 195 [   0/22533 ( 0%)]      Loss: 40.171932\n",
      "bce: 28.896473, kld: 0.140943\n",
      "Train Epoch: 195 [10240/22533 (45%)]      Loss: 40.816200\n",
      "bce: 29.586828, kld: 0.140367\n",
      "Train Epoch: 195 [20480/22533 (91%)]      Loss: 41.018059\n",
      "bce: 29.867765, kld: 0.139379\n",
      "====> Epoch: 195 Average loss: 40.6610, bce: 29.4531, kld: 0.1401\n",
      "====> Testing Average Loss: 16.498143348089467\n",
      "Train Epoch: 196 [   0/22533 ( 0%)]      Loss: 40.320724\n",
      "bce: 29.187069, kld: 0.139171\n",
      "Train Epoch: 196 [10240/22533 (45%)]      Loss: 40.470604\n",
      "bce: 29.415485, kld: 0.138189\n",
      "Train Epoch: 196 [20480/22533 (91%)]      Loss: 40.196930\n",
      "bce: 29.194130, kld: 0.137535\n",
      "====> Epoch: 196 Average loss: 40.4293, bce: 29.3560, kld: 0.1384\n",
      "Train Epoch: 197 [   0/22533 ( 0%)]      Loss: 40.516495\n",
      "bce: 29.502090, kld: 0.137680\n",
      "Train Epoch: 197 [10240/22533 (45%)]      Loss: 40.320946\n",
      "bce: 29.359955, kld: 0.137012\n",
      "Train Epoch: 197 [20480/22533 (91%)]      Loss: 40.164871\n",
      "bce: 29.274109, kld: 0.136135\n",
      "====> Epoch: 197 Average loss: 40.2006, bce: 29.2563, kld: 0.1368\n",
      "Train Epoch: 198 [   0/22533 ( 0%)]      Loss: 39.809769\n",
      "bce: 28.940834, kld: 0.135862\n",
      "Train Epoch: 198 [10240/22533 (45%)]      Loss: 40.555016\n",
      "bce: 29.711021, kld: 0.135550\n",
      "Train Epoch: 198 [20480/22533 (91%)]      Loss: 39.621296\n",
      "bce: 28.848358, kld: 0.134662\n",
      "====> Epoch: 198 Average loss: 39.9873, bce: 29.1741, kld: 0.1352\n",
      "Train Epoch: 199 [   0/22533 ( 0%)]      Loss: 40.026817\n",
      "bce: 29.282883, kld: 0.134299\n",
      "Train Epoch: 199 [10240/22533 (45%)]      Loss: 39.474998\n",
      "bce: 28.803108, kld: 0.133399\n",
      "Train Epoch: 199 [20480/22533 (91%)]      Loss: 39.271523\n",
      "bce: 28.670269, kld: 0.132516\n",
      "====> Epoch: 199 Average loss: 39.7349, bce: 29.0549, kld: 0.1335\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=80,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
