{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=1024\n",
    "N_EPOCHS=210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 133.401321\n",
      "bce: 104.360382, kld: 58.081875\n",
      "Train Epoch: 0 [5120/22533 (23%)]      Loss: 119.011642\n",
      "bce: 102.817261, kld: 32.388771\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 115.015541\n",
      "bce: 100.632759, kld: 28.765568\n",
      "Train Epoch: 0 [15360/22533 (68%)]      Loss: 112.715736\n",
      "bce: 99.006592, kld: 27.418287\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 110.834885\n",
      "bce: 97.636063, kld: 26.397636\n",
      "====> Epoch: 0 Average loss: 116.3037, bce: 100.6944, kld: 31.2187\n",
      "====> Testing Average Loss: 91.92210695147118\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 110.461990\n",
      "bce: 97.437408, kld: 26.049170\n",
      "Train Epoch: 1 [5120/22533 (23%)]      Loss: 108.819595\n",
      "bce: 96.271477, kld: 25.096235\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 107.759537\n",
      "bce: 95.692581, kld: 24.133913\n",
      "Train Epoch: 1 [15360/22533 (68%)]      Loss: 106.442108\n",
      "bce: 94.783295, kld: 23.317619\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 105.045715\n",
      "bce: 93.714859, kld: 22.661709\n",
      "====> Epoch: 1 Average loss: 107.4235, bce: 95.3577, kld: 24.1315\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 105.012299\n",
      "bce: 93.808899, kld: 22.406796\n",
      "Train Epoch: 2 [5120/22533 (23%)]      Loss: 103.494110\n",
      "bce: 92.666519, kld: 21.655176\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 102.932686\n",
      "bce: 92.453232, kld: 20.958912\n",
      "Train Epoch: 2 [15360/22533 (68%)]      Loss: 101.901176\n",
      "bce: 91.777725, kld: 20.246904\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 101.582527\n",
      "bce: 91.851440, kld: 19.462177\n",
      "====> Epoch: 2 Average loss: 102.8245, bce: 92.3889, kld: 20.8711\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 100.336899\n",
      "bce: 90.772095, kld: 19.129612\n",
      "Train Epoch: 3 [5120/22533 (23%)]      Loss: 99.999512\n",
      "bce: 90.823517, kld: 18.351986\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 99.064384\n",
      "bce: 90.336693, kld: 17.455379\n",
      "Train Epoch: 3 [15360/22533 (68%)]      Loss: 97.897919\n",
      "bce: 89.652931, kld: 16.489975\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 97.293053\n",
      "bce: 89.495300, kld: 15.595505\n",
      "====> Epoch: 3 Average loss: 98.8062, bce: 90.1511, kld: 17.3102\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 96.184837\n",
      "bce: 88.576447, kld: 15.216778\n",
      "Train Epoch: 4 [5120/22533 (23%)]      Loss: 95.509377\n",
      "bce: 88.400024, kld: 14.218709\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 93.918198\n",
      "bce: 87.280396, kld: 13.275606\n",
      "Train Epoch: 4 [15360/22533 (68%)]      Loss: 92.742653\n",
      "bce: 86.596893, kld: 12.291517\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 91.702507\n",
      "bce: 86.042793, kld: 11.319427\n",
      "====> Epoch: 4 Average loss: 93.7717, bce: 87.1914, kld: 13.1606\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 90.709099\n",
      "bce: 85.241867, kld: 10.934457\n",
      "Train Epoch: 5 [5120/22533 (23%)]      Loss: 89.495163\n",
      "bce: 84.467010, kld: 10.056307\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 88.218468\n",
      "bce: 83.601868, kld: 9.233205\n",
      "Train Epoch: 5 [15360/22533 (68%)]      Loss: 86.661568\n",
      "bce: 82.406296, kld: 8.510544\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 85.852287\n",
      "bce: 81.953308, kld: 7.797962\n",
      "====> Epoch: 5 Average loss: 87.9917, bce: 83.3848, kld: 9.2139\n",
      "====> Testing Average Loss: 73.39112114731726\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 85.310974\n",
      "bce: 81.546272, kld: 7.529408\n",
      "Train Epoch: 6 [5120/22533 (23%)]      Loss: 84.609421\n",
      "bce: 81.145477, kld: 6.927883\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 83.674042\n",
      "bce: 80.480675, kld: 6.386740\n",
      "Train Epoch: 6 [15360/22533 (68%)]      Loss: 82.848083\n",
      "bce: 79.896965, kld: 5.902235\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 82.468491\n",
      "bce: 79.737778, kld: 5.461433\n",
      "====> Epoch: 6 Average loss: 83.8166, bce: 80.6244, kld: 6.3844\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 82.093933\n",
      "bce: 79.449158, kld: 5.289555\n",
      "Train Epoch: 7 [5120/22533 (23%)]      Loss: 81.697937\n",
      "bce: 79.237862, kld: 4.920146\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 81.182495\n",
      "bce: 78.896141, kld: 4.572703\n",
      "Train Epoch: 7 [15360/22533 (68%)]      Loss: 80.461327\n",
      "bce: 78.333900, kld: 4.254849\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 80.284729\n",
      "bce: 78.305069, kld: 3.959327\n",
      "====> Epoch: 7 Average loss: 81.0071, bce: 78.7300, kld: 4.5541\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 79.836075\n",
      "bce: 77.908615, kld: 3.854922\n",
      "Train Epoch: 8 [5120/22533 (23%)]      Loss: 79.014854\n",
      "bce: 77.211052, kld: 3.607598\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 78.535004\n",
      "bce: 76.845398, kld: 3.379204\n",
      "Train Epoch: 8 [15360/22533 (68%)]      Loss: 78.330742\n",
      "bce: 76.745773, kld: 3.169934\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 78.530235\n",
      "bce: 77.042809, kld: 2.974857\n",
      "====> Epoch: 8 Average loss: 78.7995, bce: 77.1136, kld: 3.3718\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 78.379707\n",
      "bce: 76.924576, kld: 2.910256\n",
      "Train Epoch: 9 [5120/22533 (23%)]      Loss: 77.617729\n",
      "bce: 76.239838, kld: 2.755782\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 77.384491\n",
      "bce: 76.088196, kld: 2.592589\n",
      "Train Epoch: 9 [15360/22533 (68%)]      Loss: 76.179268\n",
      "bce: 74.955521, kld: 2.447488\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 75.978073\n",
      "bce: 74.824303, kld: 2.307539\n",
      "====> Epoch: 9 Average loss: 76.9341, bce: 75.6432, kld: 2.5819\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 75.040260\n",
      "bce: 73.905487, kld: 2.269541\n",
      "Train Epoch: 10 [5120/22533 (23%)]      Loss: 76.005089\n",
      "bce: 74.935631, kld: 2.138920\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 75.345100\n",
      "bce: 74.325485, kld: 2.039231\n",
      "Train Epoch: 10 [15360/22533 (68%)]      Loss: 74.943649\n",
      "bce: 73.972137, kld: 1.943021\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 74.948059\n",
      "bce: 74.021744, kld: 1.852631\n",
      "====> Epoch: 10 Average loss: 75.2856, bce: 74.2675, kld: 2.0362\n",
      "====> Testing Average Loss: 63.76257634635867\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 74.830185\n",
      "bce: 73.922791, kld: 1.814791\n",
      "Train Epoch: 11 [5120/22533 (23%)]      Loss: 74.119934\n",
      "bce: 73.256012, kld: 1.727842\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 73.601265\n",
      "bce: 72.776253, kld: 1.650021\n",
      "Train Epoch: 11 [15360/22533 (68%)]      Loss: 73.273422\n",
      "bce: 72.486595, kld: 1.573658\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 73.202728\n",
      "bce: 72.444923, kld: 1.515616\n",
      "====> Epoch: 11 Average loss: 73.7850, bce: 72.9616, kld: 1.6466\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 73.053291\n",
      "bce: 72.306725, kld: 1.493135\n",
      "Train Epoch: 12 [5120/22533 (23%)]      Loss: 72.736641\n",
      "bce: 72.022934, kld: 1.427417\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 72.603279\n",
      "bce: 71.920982, kld: 1.364596\n",
      "Train Epoch: 12 [15360/22533 (68%)]      Loss: 72.190796\n",
      "bce: 71.531769, kld: 1.318060\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 71.757004\n",
      "bce: 71.122894, kld: 1.268224\n",
      "====> Epoch: 12 Average loss: 72.3857, bce: 71.7024, kld: 1.3666\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 71.699104\n",
      "bce: 71.077194, kld: 1.243816\n",
      "Train Epoch: 13 [5120/22533 (23%)]      Loss: 71.403908\n",
      "bce: 70.807510, kld: 1.192799\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 71.405640\n",
      "bce: 70.825485, kld: 1.160311\n",
      "Train Epoch: 13 [15360/22533 (68%)]      Loss: 70.027802\n",
      "bce: 69.466431, kld: 1.122735\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 70.271927\n",
      "bce: 69.735413, kld: 1.073030\n",
      "====> Epoch: 13 Average loss: 71.0694, bce: 70.4933, kld: 1.1522\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 70.351326\n",
      "bce: 69.820770, kld: 1.061112\n",
      "Train Epoch: 14 [5120/22533 (23%)]      Loss: 70.336617\n",
      "bce: 69.823082, kld: 1.027068\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 69.883049\n",
      "bce: 69.381813, kld: 1.002473\n",
      "Train Epoch: 14 [15360/22533 (68%)]      Loss: 69.956322\n",
      "bce: 69.478577, kld: 0.955497\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 69.438629\n",
      "bce: 68.972641, kld: 0.931984\n",
      "====> Epoch: 14 Average loss: 69.8118, bce: 69.3162, kld: 0.9911\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 69.507385\n",
      "bce: 69.041489, kld: 0.931798\n",
      "Train Epoch: 15 [5120/22533 (23%)]      Loss: 69.304314\n",
      "bce: 68.854202, kld: 0.900226\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 68.324753\n",
      "bce: 67.885559, kld: 0.878380\n",
      "Train Epoch: 15 [15360/22533 (68%)]      Loss: 68.298622\n",
      "bce: 67.878586, kld: 0.840074\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 68.299469\n",
      "bce: 67.884773, kld: 0.829394\n",
      "====> Epoch: 15 Average loss: 68.6030, bce: 68.1661, kld: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Testing Average Loss: 57.26763091216216\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 68.102402\n",
      "bce: 67.690430, kld: 0.823947\n",
      "Train Epoch: 16 [5120/22533 (23%)]      Loss: 67.535851\n",
      "bce: 67.130104, kld: 0.811487\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 67.699318\n",
      "bce: 67.306992, kld: 0.784659\n",
      "Train Epoch: 16 [15360/22533 (68%)]      Loss: 67.443115\n",
      "bce: 67.064041, kld: 0.758153\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 66.984489\n",
      "bce: 66.618515, kld: 0.731952\n",
      "====> Epoch: 16 Average loss: 67.4375, bce: 67.0480, kld: 0.7789\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 66.602554\n",
      "bce: 66.238495, kld: 0.728125\n",
      "Train Epoch: 17 [5120/22533 (23%)]      Loss: 66.466080\n",
      "bce: 66.104797, kld: 0.722565\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 66.458626\n",
      "bce: 66.103790, kld: 0.709677\n",
      "Train Epoch: 17 [15360/22533 (68%)]      Loss: 65.897827\n",
      "bce: 65.553139, kld: 0.689384\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 65.994995\n",
      "bce: 65.665970, kld: 0.658050\n",
      "====> Epoch: 17 Average loss: 66.3113, bce: 65.9609, kld: 0.7008\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 65.947876\n",
      "bce: 65.618591, kld: 0.658566\n",
      "Train Epoch: 18 [5120/22533 (23%)]      Loss: 65.174026\n",
      "bce: 64.845901, kld: 0.656245\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 64.985657\n",
      "bce: 64.660454, kld: 0.650407\n",
      "Train Epoch: 18 [15360/22533 (68%)]      Loss: 64.412910\n",
      "bce: 64.105179, kld: 0.615461\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 65.045654\n",
      "bce: 64.729858, kld: 0.631589\n",
      "====> Epoch: 18 Average loss: 65.2234, bce: 64.9023, kld: 0.6422\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 65.759865\n",
      "bce: 65.454575, kld: 0.610585\n",
      "Train Epoch: 19 [5120/22533 (23%)]      Loss: 64.597115\n",
      "bce: 64.300934, kld: 0.592365\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 64.457779\n",
      "bce: 64.162224, kld: 0.591117\n",
      "Train Epoch: 19 [15360/22533 (68%)]      Loss: 64.051643\n",
      "bce: 63.754147, kld: 0.594992\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 63.466095\n",
      "bce: 63.180904, kld: 0.570381\n",
      "====> Epoch: 19 Average loss: 64.1630, bce: 63.8696, kld: 0.5869\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 63.299725\n",
      "bce: 63.016632, kld: 0.566187\n",
      "Train Epoch: 20 [5120/22533 (23%)]      Loss: 62.940735\n",
      "bce: 62.677040, kld: 0.527392\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 62.920494\n",
      "bce: 62.632465, kld: 0.576055\n",
      "Train Epoch: 20 [15360/22533 (68%)]      Loss: 62.686325\n",
      "bce: 62.422180, kld: 0.528288\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 63.103214\n",
      "bce: 62.838875, kld: 0.528678\n",
      "====> Epoch: 20 Average loss: 63.1308, bce: 62.8580, kld: 0.5456\n",
      "====> Testing Average Loss: 52.00146399863534\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 62.616470\n",
      "bce: 62.346024, kld: 0.540895\n",
      "Train Epoch: 21 [5120/22533 (23%)]      Loss: 62.805473\n",
      "bce: 62.524090, kld: 0.562766\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 61.953453\n",
      "bce: 61.701031, kld: 0.504848\n",
      "Train Epoch: 21 [15360/22533 (68%)]      Loss: 61.722794\n",
      "bce: 61.464790, kld: 0.516007\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 61.455410\n",
      "bce: 61.200294, kld: 0.510230\n",
      "====> Epoch: 21 Average loss: 62.1139, bce: 61.8515, kld: 0.5247\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 60.737514\n",
      "bce: 60.475548, kld: 0.523931\n",
      "Train Epoch: 22 [5120/22533 (23%)]      Loss: 61.676502\n",
      "bce: 61.426880, kld: 0.499247\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 61.394024\n",
      "bce: 61.141628, kld: 0.504789\n",
      "Train Epoch: 22 [15360/22533 (68%)]      Loss: 60.749767\n",
      "bce: 60.513878, kld: 0.471780\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 61.072212\n",
      "bce: 60.831787, kld: 0.480853\n",
      "====> Epoch: 22 Average loss: 61.1020, bce: 60.8562, kld: 0.4915\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 60.601200\n",
      "bce: 60.365379, kld: 0.471639\n",
      "Train Epoch: 23 [5120/22533 (23%)]      Loss: 60.482334\n",
      "bce: 60.251102, kld: 0.462460\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 60.450432\n",
      "bce: 60.216671, kld: 0.467522\n",
      "Train Epoch: 23 [15360/22533 (68%)]      Loss: 59.781784\n",
      "bce: 59.547607, kld: 0.468356\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 59.823765\n",
      "bce: 59.602798, kld: 0.441931\n",
      "====> Epoch: 23 Average loss: 60.1156, bce: 59.8843, kld: 0.4626\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 59.075237\n",
      "bce: 58.864582, kld: 0.421314\n",
      "Train Epoch: 24 [5120/22533 (23%)]      Loss: 58.344616\n",
      "bce: 58.116802, kld: 0.455628\n",
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 59.639370\n",
      "bce: 59.425571, kld: 0.427595\n",
      "Train Epoch: 24 [15360/22533 (68%)]      Loss: 58.747276\n",
      "bce: 58.530205, kld: 0.434140\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 58.725445\n",
      "bce: 58.521320, kld: 0.408249\n",
      "====> Epoch: 24 Average loss: 59.1339, bce: 58.9157, kld: 0.4364\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 58.115284\n",
      "bce: 57.911533, kld: 0.407499\n",
      "Train Epoch: 25 [5120/22533 (23%)]      Loss: 57.996212\n",
      "bce: 57.787811, kld: 0.416802\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 57.950340\n",
      "bce: 57.735859, kld: 0.428962\n",
      "Train Epoch: 25 [15360/22533 (68%)]      Loss: 57.623405\n",
      "bce: 57.429691, kld: 0.387431\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 58.365818\n",
      "bce: 58.157585, kld: 0.416468\n",
      "====> Epoch: 25 Average loss: 58.2215, bce: 58.0143, kld: 0.4144\n",
      "====> Testing Average Loss: 47.781044052056984\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 57.944118\n",
      "bce: 57.739353, kld: 0.409532\n",
      "Train Epoch: 26 [5120/22533 (23%)]      Loss: 57.005875\n",
      "bce: 56.813126, kld: 0.385495\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 57.586052\n",
      "bce: 57.390411, kld: 0.391284\n",
      "Train Epoch: 26 [15360/22533 (68%)]      Loss: 57.165867\n",
      "bce: 56.971611, kld: 0.388511\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 56.566963\n",
      "bce: 56.369270, kld: 0.395385\n",
      "====> Epoch: 26 Average loss: 57.2869, bce: 57.0915, kld: 0.3906\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 56.966007\n",
      "bce: 56.780998, kld: 0.370021\n",
      "Train Epoch: 27 [5120/22533 (23%)]      Loss: 56.969505\n",
      "bce: 56.777962, kld: 0.383083\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 57.168835\n",
      "bce: 56.985374, kld: 0.366924\n",
      "Train Epoch: 27 [15360/22533 (68%)]      Loss: 56.598927\n",
      "bce: 56.405869, kld: 0.386114\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 56.097851\n",
      "bce: 55.921089, kld: 0.353526\n",
      "====> Epoch: 27 Average loss: 56.3750, bce: 56.1890, kld: 0.3721\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 55.424431\n",
      "bce: 55.248894, kld: 0.351072\n",
      "Train Epoch: 28 [5120/22533 (23%)]      Loss: 55.994225\n",
      "bce: 55.810265, kld: 0.367923\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 54.817009\n",
      "bce: 54.646637, kld: 0.340747\n",
      "Train Epoch: 28 [15360/22533 (68%)]      Loss: 55.257866\n",
      "bce: 55.092041, kld: 0.331653\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 55.139416\n",
      "bce: 54.963688, kld: 0.351456\n",
      "====> Epoch: 28 Average loss: 55.4821, bce: 55.3070, kld: 0.3500\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 55.191265\n",
      "bce: 55.021034, kld: 0.340465\n",
      "Train Epoch: 29 [5120/22533 (23%)]      Loss: 54.698818\n",
      "bce: 54.520710, kld: 0.356218\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 54.373665\n",
      "bce: 54.202965, kld: 0.341397\n",
      "Train Epoch: 29 [15360/22533 (68%)]      Loss: 55.587872\n",
      "bce: 55.417946, kld: 0.339850\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 53.933922\n",
      "bce: 53.763084, kld: 0.341673\n",
      "====> Epoch: 29 Average loss: 54.6110, bce: 54.4407, kld: 0.3406\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 53.972523\n",
      "bce: 53.809448, kld: 0.326152\n",
      "Train Epoch: 30 [5120/22533 (23%)]      Loss: 53.877422\n",
      "bce: 53.709351, kld: 0.336143\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 53.431717\n",
      "bce: 53.275166, kld: 0.313099\n",
      "Train Epoch: 30 [15360/22533 (68%)]      Loss: 54.297276\n",
      "bce: 54.138496, kld: 0.317558\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 53.583485\n",
      "bce: 53.418278, kld: 0.330412\n",
      "====> Epoch: 30 Average loss: 53.7597, bce: 53.5964, kld: 0.3265\n",
      "====> Testing Average Loss: 44.235775029956066\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 53.347759\n",
      "bce: 53.174553, kld: 0.346414\n",
      "Train Epoch: 31 [5120/22533 (23%)]      Loss: 53.006336\n",
      "bce: 52.852428, kld: 0.307812\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 52.839291\n",
      "bce: 52.680855, kld: 0.316869\n",
      "Train Epoch: 31 [15360/22533 (68%)]      Loss: 52.470894\n",
      "bce: 52.319454, kld: 0.302879\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 52.909393\n",
      "bce: 52.750427, kld: 0.317931\n",
      "====> Epoch: 31 Average loss: 52.9453, bce: 52.7851, kld: 0.3204\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 52.363762\n",
      "bce: 52.198223, kld: 0.331080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [5120/22533 (23%)]      Loss: 51.979122\n",
      "bce: 51.828979, kld: 0.300282\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 51.571922\n",
      "bce: 51.413685, kld: 0.316477\n",
      "Train Epoch: 32 [15360/22533 (68%)]      Loss: 52.245502\n",
      "bce: 52.081238, kld: 0.328526\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 51.928391\n",
      "bce: 51.774662, kld: 0.307455\n",
      "====> Epoch: 32 Average loss: 52.1170, bce: 51.9605, kld: 0.3130\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 51.466068\n",
      "bce: 51.310844, kld: 0.310446\n",
      "Train Epoch: 33 [5120/22533 (23%)]      Loss: 51.333900\n",
      "bce: 51.182426, kld: 0.302948\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 51.301903\n",
      "bce: 51.146648, kld: 0.310508\n",
      "Train Epoch: 33 [15360/22533 (68%)]      Loss: 51.675468\n",
      "bce: 51.522652, kld: 0.305633\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 50.559284\n",
      "bce: 50.408638, kld: 0.301292\n",
      "====> Epoch: 33 Average loss: 51.3047, bce: 51.1516, kld: 0.3062\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 50.780403\n",
      "bce: 50.627357, kld: 0.306090\n",
      "Train Epoch: 34 [5120/22533 (23%)]      Loss: 51.103294\n",
      "bce: 50.948563, kld: 0.309463\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 50.725674\n",
      "bce: 50.580025, kld: 0.291296\n",
      "Train Epoch: 34 [15360/22533 (68%)]      Loss: 50.961910\n",
      "bce: 50.813965, kld: 0.295888\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 50.118889\n",
      "bce: 49.975868, kld: 0.286039\n",
      "====> Epoch: 34 Average loss: 50.5667, bce: 50.4168, kld: 0.2998\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 49.957424\n",
      "bce: 49.810974, kld: 0.292901\n",
      "Train Epoch: 35 [5120/22533 (23%)]      Loss: 49.672066\n",
      "bce: 49.517212, kld: 0.309708\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 50.172371\n",
      "bce: 50.029350, kld: 0.286038\n",
      "Train Epoch: 35 [15360/22533 (68%)]      Loss: 50.570423\n",
      "bce: 50.424324, kld: 0.292197\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 49.469170\n",
      "bce: 49.330856, kld: 0.276630\n",
      "====> Epoch: 35 Average loss: 49.8521, bce: 49.7037, kld: 0.2967\n",
      "====> Testing Average Loss: 40.280050197210755\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 49.629230\n",
      "bce: 49.492050, kld: 0.274361\n",
      "Train Epoch: 36 [5120/22533 (23%)]      Loss: 49.188107\n",
      "bce: 49.037601, kld: 0.301010\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 49.826420\n",
      "bce: 49.674515, kld: 0.303807\n",
      "Train Epoch: 36 [15360/22533 (68%)]      Loss: 48.595871\n",
      "bce: 48.448757, kld: 0.294229\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 49.012512\n",
      "bce: 48.871655, kld: 0.281714\n",
      "====> Epoch: 36 Average loss: 49.1303, bce: 48.9839, kld: 0.2929\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 48.947689\n",
      "bce: 48.800220, kld: 0.294937\n",
      "Train Epoch: 37 [5120/22533 (23%)]      Loss: 48.838219\n",
      "bce: 48.682610, kld: 0.311215\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 48.655128\n",
      "bce: 48.514641, kld: 0.280978\n",
      "Train Epoch: 37 [15360/22533 (68%)]      Loss: 48.194199\n",
      "bce: 48.046715, kld: 0.294970\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 48.332020\n",
      "bce: 48.195816, kld: 0.272406\n",
      "====> Epoch: 37 Average loss: 48.3832, bce: 48.2372, kld: 0.2919\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 47.800488\n",
      "bce: 47.657654, kld: 0.285671\n",
      "Train Epoch: 38 [5120/22533 (23%)]      Loss: 47.838074\n",
      "bce: 47.695107, kld: 0.285937\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 47.816875\n",
      "bce: 47.671841, kld: 0.290072\n",
      "Train Epoch: 38 [15360/22533 (68%)]      Loss: 47.903030\n",
      "bce: 47.765320, kld: 0.275423\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 47.402180\n",
      "bce: 47.258057, kld: 0.288247\n",
      "====> Epoch: 38 Average loss: 47.7122, bce: 47.5709, kld: 0.2826\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 47.416264\n",
      "bce: 47.270180, kld: 0.292171\n",
      "Train Epoch: 39 [5120/22533 (23%)]      Loss: 47.646416\n",
      "bce: 47.504333, kld: 0.284164\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 47.286667\n",
      "bce: 47.144119, kld: 0.285096\n",
      "Train Epoch: 39 [15360/22533 (68%)]      Loss: 47.420593\n",
      "bce: 47.285126, kld: 0.270939\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 47.060635\n",
      "bce: 46.921829, kld: 0.277614\n",
      "====> Epoch: 39 Average loss: 47.0380, bce: 46.8991, kld: 0.2778\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 46.353947\n",
      "bce: 46.218010, kld: 0.271876\n",
      "Train Epoch: 40 [5120/22533 (23%)]      Loss: 47.107128\n",
      "bce: 46.969776, kld: 0.274703\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 45.830914\n",
      "bce: 45.687515, kld: 0.286797\n",
      "Train Epoch: 40 [15360/22533 (68%)]      Loss: 46.079510\n",
      "bce: 45.938118, kld: 0.282786\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 46.543427\n",
      "bce: 46.412376, kld: 0.262102\n",
      "====> Epoch: 40 Average loss: 46.3643, bce: 46.2258, kld: 0.2769\n",
      "====> Testing Average Loss: 37.525688365397414\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 46.103184\n",
      "bce: 45.970032, kld: 0.266304\n",
      "Train Epoch: 41 [5120/22533 (23%)]      Loss: 46.370846\n",
      "bce: 46.229282, kld: 0.283126\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 45.805866\n",
      "bce: 45.669395, kld: 0.272940\n",
      "Train Epoch: 41 [15360/22533 (68%)]      Loss: 45.975658\n",
      "bce: 45.841461, kld: 0.268395\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 45.686443\n",
      "bce: 45.555103, kld: 0.262678\n",
      "====> Epoch: 41 Average loss: 45.7341, bce: 45.5986, kld: 0.2711\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 45.611385\n",
      "bce: 45.479740, kld: 0.263291\n",
      "Train Epoch: 42 [5120/22533 (23%)]      Loss: 44.921749\n",
      "bce: 44.783466, kld: 0.276566\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 45.693157\n",
      "bce: 45.559391, kld: 0.267534\n",
      "Train Epoch: 42 [15360/22533 (68%)]      Loss: 45.796234\n",
      "bce: 45.661133, kld: 0.270201\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 44.988605\n",
      "bce: 44.860077, kld: 0.257059\n",
      "====> Epoch: 42 Average loss: 45.0927, bce: 44.9591, kld: 0.2672\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 44.739334\n",
      "bce: 44.613964, kld: 0.250740\n",
      "Train Epoch: 43 [5120/22533 (23%)]      Loss: 44.360626\n",
      "bce: 44.231777, kld: 0.257701\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 45.006908\n",
      "bce: 44.880936, kld: 0.251945\n",
      "Train Epoch: 43 [15360/22533 (68%)]      Loss: 43.799873\n",
      "bce: 43.673283, kld: 0.253180\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 44.211361\n",
      "bce: 44.074669, kld: 0.273381\n",
      "====> Epoch: 43 Average loss: 44.4726, bce: 44.3399, kld: 0.2654\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 44.210125\n",
      "bce: 44.073715, kld: 0.272819\n",
      "Train Epoch: 44 [5120/22533 (23%)]      Loss: 44.489697\n",
      "bce: 44.357738, kld: 0.263916\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 44.178215\n",
      "bce: 44.042412, kld: 0.271604\n",
      "Train Epoch: 44 [15360/22533 (68%)]      Loss: 43.626720\n",
      "bce: 43.501808, kld: 0.249824\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 44.058979\n",
      "bce: 43.928467, kld: 0.261023\n",
      "====> Epoch: 44 Average loss: 43.8512, bce: 43.7214, kld: 0.2596\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 43.133888\n",
      "bce: 43.007900, kld: 0.251978\n",
      "Train Epoch: 45 [5120/22533 (23%)]      Loss: 44.437424\n",
      "bce: 44.308922, kld: 0.257001\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 43.804058\n",
      "bce: 43.673107, kld: 0.261901\n",
      "Train Epoch: 45 [15360/22533 (68%)]      Loss: 43.683792\n",
      "bce: 43.552982, kld: 0.261622\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 43.052643\n",
      "bce: 42.924797, kld: 0.255694\n",
      "====> Epoch: 45 Average loss: 43.2973, bce: 43.1682, kld: 0.2583\n",
      "====> Testing Average Loss: 35.18322033933564\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 42.653618\n",
      "bce: 42.522427, kld: 0.262383\n",
      "Train Epoch: 46 [5120/22533 (23%)]      Loss: 42.480705\n",
      "bce: 42.343048, kld: 0.275313\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 42.322533\n",
      "bce: 42.202728, kld: 0.239608\n",
      "Train Epoch: 46 [15360/22533 (68%)]      Loss: 42.478794\n",
      "bce: 42.348583, kld: 0.260422\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 42.851501\n",
      "bce: 42.724937, kld: 0.253131\n",
      "====> Epoch: 46 Average loss: 42.7398, bce: 42.6107, kld: 0.2583\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 42.767403\n",
      "bce: 42.640377, kld: 0.254049\n",
      "Train Epoch: 47 [5120/22533 (23%)]      Loss: 42.533924\n",
      "bce: 42.397072, kld: 0.273705\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 41.989628\n",
      "bce: 41.857498, kld: 0.264258\n",
      "Train Epoch: 47 [15360/22533 (68%)]      Loss: 41.456398\n",
      "bce: 41.325211, kld: 0.262375\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 42.223732\n",
      "bce: 42.097301, kld: 0.252861\n",
      "====> Epoch: 47 Average loss: 42.1727, bce: 42.0437, kld: 0.2580\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 41.613152\n",
      "bce: 41.475590, kld: 0.275126\n",
      "Train Epoch: 48 [5120/22533 (23%)]      Loss: 41.629574\n",
      "bce: 41.503197, kld: 0.252755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 42.229748\n",
      "bce: 42.105392, kld: 0.248712\n",
      "Train Epoch: 48 [15360/22533 (68%)]      Loss: 41.418629\n",
      "bce: 41.284363, kld: 0.268530\n",
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 42.037956\n",
      "bce: 41.907928, kld: 0.260054\n",
      "====> Epoch: 48 Average loss: 41.6686, bce: 41.5402, kld: 0.2568\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 41.634342\n",
      "bce: 41.509636, kld: 0.249411\n",
      "Train Epoch: 49 [5120/22533 (23%)]      Loss: 41.310146\n",
      "bce: 41.178974, kld: 0.262343\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 40.884533\n",
      "bce: 40.760368, kld: 0.248327\n",
      "Train Epoch: 49 [15360/22533 (68%)]      Loss: 40.618439\n",
      "bce: 40.491409, kld: 0.254060\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 40.880344\n",
      "bce: 40.755028, kld: 0.250634\n",
      "====> Epoch: 49 Average loss: 41.0950, bce: 40.9681, kld: 0.2537\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 40.600498\n",
      "bce: 40.469639, kld: 0.261722\n",
      "Train Epoch: 50 [5120/22533 (23%)]      Loss: 40.863312\n",
      "bce: 40.746849, kld: 0.232922\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 40.699490\n",
      "bce: 40.576740, kld: 0.245496\n",
      "Train Epoch: 50 [15360/22533 (68%)]      Loss: 40.762646\n",
      "bce: 40.631329, kld: 0.262634\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 40.147465\n",
      "bce: 40.018803, kld: 0.257321\n",
      "====> Epoch: 50 Average loss: 40.5744, bce: 40.4479, kld: 0.2528\n",
      "====> Testing Average Loss: 32.852286438223935\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 40.593349\n",
      "bce: 40.466530, kld: 0.253639\n",
      "Train Epoch: 51 [5120/22533 (23%)]      Loss: 40.451973\n",
      "bce: 40.328339, kld: 0.247272\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 39.957355\n",
      "bce: 39.836708, kld: 0.241292\n",
      "Train Epoch: 51 [15360/22533 (68%)]      Loss: 39.913078\n",
      "bce: 39.787807, kld: 0.250542\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 39.112549\n",
      "bce: 38.987396, kld: 0.250308\n",
      "====> Epoch: 51 Average loss: 40.0509, bce: 39.9264, kld: 0.2490\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 39.980473\n",
      "bce: 39.859768, kld: 0.241408\n",
      "Train Epoch: 52 [5120/22533 (23%)]      Loss: 39.261478\n",
      "bce: 39.138176, kld: 0.246605\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 39.953270\n",
      "bce: 39.829910, kld: 0.246722\n",
      "Train Epoch: 52 [15360/22533 (68%)]      Loss: 39.157471\n",
      "bce: 39.034630, kld: 0.245685\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 39.975140\n",
      "bce: 39.848801, kld: 0.252677\n",
      "====> Epoch: 52 Average loss: 39.5978, bce: 39.4743, kld: 0.2470\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 39.183521\n",
      "bce: 39.060959, kld: 0.245125\n",
      "Train Epoch: 53 [5120/22533 (23%)]      Loss: 38.233559\n",
      "bce: 38.111046, kld: 0.245023\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 38.772945\n",
      "bce: 38.654427, kld: 0.237040\n",
      "Train Epoch: 53 [15360/22533 (68%)]      Loss: 38.983582\n",
      "bce: 38.857079, kld: 0.253010\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 38.692398\n",
      "bce: 38.572346, kld: 0.240104\n",
      "====> Epoch: 53 Average loss: 39.1103, bce: 38.9863, kld: 0.2480\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 38.915871\n",
      "bce: 38.793571, kld: 0.244602\n",
      "Train Epoch: 54 [5120/22533 (23%)]      Loss: 38.641575\n",
      "bce: 38.517654, kld: 0.247837\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 37.702641\n",
      "bce: 37.587456, kld: 0.230371\n",
      "Train Epoch: 54 [15360/22533 (68%)]      Loss: 38.131836\n",
      "bce: 38.008148, kld: 0.247376\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 38.668095\n",
      "bce: 38.541378, kld: 0.253430\n",
      "====> Epoch: 54 Average loss: 38.6318, bce: 38.5085, kld: 0.2465\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 38.239040\n",
      "bce: 38.117867, kld: 0.242348\n",
      "Train Epoch: 55 [5120/22533 (23%)]      Loss: 38.839294\n",
      "bce: 38.716537, kld: 0.245516\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 37.903355\n",
      "bce: 37.787758, kld: 0.231193\n",
      "Train Epoch: 55 [15360/22533 (68%)]      Loss: 37.681175\n",
      "bce: 37.557114, kld: 0.248122\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 37.684704\n",
      "bce: 37.557739, kld: 0.253933\n",
      "====> Epoch: 55 Average loss: 38.1499, bce: 38.0281, kld: 0.2438\n",
      "====> Testing Average Loss: 30.77666713819731\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 37.480049\n",
      "bce: 37.364429, kld: 0.231236\n",
      "Train Epoch: 56 [5120/22533 (23%)]      Loss: 37.539925\n",
      "bce: 37.418221, kld: 0.243410\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 37.388397\n",
      "bce: 37.272949, kld: 0.230892\n",
      "Train Epoch: 56 [15360/22533 (68%)]      Loss: 37.313694\n",
      "bce: 37.191307, kld: 0.244771\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 38.373299\n",
      "bce: 38.248352, kld: 0.249892\n",
      "====> Epoch: 56 Average loss: 37.7345, bce: 37.6126, kld: 0.2438\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 37.771976\n",
      "bce: 37.647827, kld: 0.248301\n",
      "Train Epoch: 57 [5120/22533 (23%)]      Loss: 37.430576\n",
      "bce: 37.312080, kld: 0.236994\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 37.230545\n",
      "bce: 37.105888, kld: 0.249313\n",
      "Train Epoch: 57 [15360/22533 (68%)]      Loss: 36.648968\n",
      "bce: 36.528954, kld: 0.240025\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 37.785564\n",
      "bce: 37.668945, kld: 0.233237\n",
      "====> Epoch: 57 Average loss: 37.2559, bce: 37.1337, kld: 0.2444\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 37.513107\n",
      "bce: 37.388599, kld: 0.249019\n",
      "Train Epoch: 58 [5120/22533 (23%)]      Loss: 37.530399\n",
      "bce: 37.405663, kld: 0.249475\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 36.930721\n",
      "bce: 36.815231, kld: 0.230980\n",
      "Train Epoch: 58 [15360/22533 (68%)]      Loss: 36.365749\n",
      "bce: 36.245651, kld: 0.240194\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 35.771751\n",
      "bce: 35.645836, kld: 0.251833\n",
      "====> Epoch: 58 Average loss: 36.8237, bce: 36.7030, kld: 0.2414\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 36.029129\n",
      "bce: 35.911125, kld: 0.236008\n",
      "Train Epoch: 59 [5120/22533 (23%)]      Loss: 35.624237\n",
      "bce: 35.509422, kld: 0.229629\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 36.565487\n",
      "bce: 36.443638, kld: 0.243697\n",
      "Train Epoch: 59 [15360/22533 (68%)]      Loss: 36.807205\n",
      "bce: 36.684223, kld: 0.245962\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 36.461521\n",
      "bce: 36.344955, kld: 0.233135\n",
      "====> Epoch: 59 Average loss: 36.4068, bce: 36.2868, kld: 0.2399\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 36.404289\n",
      "bce: 36.292336, kld: 0.223910\n",
      "Train Epoch: 60 [5120/22533 (23%)]      Loss: 36.089813\n",
      "bce: 35.976349, kld: 0.226930\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 35.760735\n",
      "bce: 35.640129, kld: 0.241214\n",
      "Train Epoch: 60 [15360/22533 (68%)]      Loss: 36.092670\n",
      "bce: 35.966690, kld: 0.251959\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 35.672764\n",
      "bce: 35.556343, kld: 0.232839\n",
      "====> Epoch: 60 Average loss: 36.0049, bce: 35.8846, kld: 0.2406\n",
      "====> Testing Average Loss: 28.758678677522965\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 35.457325\n",
      "bce: 35.341305, kld: 0.232044\n",
      "Train Epoch: 61 [5120/22533 (23%)]      Loss: 35.591572\n",
      "bce: 35.471306, kld: 0.240535\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 35.544689\n",
      "bce: 35.432465, kld: 0.224449\n",
      "Train Epoch: 61 [15360/22533 (68%)]      Loss: 35.482044\n",
      "bce: 35.360886, kld: 0.242316\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 35.265041\n",
      "bce: 35.148003, kld: 0.234080\n",
      "====> Epoch: 61 Average loss: 35.6050, bce: 35.4857, kld: 0.2386\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 35.117588\n",
      "bce: 34.996616, kld: 0.241942\n",
      "Train Epoch: 62 [5120/22533 (23%)]      Loss: 35.286983\n",
      "bce: 35.162338, kld: 0.249291\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 35.362839\n",
      "bce: 35.236889, kld: 0.251901\n",
      "Train Epoch: 62 [15360/22533 (68%)]      Loss: 35.290089\n",
      "bce: 35.170799, kld: 0.238580\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 34.548626\n",
      "bce: 34.433311, kld: 0.230625\n",
      "====> Epoch: 62 Average loss: 35.2319, bce: 35.1116, kld: 0.2407\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 34.931889\n",
      "bce: 34.805786, kld: 0.252206\n",
      "Train Epoch: 63 [5120/22533 (23%)]      Loss: 34.991444\n",
      "bce: 34.868797, kld: 0.245291\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 35.055691\n",
      "bce: 34.934990, kld: 0.241405\n",
      "Train Epoch: 63 [15360/22533 (68%)]      Loss: 34.732910\n",
      "bce: 34.616039, kld: 0.233739\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 34.857029\n",
      "bce: 34.737778, kld: 0.238501\n",
      "====> Epoch: 63 Average loss: 34.8194, bce: 34.6993, kld: 0.2402\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 34.549721\n",
      "bce: 34.436085, kld: 0.227272\n",
      "Train Epoch: 64 [5120/22533 (23%)]      Loss: 34.836411\n",
      "bce: 34.720757, kld: 0.231305\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 34.709183\n",
      "bce: 34.590591, kld: 0.237185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [15360/22533 (68%)]      Loss: 33.985054\n",
      "bce: 33.865860, kld: 0.238390\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 34.471413\n",
      "bce: 34.355907, kld: 0.231010\n",
      "====> Epoch: 64 Average loss: 34.4527, bce: 34.3344, kld: 0.2367\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 34.030186\n",
      "bce: 33.915329, kld: 0.229713\n",
      "Train Epoch: 65 [5120/22533 (23%)]      Loss: 34.041176\n",
      "bce: 33.924782, kld: 0.232787\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 34.379066\n",
      "bce: 34.256256, kld: 0.245623\n",
      "Train Epoch: 65 [15360/22533 (68%)]      Loss: 33.842651\n",
      "bce: 33.719101, kld: 0.247098\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 33.930534\n",
      "bce: 33.812088, kld: 0.236894\n",
      "====> Epoch: 65 Average loss: 34.1033, bce: 33.9844, kld: 0.2379\n",
      "====> Testing Average Loss: 26.80126647583544\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 33.604115\n",
      "bce: 33.487934, kld: 0.232360\n",
      "Train Epoch: 66 [5120/22533 (23%)]      Loss: 33.430576\n",
      "bce: 33.316071, kld: 0.229008\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 34.016338\n",
      "bce: 33.904270, kld: 0.224140\n",
      "Train Epoch: 66 [15360/22533 (68%)]      Loss: 33.860756\n",
      "bce: 33.737225, kld: 0.247060\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 33.681404\n",
      "bce: 33.558918, kld: 0.244973\n",
      "====> Epoch: 66 Average loss: 33.7477, bce: 33.6285, kld: 0.2385\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 33.459747\n",
      "bce: 33.338829, kld: 0.241836\n",
      "Train Epoch: 67 [5120/22533 (23%)]      Loss: 33.643372\n",
      "bce: 33.527084, kld: 0.232575\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 33.674290\n",
      "bce: 33.547958, kld: 0.252661\n",
      "Train Epoch: 67 [15360/22533 (68%)]      Loss: 33.075531\n",
      "bce: 32.955238, kld: 0.240584\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 33.106865\n",
      "bce: 32.994034, kld: 0.225661\n",
      "====> Epoch: 67 Average loss: 33.4089, bce: 33.2882, kld: 0.2412\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 32.617695\n",
      "bce: 32.500488, kld: 0.234412\n",
      "Train Epoch: 68 [5120/22533 (23%)]      Loss: 33.132374\n",
      "bce: 33.010651, kld: 0.243443\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 32.837521\n",
      "bce: 32.722870, kld: 0.229299\n",
      "Train Epoch: 68 [15360/22533 (68%)]      Loss: 33.397575\n",
      "bce: 33.282467, kld: 0.230218\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 32.404488\n",
      "bce: 32.281231, kld: 0.246516\n",
      "====> Epoch: 68 Average loss: 33.0438, bce: 32.9235, kld: 0.2407\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 32.048065\n",
      "bce: 31.931042, kld: 0.234047\n",
      "Train Epoch: 69 [5120/22533 (23%)]      Loss: 32.736683\n",
      "bce: 32.613152, kld: 0.247064\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 32.752041\n",
      "bce: 32.628811, kld: 0.246463\n",
      "Train Epoch: 69 [15360/22533 (68%)]      Loss: 32.852089\n",
      "bce: 32.729218, kld: 0.245744\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 32.124519\n",
      "bce: 32.007980, kld: 0.233081\n",
      "====> Epoch: 69 Average loss: 32.7094, bce: 32.5898, kld: 0.2393\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 32.482437\n",
      "bce: 32.355881, kld: 0.253114\n",
      "Train Epoch: 70 [5120/22533 (23%)]      Loss: 32.011990\n",
      "bce: 31.891125, kld: 0.241733\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 32.237495\n",
      "bce: 32.113155, kld: 0.248678\n",
      "Train Epoch: 70 [15360/22533 (68%)]      Loss: 32.651859\n",
      "bce: 32.536659, kld: 0.230403\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 33.172295\n",
      "bce: 33.055595, kld: 0.233396\n",
      "====> Epoch: 70 Average loss: 32.4096, bce: 32.2889, kld: 0.2413\n",
      "====> Testing Average Loss: 26.096475429786313\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 32.169003\n",
      "bce: 32.048203, kld: 0.241600\n",
      "Train Epoch: 71 [5120/22533 (23%)]      Loss: 32.091179\n",
      "bce: 31.977537, kld: 0.227284\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 31.963291\n",
      "bce: 31.843452, kld: 0.239678\n",
      "Train Epoch: 71 [15360/22533 (68%)]      Loss: 32.314934\n",
      "bce: 32.196411, kld: 0.237045\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 31.053373\n",
      "bce: 30.933935, kld: 0.238876\n",
      "====> Epoch: 71 Average loss: 32.0470, bce: 31.9275, kld: 0.2390\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 31.650486\n",
      "bce: 31.531881, kld: 0.237211\n",
      "Train Epoch: 72 [5120/22533 (23%)]      Loss: 32.234573\n",
      "bce: 32.119766, kld: 0.229613\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 31.269081\n",
      "bce: 31.148819, kld: 0.240525\n",
      "Train Epoch: 72 [15360/22533 (68%)]      Loss: 32.059570\n",
      "bce: 31.935406, kld: 0.248331\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 31.700586\n",
      "bce: 31.579739, kld: 0.241696\n",
      "====> Epoch: 72 Average loss: 31.7887, bce: 31.6679, kld: 0.2416\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 31.184843\n",
      "bce: 31.066948, kld: 0.235791\n",
      "Train Epoch: 73 [5120/22533 (23%)]      Loss: 30.569954\n",
      "bce: 30.451727, kld: 0.236456\n",
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 31.404469\n",
      "bce: 31.284149, kld: 0.240638\n",
      "Train Epoch: 73 [15360/22533 (68%)]      Loss: 31.826145\n",
      "bce: 31.705564, kld: 0.241162\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 31.571014\n",
      "bce: 31.446886, kld: 0.248257\n",
      "====> Epoch: 73 Average loss: 31.5263, bce: 31.4056, kld: 0.2413\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 31.598007\n",
      "bce: 31.475821, kld: 0.244373\n",
      "Train Epoch: 74 [5120/22533 (23%)]      Loss: 30.853334\n",
      "bce: 30.732567, kld: 0.241535\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 30.208496\n",
      "bce: 30.088202, kld: 0.240591\n",
      "Train Epoch: 74 [15360/22533 (68%)]      Loss: 30.776146\n",
      "bce: 30.655748, kld: 0.240796\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 31.128145\n",
      "bce: 31.007498, kld: 0.241295\n",
      "====> Epoch: 74 Average loss: 31.1151, bce: 30.9930, kld: 0.2440\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 31.158171\n",
      "bce: 31.036545, kld: 0.243253\n",
      "Train Epoch: 75 [5120/22533 (23%)]      Loss: 30.644260\n",
      "bce: 30.527189, kld: 0.234144\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 30.357956\n",
      "bce: 30.240217, kld: 0.235479\n",
      "Train Epoch: 75 [15360/22533 (68%)]      Loss: 30.903975\n",
      "bce: 30.788361, kld: 0.231230\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 30.290720\n",
      "bce: 30.173111, kld: 0.235218\n",
      "====> Epoch: 75 Average loss: 30.7658, bce: 30.6460, kld: 0.2397\n",
      "====> Testing Average Loss: 24.690350246721476\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 30.924278\n",
      "bce: 30.806286, kld: 0.235984\n",
      "Train Epoch: 76 [5120/22533 (23%)]      Loss: 30.988882\n",
      "bce: 30.865566, kld: 0.246633\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 31.220596\n",
      "bce: 31.098316, kld: 0.244559\n",
      "Train Epoch: 76 [15360/22533 (68%)]      Loss: 30.334833\n",
      "bce: 30.221561, kld: 0.226543\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 30.100657\n",
      "bce: 29.980724, kld: 0.239866\n",
      "====> Epoch: 76 Average loss: 30.5117, bce: 30.3924, kld: 0.2385\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 30.934025\n",
      "bce: 30.813648, kld: 0.240752\n",
      "Train Epoch: 77 [5120/22533 (23%)]      Loss: 29.949118\n",
      "bce: 29.820854, kld: 0.256526\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 30.906464\n",
      "bce: 30.791393, kld: 0.230139\n",
      "Train Epoch: 77 [15360/22533 (68%)]      Loss: 30.244251\n",
      "bce: 30.126240, kld: 0.236024\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 29.943432\n",
      "bce: 29.821033, kld: 0.244796\n",
      "====> Epoch: 77 Average loss: 30.2969, bce: 30.1753, kld: 0.2433\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 29.935337\n",
      "bce: 29.819603, kld: 0.231470\n",
      "Train Epoch: 78 [5120/22533 (23%)]      Loss: 29.493229\n",
      "bce: 29.373291, kld: 0.239877\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 30.437979\n",
      "bce: 30.316820, kld: 0.242315\n",
      "Train Epoch: 78 [15360/22533 (68%)]      Loss: 30.078688\n",
      "bce: 29.959269, kld: 0.238837\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 30.357931\n",
      "bce: 30.244606, kld: 0.226650\n",
      "====> Epoch: 78 Average loss: 29.9081, bce: 29.7889, kld: 0.2383\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 29.529459\n",
      "bce: 29.407318, kld: 0.244283\n",
      "Train Epoch: 79 [5120/22533 (23%)]      Loss: 29.297546\n",
      "bce: 29.172615, kld: 0.249863\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 29.496353\n",
      "bce: 29.378101, kld: 0.236503\n",
      "Train Epoch: 79 [15360/22533 (68%)]      Loss: 30.017704\n",
      "bce: 29.904226, kld: 0.226955\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 29.792917\n",
      "bce: 29.675774, kld: 0.234285\n",
      "====> Epoch: 79 Average loss: 29.6758, bce: 29.5554, kld: 0.2410\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 28.865395\n",
      "bce: 28.742992, kld: 0.244804\n",
      "Train Epoch: 80 [5120/22533 (23%)]      Loss: 29.418142\n",
      "bce: 29.299231, kld: 0.237822\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 29.681175\n",
      "bce: 29.560528, kld: 0.241294\n",
      "Train Epoch: 80 [15360/22533 (68%)]      Loss: 30.075937\n",
      "bce: 29.960245, kld: 0.231385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 29.560556\n",
      "bce: 29.446877, kld: 0.227358\n",
      "====> Epoch: 80 Average loss: 29.4224, bce: 29.3015, kld: 0.2417\n",
      "====> Testing Average Loss: 23.68354642357875\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 29.475115\n",
      "bce: 29.355560, kld: 0.239108\n",
      "Train Epoch: 81 [5120/22533 (23%)]      Loss: 29.206165\n",
      "bce: 29.093088, kld: 0.226155\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 29.404476\n",
      "bce: 29.284557, kld: 0.239839\n",
      "Train Epoch: 81 [15360/22533 (68%)]      Loss: 29.682743\n",
      "bce: 29.560947, kld: 0.243593\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 29.301960\n",
      "bce: 29.183235, kld: 0.237449\n",
      "====> Epoch: 81 Average loss: 29.1529, bce: 29.0328, kld: 0.2403\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 28.429586\n",
      "bce: 28.308479, kld: 0.242216\n",
      "Train Epoch: 82 [5120/22533 (23%)]      Loss: 28.853672\n",
      "bce: 28.735399, kld: 0.236545\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 28.853407\n",
      "bce: 28.734514, kld: 0.237785\n",
      "Train Epoch: 82 [15360/22533 (68%)]      Loss: 29.115810\n",
      "bce: 29.000650, kld: 0.230321\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 29.242992\n",
      "bce: 29.125366, kld: 0.235251\n",
      "====> Epoch: 82 Average loss: 28.9206, bce: 28.8006, kld: 0.2398\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 28.813431\n",
      "bce: 28.697596, kld: 0.231669\n",
      "Train Epoch: 83 [5120/22533 (23%)]      Loss: 28.169945\n",
      "bce: 28.052490, kld: 0.234908\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 28.513788\n",
      "bce: 28.386782, kld: 0.254015\n",
      "Train Epoch: 83 [15360/22533 (68%)]      Loss: 29.245689\n",
      "bce: 29.128143, kld: 0.235091\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 28.925844\n",
      "bce: 28.803658, kld: 0.244374\n",
      "====> Epoch: 83 Average loss: 28.6396, bce: 28.5192, kld: 0.2408\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 28.677040\n",
      "bce: 28.561165, kld: 0.231750\n",
      "Train Epoch: 84 [5120/22533 (23%)]      Loss: 28.943724\n",
      "bce: 28.822287, kld: 0.242875\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 27.914547\n",
      "bce: 27.798176, kld: 0.232744\n",
      "Train Epoch: 84 [15360/22533 (68%)]      Loss: 28.566011\n",
      "bce: 28.447102, kld: 0.237821\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 28.019749\n",
      "bce: 27.904442, kld: 0.230612\n",
      "====> Epoch: 84 Average loss: 28.4209, bce: 28.3001, kld: 0.2415\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 27.987597\n",
      "bce: 27.871943, kld: 0.231309\n",
      "Train Epoch: 85 [5120/22533 (23%)]      Loss: 28.736351\n",
      "bce: 28.624407, kld: 0.223889\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 28.282516\n",
      "bce: 28.160540, kld: 0.243955\n",
      "Train Epoch: 85 [15360/22533 (68%)]      Loss: 28.078686\n",
      "bce: 27.957899, kld: 0.241572\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 28.068254\n",
      "bce: 27.948250, kld: 0.240009\n",
      "====> Epoch: 85 Average loss: 28.1404, bce: 28.0209, kld: 0.2391\n",
      "====> Testing Average Loss: 22.57052234847224\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 27.915634\n",
      "bce: 27.790281, kld: 0.250707\n",
      "Train Epoch: 86 [5120/22533 (23%)]      Loss: 27.832422\n",
      "bce: 27.710016, kld: 0.244812\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 28.549820\n",
      "bce: 28.428513, kld: 0.242614\n",
      "Train Epoch: 86 [15360/22533 (68%)]      Loss: 27.527653\n",
      "bce: 27.406219, kld: 0.242868\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 27.601130\n",
      "bce: 27.479374, kld: 0.243512\n",
      "====> Epoch: 86 Average loss: 27.9143, bce: 27.7951, kld: 0.2385\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 27.696905\n",
      "bce: 27.583029, kld: 0.227752\n",
      "Train Epoch: 87 [5120/22533 (23%)]      Loss: 29.170559\n",
      "bce: 29.046700, kld: 0.247719\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 27.615141\n",
      "bce: 27.496857, kld: 0.236567\n",
      "Train Epoch: 87 [15360/22533 (68%)]      Loss: 28.213461\n",
      "bce: 28.092190, kld: 0.242543\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 28.147602\n",
      "bce: 28.026905, kld: 0.241394\n",
      "====> Epoch: 87 Average loss: 27.7350, bce: 27.6145, kld: 0.2411\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 27.373188\n",
      "bce: 27.256489, kld: 0.233400\n",
      "Train Epoch: 88 [5120/22533 (23%)]      Loss: 27.978655\n",
      "bce: 27.851536, kld: 0.254239\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 27.457664\n",
      "bce: 27.330286, kld: 0.254756\n",
      "Train Epoch: 88 [15360/22533 (68%)]      Loss: 27.807850\n",
      "bce: 27.685707, kld: 0.244287\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 27.897268\n",
      "bce: 27.768898, kld: 0.256740\n",
      "====> Epoch: 88 Average loss: 27.5440, bce: 27.4218, kld: 0.2444\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 27.353729\n",
      "bce: 27.230658, kld: 0.246143\n",
      "Train Epoch: 89 [5120/22533 (23%)]      Loss: 27.786795\n",
      "bce: 27.665752, kld: 0.242086\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 27.311405\n",
      "bce: 27.182388, kld: 0.258034\n",
      "Train Epoch: 89 [15360/22533 (68%)]      Loss: 27.307529\n",
      "bce: 27.188416, kld: 0.238230\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 27.162380\n",
      "bce: 27.048197, kld: 0.228368\n",
      "====> Epoch: 89 Average loss: 27.2476, bce: 27.1253, kld: 0.2444\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 26.753450\n",
      "bce: 26.633974, kld: 0.238954\n",
      "Train Epoch: 90 [5120/22533 (23%)]      Loss: 26.701183\n",
      "bce: 26.582922, kld: 0.236522\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 27.017550\n",
      "bce: 26.890427, kld: 0.254245\n",
      "Train Epoch: 90 [15360/22533 (68%)]      Loss: 27.166267\n",
      "bce: 27.044765, kld: 0.243003\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 27.423613\n",
      "bce: 27.307281, kld: 0.232662\n",
      "====> Epoch: 90 Average loss: 26.9615, bce: 26.8418, kld: 0.2394\n",
      "====> Testing Average Loss: 21.693070215766877\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 26.945572\n",
      "bce: 26.824245, kld: 0.242653\n",
      "Train Epoch: 91 [5120/22533 (23%)]      Loss: 26.456173\n",
      "bce: 26.335306, kld: 0.241733\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 26.416395\n",
      "bce: 26.296623, kld: 0.239544\n",
      "Train Epoch: 91 [15360/22533 (68%)]      Loss: 27.011698\n",
      "bce: 26.886570, kld: 0.250257\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 27.164146\n",
      "bce: 27.043409, kld: 0.241475\n",
      "====> Epoch: 91 Average loss: 26.7251, bce: 26.6047, kld: 0.2407\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 26.069239\n",
      "bce: 25.954517, kld: 0.229443\n",
      "Train Epoch: 92 [5120/22533 (23%)]      Loss: 26.829832\n",
      "bce: 26.710606, kld: 0.238452\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 25.904577\n",
      "bce: 25.788017, kld: 0.233119\n",
      "Train Epoch: 92 [15360/22533 (68%)]      Loss: 26.865000\n",
      "bce: 26.743952, kld: 0.242097\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 26.329706\n",
      "bce: 26.217262, kld: 0.224889\n",
      "====> Epoch: 92 Average loss: 26.5653, bce: 26.4449, kld: 0.2408\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 25.920876\n",
      "bce: 25.798237, kld: 0.245276\n",
      "Train Epoch: 93 [5120/22533 (23%)]      Loss: 25.839876\n",
      "bce: 25.723841, kld: 0.232072\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 26.492796\n",
      "bce: 26.373051, kld: 0.239492\n",
      "Train Epoch: 93 [15360/22533 (68%)]      Loss: 25.564371\n",
      "bce: 25.445887, kld: 0.236968\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 26.127796\n",
      "bce: 26.000690, kld: 0.254210\n",
      "====> Epoch: 93 Average loss: 26.3303, bce: 26.2113, kld: 0.2380\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 25.842880\n",
      "bce: 25.716908, kld: 0.251945\n",
      "Train Epoch: 94 [5120/22533 (23%)]      Loss: 26.228786\n",
      "bce: 26.108086, kld: 0.241403\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 25.935322\n",
      "bce: 25.813698, kld: 0.243248\n",
      "Train Epoch: 94 [15360/22533 (68%)]      Loss: 25.954817\n",
      "bce: 25.832008, kld: 0.245617\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 26.210747\n",
      "bce: 26.089626, kld: 0.242240\n",
      "====> Epoch: 94 Average loss: 26.1618, bce: 26.0409, kld: 0.2417\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 26.158222\n",
      "bce: 26.032700, kld: 0.251046\n",
      "Train Epoch: 95 [5120/22533 (23%)]      Loss: 26.262321\n",
      "bce: 26.143745, kld: 0.237153\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 25.521025\n",
      "bce: 25.394436, kld: 0.253178\n",
      "Train Epoch: 95 [15360/22533 (68%)]      Loss: 26.141737\n",
      "bce: 26.017982, kld: 0.247510\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 26.211081\n",
      "bce: 26.088610, kld: 0.244942\n",
      "====> Epoch: 95 Average loss: 25.9438, bce: 25.8232, kld: 0.2412\n",
      "====> Testing Average Loss: 21.045453907186126\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 25.921358\n",
      "bce: 25.802292, kld: 0.238131\n",
      "Train Epoch: 96 [5120/22533 (23%)]      Loss: 25.688679\n",
      "bce: 25.566517, kld: 0.244325\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 25.765507\n",
      "bce: 25.645882, kld: 0.239249\n",
      "Train Epoch: 96 [15360/22533 (68%)]      Loss: 25.097027\n",
      "bce: 24.979235, kld: 0.235586\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 25.494303\n",
      "bce: 25.380264, kld: 0.228076\n",
      "====> Epoch: 96 Average loss: 25.7655, bce: 25.6461, kld: 0.2387\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 26.687279\n",
      "bce: 26.564249, kld: 0.246059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [5120/22533 (23%)]      Loss: 25.679329\n",
      "bce: 25.555672, kld: 0.247313\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 25.225525\n",
      "bce: 25.106270, kld: 0.238510\n",
      "Train Epoch: 97 [15360/22533 (68%)]      Loss: 25.544321\n",
      "bce: 25.424627, kld: 0.239388\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 25.019791\n",
      "bce: 24.901840, kld: 0.235899\n",
      "====> Epoch: 97 Average loss: 25.5778, bce: 25.4566, kld: 0.2426\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 24.973890\n",
      "bce: 24.849091, kld: 0.249601\n",
      "Train Epoch: 98 [5120/22533 (23%)]      Loss: 24.806620\n",
      "bce: 24.690580, kld: 0.232077\n",
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 24.401934\n",
      "bce: 24.274960, kld: 0.253947\n",
      "Train Epoch: 98 [15360/22533 (68%)]      Loss: 25.716116\n",
      "bce: 25.601521, kld: 0.229192\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 25.098579\n",
      "bce: 24.969837, kld: 0.257485\n",
      "====> Epoch: 98 Average loss: 25.3719, bce: 25.2509, kld: 0.2420\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 24.847128\n",
      "bce: 24.726372, kld: 0.241512\n",
      "Train Epoch: 99 [5120/22533 (23%)]      Loss: 25.332359\n",
      "bce: 25.214954, kld: 0.234810\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 24.881496\n",
      "bce: 24.763227, kld: 0.236536\n",
      "Train Epoch: 99 [15360/22533 (68%)]      Loss: 25.318806\n",
      "bce: 25.200588, kld: 0.236436\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 25.261478\n",
      "bce: 25.142590, kld: 0.237776\n",
      "====> Epoch: 99 Average loss: 25.1254, bce: 25.0053, kld: 0.2401\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 25.128027\n",
      "bce: 25.016212, kld: 0.223629\n",
      "Train Epoch: 100 [5120/22533 (23%)]      Loss: 25.036726\n",
      "bce: 24.917906, kld: 0.237640\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 25.368769\n",
      "bce: 25.249619, kld: 0.238300\n",
      "Train Epoch: 100 [15360/22533 (68%)]      Loss: 24.994278\n",
      "bce: 24.875938, kld: 0.236680\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 25.521677\n",
      "bce: 25.399313, kld: 0.244728\n",
      "====> Epoch: 100 Average loss: 24.9989, bce: 24.8791, kld: 0.2395\n",
      "====> Testing Average Loss: 19.882662459642525\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 24.539959\n",
      "bce: 24.418221, kld: 0.243479\n",
      "Train Epoch: 101 [5120/22533 (23%)]      Loss: 24.782499\n",
      "bce: 24.663773, kld: 0.237454\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 24.962580\n",
      "bce: 24.837027, kld: 0.251107\n",
      "Train Epoch: 101 [15360/22533 (68%)]      Loss: 24.192749\n",
      "bce: 24.070883, kld: 0.243733\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 24.293058\n",
      "bce: 24.173786, kld: 0.238544\n",
      "====> Epoch: 101 Average loss: 24.8240, bce: 24.7029, kld: 0.2422\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 24.251820\n",
      "bce: 24.130064, kld: 0.243511\n",
      "Train Epoch: 102 [5120/22533 (23%)]      Loss: 24.288078\n",
      "bce: 24.171646, kld: 0.232866\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 24.879570\n",
      "bce: 24.751925, kld: 0.255290\n",
      "Train Epoch: 102 [15360/22533 (68%)]      Loss: 24.785536\n",
      "bce: 24.658092, kld: 0.254885\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 24.624426\n",
      "bce: 24.497976, kld: 0.252901\n",
      "====> Epoch: 102 Average loss: 24.6407, bce: 24.5194, kld: 0.2425\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 24.725546\n",
      "bce: 24.602884, kld: 0.245323\n",
      "Train Epoch: 103 [5120/22533 (23%)]      Loss: 24.563484\n",
      "bce: 24.441746, kld: 0.243477\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 24.960918\n",
      "bce: 24.837536, kld: 0.246764\n",
      "Train Epoch: 103 [15360/22533 (68%)]      Loss: 23.994753\n",
      "bce: 23.876354, kld: 0.236799\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 24.663170\n",
      "bce: 24.551369, kld: 0.223604\n",
      "====> Epoch: 103 Average loss: 24.4795, bce: 24.3592, kld: 0.2405\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 24.193291\n",
      "bce: 24.073433, kld: 0.239716\n",
      "Train Epoch: 104 [5120/22533 (23%)]      Loss: 24.803946\n",
      "bce: 24.682785, kld: 0.242320\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 24.283939\n",
      "bce: 24.166561, kld: 0.234756\n",
      "Train Epoch: 104 [15360/22533 (68%)]      Loss: 23.540936\n",
      "bce: 23.426451, kld: 0.228968\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 24.298666\n",
      "bce: 24.169483, kld: 0.258366\n",
      "====> Epoch: 104 Average loss: 24.3159, bce: 24.1945, kld: 0.2429\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 23.633776\n",
      "bce: 23.506876, kld: 0.253798\n",
      "Train Epoch: 105 [5120/22533 (23%)]      Loss: 24.264488\n",
      "bce: 24.141687, kld: 0.245600\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 24.339014\n",
      "bce: 24.225887, kld: 0.226253\n",
      "Train Epoch: 105 [15360/22533 (68%)]      Loss: 24.402746\n",
      "bce: 24.273830, kld: 0.257832\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 23.838785\n",
      "bce: 23.720905, kld: 0.235759\n",
      "====> Epoch: 105 Average loss: 24.1592, bce: 24.0379, kld: 0.2425\n",
      "====> Testing Average Loss: 19.4024058984323\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 23.498209\n",
      "bce: 23.381630, kld: 0.233158\n",
      "Train Epoch: 106 [5120/22533 (23%)]      Loss: 24.210699\n",
      "bce: 24.092159, kld: 0.237080\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 24.274885\n",
      "bce: 24.152233, kld: 0.245306\n",
      "Train Epoch: 106 [15360/22533 (68%)]      Loss: 24.331047\n",
      "bce: 24.203037, kld: 0.256019\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 23.267117\n",
      "bce: 23.143692, kld: 0.246848\n",
      "====> Epoch: 106 Average loss: 23.9677, bce: 23.8461, kld: 0.2431\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 23.607237\n",
      "bce: 23.485233, kld: 0.244008\n",
      "Train Epoch: 107 [5120/22533 (23%)]      Loss: 24.174406\n",
      "bce: 24.053780, kld: 0.241254\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 23.876387\n",
      "bce: 23.755619, kld: 0.241533\n",
      "Train Epoch: 107 [15360/22533 (68%)]      Loss: 23.766073\n",
      "bce: 23.644320, kld: 0.243507\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 23.843220\n",
      "bce: 23.719597, kld: 0.247246\n",
      "====> Epoch: 107 Average loss: 23.8413, bce: 23.7197, kld: 0.2431\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 22.858402\n",
      "bce: 22.740894, kld: 0.235016\n",
      "Train Epoch: 108 [5120/22533 (23%)]      Loss: 23.571356\n",
      "bce: 23.454292, kld: 0.234127\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 24.267971\n",
      "bce: 24.149593, kld: 0.236757\n",
      "Train Epoch: 108 [15360/22533 (68%)]      Loss: 23.589464\n",
      "bce: 23.470436, kld: 0.238057\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 23.333864\n",
      "bce: 23.211071, kld: 0.245587\n",
      "====> Epoch: 108 Average loss: 23.6411, bce: 23.5200, kld: 0.2421\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 24.315092\n",
      "bce: 24.189358, kld: 0.251468\n",
      "Train Epoch: 109 [5120/22533 (23%)]      Loss: 23.118479\n",
      "bce: 22.999851, kld: 0.237254\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 23.516619\n",
      "bce: 23.392387, kld: 0.248461\n",
      "Train Epoch: 109 [15360/22533 (68%)]      Loss: 23.720413\n",
      "bce: 23.595974, kld: 0.248877\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 23.792162\n",
      "bce: 23.669571, kld: 0.245183\n",
      "====> Epoch: 109 Average loss: 23.5234, bce: 23.4016, kld: 0.2436\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 23.490543\n",
      "bce: 23.370129, kld: 0.240829\n",
      "Train Epoch: 110 [5120/22533 (23%)]      Loss: 23.030657\n",
      "bce: 22.906551, kld: 0.248209\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 23.336285\n",
      "bce: 23.215401, kld: 0.241766\n",
      "Train Epoch: 110 [15360/22533 (68%)]      Loss: 23.802704\n",
      "bce: 23.683825, kld: 0.237757\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 23.720955\n",
      "bce: 23.593327, kld: 0.255258\n",
      "====> Epoch: 110 Average loss: 23.3448, bce: 23.2225, kld: 0.2445\n",
      "====> Testing Average Loss: 18.631261649580615\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 23.066055\n",
      "bce: 22.944050, kld: 0.244009\n",
      "Train Epoch: 111 [5120/22533 (23%)]      Loss: 22.966476\n",
      "bce: 22.844168, kld: 0.244618\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 22.730354\n",
      "bce: 22.618195, kld: 0.224319\n",
      "Train Epoch: 111 [15360/22533 (68%)]      Loss: 23.248310\n",
      "bce: 23.127348, kld: 0.241924\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 23.365911\n",
      "bce: 23.244596, kld: 0.242629\n",
      "====> Epoch: 111 Average loss: 23.1640, bce: 23.0426, kld: 0.2428\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 23.065601\n",
      "bce: 22.944790, kld: 0.241622\n",
      "Train Epoch: 112 [5120/22533 (23%)]      Loss: 22.548862\n",
      "bce: 22.420597, kld: 0.256532\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 22.712658\n",
      "bce: 22.588774, kld: 0.247768\n",
      "Train Epoch: 112 [15360/22533 (68%)]      Loss: 23.607130\n",
      "bce: 23.490005, kld: 0.234248\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 22.499645\n",
      "bce: 22.374691, kld: 0.249910\n",
      "====> Epoch: 112 Average loss: 23.0018, bce: 22.8801, kld: 0.2435\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 23.153118\n",
      "bce: 23.037579, kld: 0.231078\n",
      "Train Epoch: 113 [5120/22533 (23%)]      Loss: 22.801062\n",
      "bce: 22.680336, kld: 0.241451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 23.222115\n",
      "bce: 23.098406, kld: 0.247416\n",
      "Train Epoch: 113 [15360/22533 (68%)]      Loss: 22.682909\n",
      "bce: 22.558613, kld: 0.248593\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 23.312771\n",
      "bce: 23.189356, kld: 0.246829\n",
      "====> Epoch: 113 Average loss: 22.8737, bce: 22.7532, kld: 0.2410\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 22.372684\n",
      "bce: 22.253307, kld: 0.238753\n",
      "Train Epoch: 114 [5120/22533 (23%)]      Loss: 23.061949\n",
      "bce: 22.939402, kld: 0.245094\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 22.186172\n",
      "bce: 22.065144, kld: 0.242056\n",
      "Train Epoch: 114 [15360/22533 (68%)]      Loss: 22.611389\n",
      "bce: 22.490475, kld: 0.241828\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 23.054935\n",
      "bce: 22.929577, kld: 0.250718\n",
      "====> Epoch: 114 Average loss: 22.6962, bce: 22.5747, kld: 0.2430\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 22.636095\n",
      "bce: 22.510796, kld: 0.250600\n",
      "Train Epoch: 115 [5120/22533 (23%)]      Loss: 22.360720\n",
      "bce: 22.239178, kld: 0.243083\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 22.207937\n",
      "bce: 22.086533, kld: 0.242809\n",
      "Train Epoch: 115 [15360/22533 (68%)]      Loss: 22.036572\n",
      "bce: 21.911041, kld: 0.251060\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 23.010275\n",
      "bce: 22.886335, kld: 0.247878\n",
      "====> Epoch: 115 Average loss: 22.5517, bce: 22.4304, kld: 0.2426\n",
      "====> Testing Average Loss: 19.100229299111305\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 22.686323\n",
      "bce: 22.562637, kld: 0.247373\n",
      "Train Epoch: 116 [5120/22533 (23%)]      Loss: 22.024654\n",
      "bce: 21.898911, kld: 0.251489\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 22.068624\n",
      "bce: 21.940762, kld: 0.255724\n",
      "Train Epoch: 116 [15360/22533 (68%)]      Loss: 23.210529\n",
      "bce: 23.094727, kld: 0.231604\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 22.385447\n",
      "bce: 22.265385, kld: 0.240124\n",
      "====> Epoch: 116 Average loss: 22.4729, bce: 22.3502, kld: 0.2452\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 22.243273\n",
      "bce: 22.125914, kld: 0.234718\n",
      "Train Epoch: 117 [5120/22533 (23%)]      Loss: 22.210587\n",
      "bce: 22.090302, kld: 0.240571\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 22.304874\n",
      "bce: 22.180969, kld: 0.247810\n",
      "Train Epoch: 117 [15360/22533 (68%)]      Loss: 21.943705\n",
      "bce: 21.815332, kld: 0.256743\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 22.624620\n",
      "bce: 22.501379, kld: 0.246483\n",
      "====> Epoch: 117 Average loss: 22.3488, bce: 22.2263, kld: 0.2449\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 21.814816\n",
      "bce: 21.688995, kld: 0.251640\n",
      "Train Epoch: 118 [5120/22533 (23%)]      Loss: 22.629574\n",
      "bce: 22.505547, kld: 0.248055\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 22.559769\n",
      "bce: 22.434147, kld: 0.251243\n",
      "Train Epoch: 118 [15360/22533 (68%)]      Loss: 22.340960\n",
      "bce: 22.213253, kld: 0.255414\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 22.555937\n",
      "bce: 22.431467, kld: 0.248938\n",
      "====> Epoch: 118 Average loss: 22.2618, bce: 22.1386, kld: 0.2463\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 22.400440\n",
      "bce: 22.275391, kld: 0.250098\n",
      "Train Epoch: 119 [5120/22533 (23%)]      Loss: 22.642159\n",
      "bce: 22.516010, kld: 0.252296\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 22.166008\n",
      "bce: 22.039431, kld: 0.253153\n",
      "Train Epoch: 119 [15360/22533 (68%)]      Loss: 21.936819\n",
      "bce: 21.812107, kld: 0.249426\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 21.995058\n",
      "bce: 21.875999, kld: 0.238117\n",
      "====> Epoch: 119 Average loss: 22.1013, bce: 21.9777, kld: 0.2472\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 22.220881\n",
      "bce: 22.098942, kld: 0.243876\n",
      "Train Epoch: 120 [5120/22533 (23%)]      Loss: 21.388514\n",
      "bce: 21.263992, kld: 0.249042\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 22.135120\n",
      "bce: 22.011269, kld: 0.247702\n",
      "Train Epoch: 120 [15360/22533 (68%)]      Loss: 22.001545\n",
      "bce: 21.874146, kld: 0.254799\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 21.704884\n",
      "bce: 21.577198, kld: 0.255372\n",
      "====> Epoch: 120 Average loss: 21.9530, bce: 21.8294, kld: 0.2471\n",
      "====> Testing Average Loss: 17.127600352815872\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 21.817713\n",
      "bce: 21.693642, kld: 0.248144\n",
      "Train Epoch: 121 [5120/22533 (23%)]      Loss: 21.303154\n",
      "bce: 21.186741, kld: 0.232825\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 21.897463\n",
      "bce: 21.769207, kld: 0.256513\n",
      "Train Epoch: 121 [15360/22533 (68%)]      Loss: 21.986946\n",
      "bce: 21.864420, kld: 0.245051\n",
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 21.636019\n",
      "bce: 21.519699, kld: 0.232640\n",
      "====> Epoch: 121 Average loss: 21.8231, bce: 21.7002, kld: 0.2457\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 21.407902\n",
      "bce: 21.285042, kld: 0.245720\n",
      "Train Epoch: 122 [5120/22533 (23%)]      Loss: 21.757660\n",
      "bce: 21.637634, kld: 0.240052\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 21.560858\n",
      "bce: 21.439396, kld: 0.242922\n",
      "Train Epoch: 122 [15360/22533 (68%)]      Loss: 21.113464\n",
      "bce: 20.983063, kld: 0.260805\n",
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 21.744255\n",
      "bce: 21.616707, kld: 0.255096\n",
      "====> Epoch: 122 Average loss: 21.6758, bce: 21.5519, kld: 0.2478\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 21.923742\n",
      "bce: 21.799425, kld: 0.248634\n",
      "Train Epoch: 123 [5120/22533 (23%)]      Loss: 22.330597\n",
      "bce: 22.207914, kld: 0.245367\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 20.765882\n",
      "bce: 20.642334, kld: 0.247097\n",
      "Train Epoch: 123 [15360/22533 (68%)]      Loss: 21.294479\n",
      "bce: 21.171833, kld: 0.245293\n",
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 22.078344\n",
      "bce: 21.951202, kld: 0.254285\n",
      "====> Epoch: 123 Average loss: 21.5201, bce: 21.3971, kld: 0.2459\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 21.547733\n",
      "bce: 21.424866, kld: 0.245735\n",
      "Train Epoch: 124 [5120/22533 (23%)]      Loss: 20.849489\n",
      "bce: 20.731361, kld: 0.236257\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 21.310455\n",
      "bce: 21.188951, kld: 0.243009\n",
      "Train Epoch: 124 [15360/22533 (68%)]      Loss: 21.865499\n",
      "bce: 21.741203, kld: 0.248591\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 21.263830\n",
      "bce: 21.132450, kld: 0.262760\n",
      "====> Epoch: 124 Average loss: 21.3983, bce: 21.2755, kld: 0.2457\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 21.477741\n",
      "bce: 21.360174, kld: 0.235135\n",
      "Train Epoch: 125 [5120/22533 (23%)]      Loss: 21.515640\n",
      "bce: 21.393465, kld: 0.244351\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 20.954651\n",
      "bce: 20.830616, kld: 0.248070\n",
      "Train Epoch: 125 [15360/22533 (68%)]      Loss: 21.440844\n",
      "bce: 21.323635, kld: 0.234418\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 21.236349\n",
      "bce: 21.114740, kld: 0.243216\n",
      "====> Epoch: 125 Average loss: 21.3020, bce: 21.1784, kld: 0.2471\n",
      "====> Testing Average Loss: 16.98708664791639\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 21.879135\n",
      "bce: 21.753727, kld: 0.250817\n",
      "Train Epoch: 126 [5120/22533 (23%)]      Loss: 21.004017\n",
      "bce: 20.884113, kld: 0.239808\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 21.002420\n",
      "bce: 20.876783, kld: 0.251274\n",
      "Train Epoch: 126 [15360/22533 (68%)]      Loss: 21.212936\n",
      "bce: 21.085079, kld: 0.255715\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 21.163101\n",
      "bce: 21.041233, kld: 0.243737\n",
      "====> Epoch: 126 Average loss: 21.2152, bce: 21.0909, kld: 0.2486\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 21.303518\n",
      "bce: 21.180391, kld: 0.246255\n",
      "Train Epoch: 127 [5120/22533 (23%)]      Loss: 20.645252\n",
      "bce: 20.520411, kld: 0.249683\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 20.552011\n",
      "bce: 20.434767, kld: 0.234491\n",
      "Train Epoch: 127 [15360/22533 (68%)]      Loss: 20.766607\n",
      "bce: 20.648489, kld: 0.236238\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 20.981787\n",
      "bce: 20.856148, kld: 0.251276\n",
      "====> Epoch: 127 Average loss: 21.0764, bce: 20.9532, kld: 0.2465\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 20.500595\n",
      "bce: 20.373732, kld: 0.253728\n",
      "Train Epoch: 128 [5120/22533 (23%)]      Loss: 20.833904\n",
      "bce: 20.714291, kld: 0.239227\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 22.051104\n",
      "bce: 21.930832, kld: 0.240544\n",
      "Train Epoch: 128 [15360/22533 (68%)]      Loss: 21.019386\n",
      "bce: 20.895994, kld: 0.246785\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 20.383694\n",
      "bce: 20.261232, kld: 0.244922\n",
      "====> Epoch: 128 Average loss: 20.9411, bce: 20.8177, kld: 0.2467\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 21.210541\n",
      "bce: 21.084053, kld: 0.252974\n",
      "Train Epoch: 129 [5120/22533 (23%)]      Loss: 20.658777\n",
      "bce: 20.541283, kld: 0.234991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 20.983976\n",
      "bce: 20.857800, kld: 0.252353\n",
      "Train Epoch: 129 [15360/22533 (68%)]      Loss: 20.854979\n",
      "bce: 20.733971, kld: 0.242016\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 21.083282\n",
      "bce: 20.954519, kld: 0.257525\n",
      "====> Epoch: 129 Average loss: 20.8640, bce: 20.7405, kld: 0.2471\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 20.438189\n",
      "bce: 20.311142, kld: 0.254094\n",
      "Train Epoch: 130 [5120/22533 (23%)]      Loss: 20.230522\n",
      "bce: 20.109324, kld: 0.242395\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 20.381950\n",
      "bce: 20.257036, kld: 0.249828\n",
      "Train Epoch: 130 [15360/22533 (68%)]      Loss: 20.721626\n",
      "bce: 20.599297, kld: 0.244658\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 20.876062\n",
      "bce: 20.752945, kld: 0.246234\n",
      "====> Epoch: 130 Average loss: 20.7587, bce: 20.6350, kld: 0.2475\n",
      "====> Testing Average Loss: 16.92889283217947\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 20.142532\n",
      "bce: 20.022999, kld: 0.239069\n",
      "Train Epoch: 131 [5120/22533 (23%)]      Loss: 20.834507\n",
      "bce: 20.706005, kld: 0.257004\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 21.436989\n",
      "bce: 21.314808, kld: 0.244363\n",
      "Train Epoch: 131 [15360/22533 (68%)]      Loss: 20.309231\n",
      "bce: 20.180031, kld: 0.258402\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 21.402298\n",
      "bce: 21.277168, kld: 0.250261\n",
      "====> Epoch: 131 Average loss: 20.6520, bce: 20.5282, kld: 0.2477\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 21.027096\n",
      "bce: 20.901985, kld: 0.250222\n",
      "Train Epoch: 132 [5120/22533 (23%)]      Loss: 20.453491\n",
      "bce: 20.330837, kld: 0.245310\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 19.963713\n",
      "bce: 19.837234, kld: 0.252957\n",
      "Train Epoch: 132 [15360/22533 (68%)]      Loss: 20.449598\n",
      "bce: 20.326612, kld: 0.245973\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 20.793493\n",
      "bce: 20.657709, kld: 0.271569\n",
      "====> Epoch: 132 Average loss: 20.5432, bce: 20.4175, kld: 0.2514\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 20.162245\n",
      "bce: 20.037088, kld: 0.250312\n",
      "Train Epoch: 133 [5120/22533 (23%)]      Loss: 20.013151\n",
      "bce: 19.884504, kld: 0.257295\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 20.019489\n",
      "bce: 19.898909, kld: 0.241162\n",
      "Train Epoch: 133 [15360/22533 (68%)]      Loss: 19.937883\n",
      "bce: 19.810856, kld: 0.254053\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 20.095184\n",
      "bce: 19.971846, kld: 0.246679\n",
      "====> Epoch: 133 Average loss: 20.4255, bce: 20.3016, kld: 0.2479\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 19.741980\n",
      "bce: 19.615025, kld: 0.253908\n",
      "Train Epoch: 134 [5120/22533 (23%)]      Loss: 20.431887\n",
      "bce: 20.306396, kld: 0.250981\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 20.080711\n",
      "bce: 19.958647, kld: 0.244128\n",
      "Train Epoch: 134 [15360/22533 (68%)]      Loss: 20.551315\n",
      "bce: 20.423885, kld: 0.254859\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 20.299232\n",
      "bce: 20.181599, kld: 0.235266\n",
      "====> Epoch: 134 Average loss: 20.3106, bce: 20.1862, kld: 0.2488\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 20.537201\n",
      "bce: 20.413769, kld: 0.246866\n",
      "Train Epoch: 135 [5120/22533 (23%)]      Loss: 20.134539\n",
      "bce: 20.015047, kld: 0.238985\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 20.134777\n",
      "bce: 20.004665, kld: 0.260224\n",
      "Train Epoch: 135 [15360/22533 (68%)]      Loss: 20.609089\n",
      "bce: 20.481136, kld: 0.255904\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 19.827101\n",
      "bce: 19.698742, kld: 0.256717\n",
      "====> Epoch: 135 Average loss: 20.2264, bce: 20.1017, kld: 0.2493\n",
      "====> Testing Average Loss: 16.35169979862868\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 20.125389\n",
      "bce: 20.003925, kld: 0.242929\n",
      "Train Epoch: 136 [5120/22533 (23%)]      Loss: 20.080301\n",
      "bce: 19.955976, kld: 0.248648\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 19.741119\n",
      "bce: 19.609514, kld: 0.263212\n",
      "Train Epoch: 136 [15360/22533 (68%)]      Loss: 20.171175\n",
      "bce: 20.048359, kld: 0.245631\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 20.607670\n",
      "bce: 20.487671, kld: 0.239998\n",
      "====> Epoch: 136 Average loss: 20.0964, bce: 19.9713, kld: 0.2501\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 20.466978\n",
      "bce: 20.341146, kld: 0.251663\n",
      "Train Epoch: 137 [5120/22533 (23%)]      Loss: 19.793568\n",
      "bce: 19.668064, kld: 0.251006\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 20.536797\n",
      "bce: 20.410582, kld: 0.252430\n",
      "Train Epoch: 137 [15360/22533 (68%)]      Loss: 19.668543\n",
      "bce: 19.545841, kld: 0.245405\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 19.673573\n",
      "bce: 19.552017, kld: 0.243111\n",
      "====> Epoch: 137 Average loss: 19.9955, bce: 19.8712, kld: 0.2488\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 19.906410\n",
      "bce: 19.778244, kld: 0.256334\n",
      "Train Epoch: 138 [5120/22533 (23%)]      Loss: 19.790443\n",
      "bce: 19.669571, kld: 0.241747\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 19.835485\n",
      "bce: 19.711323, kld: 0.248327\n",
      "Train Epoch: 138 [15360/22533 (68%)]      Loss: 20.359291\n",
      "bce: 20.231478, kld: 0.255627\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 19.517262\n",
      "bce: 19.396177, kld: 0.242169\n",
      "====> Epoch: 138 Average loss: 19.9197, bce: 19.7940, kld: 0.2515\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 19.520281\n",
      "bce: 19.397839, kld: 0.244884\n",
      "Train Epoch: 139 [5120/22533 (23%)]      Loss: 19.534555\n",
      "bce: 19.409449, kld: 0.250212\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 19.946484\n",
      "bce: 19.819971, kld: 0.253023\n",
      "Train Epoch: 139 [15360/22533 (68%)]      Loss: 19.706617\n",
      "bce: 19.582314, kld: 0.248609\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 20.138821\n",
      "bce: 20.020082, kld: 0.237477\n",
      "====> Epoch: 139 Average loss: 19.8090, bce: 19.6835, kld: 0.2511\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 19.612547\n",
      "bce: 19.485790, kld: 0.253512\n",
      "Train Epoch: 140 [5120/22533 (23%)]      Loss: 19.067438\n",
      "bce: 18.940113, kld: 0.254650\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 20.079372\n",
      "bce: 19.955017, kld: 0.248711\n",
      "Train Epoch: 140 [15360/22533 (68%)]      Loss: 20.547594\n",
      "bce: 20.418324, kld: 0.258542\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 19.963137\n",
      "bce: 19.835312, kld: 0.255650\n",
      "====> Epoch: 140 Average loss: 19.6857, bce: 19.5606, kld: 0.2502\n",
      "====> Testing Average Loss: 15.737857132455732\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 19.681803\n",
      "bce: 19.559090, kld: 0.245426\n",
      "Train Epoch: 141 [5120/22533 (23%)]      Loss: 19.552568\n",
      "bce: 19.424885, kld: 0.255366\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 19.377504\n",
      "bce: 19.248215, kld: 0.258581\n",
      "Train Epoch: 141 [15360/22533 (68%)]      Loss: 20.710522\n",
      "bce: 20.581644, kld: 0.257755\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 19.507130\n",
      "bce: 19.379349, kld: 0.255561\n",
      "====> Epoch: 141 Average loss: 19.6140, bce: 19.4892, kld: 0.2498\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 18.959929\n",
      "bce: 18.834743, kld: 0.250369\n",
      "Train Epoch: 142 [5120/22533 (23%)]      Loss: 19.883650\n",
      "bce: 19.759075, kld: 0.249148\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 19.529619\n",
      "bce: 19.405973, kld: 0.247292\n",
      "Train Epoch: 142 [15360/22533 (68%)]      Loss: 20.087919\n",
      "bce: 19.960745, kld: 0.254349\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 19.667368\n",
      "bce: 19.546280, kld: 0.242176\n",
      "====> Epoch: 142 Average loss: 19.5127, bce: 19.3876, kld: 0.2501\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 19.112663\n",
      "bce: 18.984297, kld: 0.256734\n",
      "Train Epoch: 143 [5120/22533 (23%)]      Loss: 19.469193\n",
      "bce: 19.346727, kld: 0.244932\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 19.130087\n",
      "bce: 19.004675, kld: 0.250824\n",
      "Train Epoch: 143 [15360/22533 (68%)]      Loss: 19.747772\n",
      "bce: 19.621349, kld: 0.252844\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 19.671915\n",
      "bce: 19.545835, kld: 0.252160\n",
      "====> Epoch: 143 Average loss: 19.4317, bce: 19.3061, kld: 0.2513\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 18.776949\n",
      "bce: 18.649672, kld: 0.254554\n",
      "Train Epoch: 144 [5120/22533 (23%)]      Loss: 20.012278\n",
      "bce: 19.889059, kld: 0.246439\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 19.377392\n",
      "bce: 19.247940, kld: 0.258905\n",
      "Train Epoch: 144 [15360/22533 (68%)]      Loss: 20.065413\n",
      "bce: 19.943680, kld: 0.243466\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 20.201080\n",
      "bce: 20.073380, kld: 0.255401\n",
      "====> Epoch: 144 Average loss: 19.3884, bce: 19.2627, kld: 0.2515\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 19.381147\n",
      "bce: 19.255253, kld: 0.251790\n",
      "Train Epoch: 145 [5120/22533 (23%)]      Loss: 19.806593\n",
      "bce: 19.680748, kld: 0.251689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 19.635851\n",
      "bce: 19.508495, kld: 0.254710\n",
      "Train Epoch: 145 [15360/22533 (68%)]      Loss: 19.691181\n",
      "bce: 19.556316, kld: 0.269728\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 19.814398\n",
      "bce: 19.690756, kld: 0.247282\n",
      "====> Epoch: 145 Average loss: 19.3271, bce: 19.2000, kld: 0.2542\n",
      "====> Testing Average Loss: 15.764699794468113\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 19.077597\n",
      "bce: 18.950554, kld: 0.254087\n",
      "Train Epoch: 146 [5120/22533 (23%)]      Loss: 19.360794\n",
      "bce: 19.231121, kld: 0.259346\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 19.263437\n",
      "bce: 19.131699, kld: 0.263479\n",
      "Train Epoch: 146 [15360/22533 (68%)]      Loss: 18.988867\n",
      "bce: 18.866804, kld: 0.244126\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 19.042257\n",
      "bce: 18.912338, kld: 0.259836\n",
      "====> Epoch: 146 Average loss: 19.1856, bce: 19.0591, kld: 0.2530\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 19.210281\n",
      "bce: 19.080757, kld: 0.259047\n",
      "Train Epoch: 147 [5120/22533 (23%)]      Loss: 18.900047\n",
      "bce: 18.770813, kld: 0.258470\n",
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 19.231630\n",
      "bce: 19.103710, kld: 0.255840\n",
      "Train Epoch: 147 [15360/22533 (68%)]      Loss: 19.074055\n",
      "bce: 18.944096, kld: 0.259917\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 18.457787\n",
      "bce: 18.329163, kld: 0.257249\n",
      "====> Epoch: 147 Average loss: 19.0645, bce: 18.9383, kld: 0.2524\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 19.196014\n",
      "bce: 19.070160, kld: 0.251709\n",
      "Train Epoch: 148 [5120/22533 (23%)]      Loss: 19.094753\n",
      "bce: 18.967144, kld: 0.255219\n",
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 19.184511\n",
      "bce: 19.056782, kld: 0.255460\n",
      "Train Epoch: 148 [15360/22533 (68%)]      Loss: 18.535561\n",
      "bce: 18.403633, kld: 0.263856\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 18.778688\n",
      "bce: 18.654499, kld: 0.248380\n",
      "====> Epoch: 148 Average loss: 19.0058, bce: 18.8790, kld: 0.2537\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 19.311348\n",
      "bce: 19.178837, kld: 0.265024\n",
      "Train Epoch: 149 [5120/22533 (23%)]      Loss: 18.857540\n",
      "bce: 18.733637, kld: 0.247806\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 18.350979\n",
      "bce: 18.222019, kld: 0.257921\n",
      "Train Epoch: 149 [15360/22533 (68%)]      Loss: 18.957619\n",
      "bce: 18.825649, kld: 0.263939\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 18.733786\n",
      "bce: 18.607826, kld: 0.251920\n",
      "====> Epoch: 149 Average loss: 18.9337, bce: 18.8074, kld: 0.2527\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 19.198435\n",
      "bce: 19.071707, kld: 0.253457\n",
      "Train Epoch: 150 [5120/22533 (23%)]      Loss: 18.534578\n",
      "bce: 18.406549, kld: 0.256058\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 18.918024\n",
      "bce: 18.791567, kld: 0.252913\n",
      "Train Epoch: 150 [15360/22533 (68%)]      Loss: 18.690334\n",
      "bce: 18.567968, kld: 0.244731\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 18.783661\n",
      "bce: 18.660515, kld: 0.246293\n",
      "====> Epoch: 150 Average loss: 18.8379, bce: 18.7114, kld: 0.2531\n",
      "====> Testing Average Loss: 15.628644654506724\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 18.392357\n",
      "bce: 18.270208, kld: 0.244297\n",
      "Train Epoch: 151 [5120/22533 (23%)]      Loss: 18.804625\n",
      "bce: 18.680000, kld: 0.249247\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 17.999355\n",
      "bce: 17.870380, kld: 0.257948\n",
      "Train Epoch: 151 [15360/22533 (68%)]      Loss: 18.907013\n",
      "bce: 18.779428, kld: 0.255168\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 19.174799\n",
      "bce: 19.046547, kld: 0.256503\n",
      "====> Epoch: 151 Average loss: 18.7962, bce: 18.6699, kld: 0.2527\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 19.033672\n",
      "bce: 18.907457, kld: 0.252430\n",
      "Train Epoch: 152 [5120/22533 (23%)]      Loss: 19.213650\n",
      "bce: 19.083961, kld: 0.259377\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 18.153286\n",
      "bce: 18.030647, kld: 0.245279\n",
      "Train Epoch: 152 [15360/22533 (68%)]      Loss: 17.784363\n",
      "bce: 17.651016, kld: 0.266694\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 18.166269\n",
      "bce: 18.039921, kld: 0.252698\n",
      "====> Epoch: 152 Average loss: 18.7435, bce: 18.6162, kld: 0.2545\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 18.333817\n",
      "bce: 18.209280, kld: 0.249073\n",
      "Train Epoch: 153 [5120/22533 (23%)]      Loss: 18.472984\n",
      "bce: 18.345211, kld: 0.255545\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 18.595823\n",
      "bce: 18.467419, kld: 0.256811\n",
      "Train Epoch: 153 [15360/22533 (68%)]      Loss: 18.976397\n",
      "bce: 18.849566, kld: 0.253662\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 18.959063\n",
      "bce: 18.835489, kld: 0.247145\n",
      "====> Epoch: 153 Average loss: 18.5701, bce: 18.4431, kld: 0.2541\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 17.924002\n",
      "bce: 17.798080, kld: 0.251841\n",
      "Train Epoch: 154 [5120/22533 (23%)]      Loss: 18.252310\n",
      "bce: 18.125206, kld: 0.254207\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 18.628527\n",
      "bce: 18.501825, kld: 0.253402\n",
      "Train Epoch: 154 [15360/22533 (68%)]      Loss: 18.601360\n",
      "bce: 18.472019, kld: 0.258680\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 17.562754\n",
      "bce: 17.439499, kld: 0.246509\n",
      "====> Epoch: 154 Average loss: 18.5216, bce: 18.3947, kld: 0.2538\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 18.461372\n",
      "bce: 18.337364, kld: 0.248016\n",
      "Train Epoch: 155 [5120/22533 (23%)]      Loss: 18.023571\n",
      "bce: 17.895718, kld: 0.255705\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 18.805656\n",
      "bce: 18.680269, kld: 0.250775\n",
      "Train Epoch: 155 [15360/22533 (68%)]      Loss: 18.899233\n",
      "bce: 18.765350, kld: 0.267764\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 18.622587\n",
      "bce: 18.497931, kld: 0.249313\n",
      "====> Epoch: 155 Average loss: 18.4148, bce: 18.2881, kld: 0.2534\n",
      "====> Testing Average Loss: 15.653259334226467\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 17.932819\n",
      "bce: 17.809790, kld: 0.246060\n",
      "Train Epoch: 156 [5120/22533 (23%)]      Loss: 18.131529\n",
      "bce: 18.003269, kld: 0.256520\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 17.809526\n",
      "bce: 17.686672, kld: 0.245708\n",
      "Train Epoch: 156 [15360/22533 (68%)]      Loss: 18.310984\n",
      "bce: 18.184975, kld: 0.252019\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 18.200209\n",
      "bce: 18.073168, kld: 0.254081\n",
      "====> Epoch: 156 Average loss: 18.4295, bce: 18.3013, kld: 0.2564\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 18.557253\n",
      "bce: 18.433411, kld: 0.247684\n",
      "Train Epoch: 157 [5120/22533 (23%)]      Loss: 19.124573\n",
      "bce: 18.999195, kld: 0.250756\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 17.366404\n",
      "bce: 17.240814, kld: 0.251177\n",
      "Train Epoch: 157 [15360/22533 (68%)]      Loss: 18.803488\n",
      "bce: 18.677549, kld: 0.251876\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 18.516909\n",
      "bce: 18.387030, kld: 0.259757\n",
      "====> Epoch: 157 Average loss: 18.3926, bce: 18.2646, kld: 0.2560\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 17.780636\n",
      "bce: 17.648968, kld: 0.263336\n",
      "Train Epoch: 158 [5120/22533 (23%)]      Loss: 18.290411\n",
      "bce: 18.162025, kld: 0.256772\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 18.710932\n",
      "bce: 18.581423, kld: 0.259017\n",
      "Train Epoch: 158 [15360/22533 (68%)]      Loss: 18.196573\n",
      "bce: 18.061678, kld: 0.269791\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 18.409365\n",
      "bce: 18.279980, kld: 0.258770\n",
      "====> Epoch: 158 Average loss: 18.3217, bce: 18.1922, kld: 0.2590\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 18.293591\n",
      "bce: 18.160309, kld: 0.266564\n",
      "Train Epoch: 159 [5120/22533 (23%)]      Loss: 18.142633\n",
      "bce: 18.013096, kld: 0.259077\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 18.003098\n",
      "bce: 17.871891, kld: 0.262414\n",
      "Train Epoch: 159 [15360/22533 (68%)]      Loss: 18.198877\n",
      "bce: 18.064426, kld: 0.268902\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 18.879320\n",
      "bce: 18.754894, kld: 0.248851\n",
      "====> Epoch: 159 Average loss: 18.1681, bce: 18.0393, kld: 0.2574\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 18.314388\n",
      "bce: 18.187595, kld: 0.253585\n",
      "Train Epoch: 160 [5120/22533 (23%)]      Loss: 18.125780\n",
      "bce: 17.991680, kld: 0.268201\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 17.989620\n",
      "bce: 17.858795, kld: 0.261650\n",
      "Train Epoch: 160 [15360/22533 (68%)]      Loss: 17.940365\n",
      "bce: 17.813622, kld: 0.253485\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 18.279085\n",
      "bce: 18.156139, kld: 0.245892\n",
      "====> Epoch: 160 Average loss: 18.0441, bce: 17.9153, kld: 0.2575\n",
      "====> Testing Average Loss: 15.0282447722507\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 17.745211\n",
      "bce: 17.624523, kld: 0.241376\n",
      "Train Epoch: 161 [5120/22533 (23%)]      Loss: 18.589708\n",
      "bce: 18.461048, kld: 0.257322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 17.757410\n",
      "bce: 17.627008, kld: 0.260803\n",
      "Train Epoch: 161 [15360/22533 (68%)]      Loss: 18.035812\n",
      "bce: 17.914537, kld: 0.242549\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 18.584467\n",
      "bce: 18.452805, kld: 0.263325\n",
      "====> Epoch: 161 Average loss: 17.9998, bce: 17.8717, kld: 0.2562\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 17.875532\n",
      "bce: 17.750013, kld: 0.251037\n",
      "Train Epoch: 162 [5120/22533 (23%)]      Loss: 18.324137\n",
      "bce: 18.195717, kld: 0.256838\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 17.601097\n",
      "bce: 17.470686, kld: 0.260823\n",
      "Train Epoch: 162 [15360/22533 (68%)]      Loss: 17.646072\n",
      "bce: 17.519360, kld: 0.253424\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 17.468170\n",
      "bce: 17.342678, kld: 0.250982\n",
      "====> Epoch: 162 Average loss: 17.9199, bce: 17.7914, kld: 0.2570\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 17.767750\n",
      "bce: 17.641050, kld: 0.253400\n",
      "Train Epoch: 163 [5120/22533 (23%)]      Loss: 17.680809\n",
      "bce: 17.559620, kld: 0.242377\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 18.230761\n",
      "bce: 18.104954, kld: 0.251612\n",
      "Train Epoch: 163 [15360/22533 (68%)]      Loss: 17.806944\n",
      "bce: 17.674789, kld: 0.264307\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 18.100382\n",
      "bce: 17.971451, kld: 0.257860\n",
      "====> Epoch: 163 Average loss: 17.8601, bce: 17.7313, kld: 0.2575\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 17.592211\n",
      "bce: 17.464478, kld: 0.255468\n",
      "Train Epoch: 164 [5120/22533 (23%)]      Loss: 17.467594\n",
      "bce: 17.334349, kld: 0.266490\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 17.726871\n",
      "bce: 17.592390, kld: 0.268963\n",
      "Train Epoch: 164 [15360/22533 (68%)]      Loss: 18.050493\n",
      "bce: 17.919975, kld: 0.261035\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 18.150217\n",
      "bce: 18.025276, kld: 0.249881\n",
      "====> Epoch: 164 Average loss: 17.8096, bce: 17.6806, kld: 0.2579\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 17.567593\n",
      "bce: 17.442928, kld: 0.249329\n",
      "Train Epoch: 165 [5120/22533 (23%)]      Loss: 17.367395\n",
      "bce: 17.237068, kld: 0.260656\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 17.555559\n",
      "bce: 17.429077, kld: 0.252962\n",
      "Train Epoch: 165 [15360/22533 (68%)]      Loss: 17.458378\n",
      "bce: 17.325891, kld: 0.264973\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 17.325882\n",
      "bce: 17.197983, kld: 0.255800\n",
      "====> Epoch: 165 Average loss: 17.7253, bce: 17.5966, kld: 0.2573\n",
      "====> Testing Average Loss: 15.203959323200971\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 18.261162\n",
      "bce: 18.134514, kld: 0.253298\n",
      "Train Epoch: 166 [5120/22533 (23%)]      Loss: 17.933113\n",
      "bce: 17.803692, kld: 0.258843\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 18.439932\n",
      "bce: 18.308849, kld: 0.262166\n",
      "Train Epoch: 166 [15360/22533 (68%)]      Loss: 17.529346\n",
      "bce: 17.410513, kld: 0.237666\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 17.071682\n",
      "bce: 16.941483, kld: 0.260397\n",
      "====> Epoch: 166 Average loss: 17.6809, bce: 17.5526, kld: 0.2567\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 17.408241\n",
      "bce: 17.278904, kld: 0.258675\n",
      "Train Epoch: 167 [5120/22533 (23%)]      Loss: 17.579771\n",
      "bce: 17.451729, kld: 0.256085\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 17.799316\n",
      "bce: 17.664761, kld: 0.269112\n",
      "Train Epoch: 167 [15360/22533 (68%)]      Loss: 17.185225\n",
      "bce: 17.056976, kld: 0.256498\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 17.581070\n",
      "bce: 17.444107, kld: 0.273924\n",
      "====> Epoch: 167 Average loss: 17.5830, bce: 17.4544, kld: 0.2573\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 16.577042\n",
      "bce: 16.452839, kld: 0.248406\n",
      "Train Epoch: 168 [5120/22533 (23%)]      Loss: 16.819120\n",
      "bce: 16.693077, kld: 0.252088\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 17.814207\n",
      "bce: 17.684973, kld: 0.258468\n",
      "Train Epoch: 168 [15360/22533 (68%)]      Loss: 17.593903\n",
      "bce: 17.464766, kld: 0.258275\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 17.014370\n",
      "bce: 16.880817, kld: 0.267105\n",
      "====> Epoch: 168 Average loss: 17.4811, bce: 17.3522, kld: 0.2578\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 17.702042\n",
      "bce: 17.572107, kld: 0.259870\n",
      "Train Epoch: 169 [5120/22533 (23%)]      Loss: 17.791147\n",
      "bce: 17.661057, kld: 0.260180\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 17.546572\n",
      "bce: 17.419849, kld: 0.253443\n",
      "Train Epoch: 169 [15360/22533 (68%)]      Loss: 17.837639\n",
      "bce: 17.709545, kld: 0.256187\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 16.916742\n",
      "bce: 16.786209, kld: 0.261067\n",
      "====> Epoch: 169 Average loss: 17.4548, bce: 17.3261, kld: 0.2573\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 16.831917\n",
      "bce: 16.707848, kld: 0.248139\n",
      "Train Epoch: 170 [5120/22533 (23%)]      Loss: 17.248798\n",
      "bce: 17.124310, kld: 0.248979\n",
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 17.388229\n",
      "bce: 17.262024, kld: 0.252409\n",
      "Train Epoch: 170 [15360/22533 (68%)]      Loss: 18.106396\n",
      "bce: 17.983892, kld: 0.245006\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 16.760853\n",
      "bce: 16.635815, kld: 0.250078\n",
      "====> Epoch: 170 Average loss: 17.4012, bce: 17.2734, kld: 0.2556\n",
      "====> Testing Average Loss: 14.86513465146951\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 16.993101\n",
      "bce: 16.865080, kld: 0.256041\n",
      "Train Epoch: 171 [5120/22533 (23%)]      Loss: 17.017353\n",
      "bce: 16.892017, kld: 0.250673\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 17.077124\n",
      "bce: 16.944822, kld: 0.264601\n",
      "Train Epoch: 171 [15360/22533 (68%)]      Loss: 17.702410\n",
      "bce: 17.579254, kld: 0.246313\n",
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 17.562275\n",
      "bce: 17.438503, kld: 0.247543\n",
      "====> Epoch: 171 Average loss: 17.3384, bce: 17.2092, kld: 0.2584\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 17.508541\n",
      "bce: 17.383354, kld: 0.250373\n",
      "Train Epoch: 172 [5120/22533 (23%)]      Loss: 17.580988\n",
      "bce: 17.450493, kld: 0.260990\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 16.771891\n",
      "bce: 16.647139, kld: 0.249503\n",
      "Train Epoch: 172 [15360/22533 (68%)]      Loss: 17.887747\n",
      "bce: 17.751156, kld: 0.273182\n",
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 17.508205\n",
      "bce: 17.376410, kld: 0.263591\n",
      "====> Epoch: 172 Average loss: 17.3078, bce: 17.1784, kld: 0.2588\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 16.972788\n",
      "bce: 16.842070, kld: 0.261437\n",
      "Train Epoch: 173 [5120/22533 (23%)]      Loss: 16.441336\n",
      "bce: 16.313993, kld: 0.254686\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 17.958685\n",
      "bce: 17.827663, kld: 0.262043\n",
      "Train Epoch: 173 [15360/22533 (68%)]      Loss: 16.802385\n",
      "bce: 16.674486, kld: 0.255799\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 17.626535\n",
      "bce: 17.502237, kld: 0.248596\n",
      "====> Epoch: 173 Average loss: 17.2188, bce: 17.0906, kld: 0.2562\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 16.702068\n",
      "bce: 16.572422, kld: 0.259292\n",
      "Train Epoch: 174 [5120/22533 (23%)]      Loss: 17.275976\n",
      "bce: 17.148750, kld: 0.254451\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 16.802578\n",
      "bce: 16.669121, kld: 0.266915\n",
      "Train Epoch: 174 [15360/22533 (68%)]      Loss: 17.065395\n",
      "bce: 16.939674, kld: 0.251441\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 17.493011\n",
      "bce: 17.366167, kld: 0.253687\n",
      "====> Epoch: 174 Average loss: 17.1328, bce: 17.0038, kld: 0.2582\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 16.885485\n",
      "bce: 16.748024, kld: 0.274921\n",
      "Train Epoch: 175 [5120/22533 (23%)]      Loss: 16.615795\n",
      "bce: 16.485569, kld: 0.260454\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 17.697222\n",
      "bce: 17.571136, kld: 0.252169\n",
      "Train Epoch: 175 [15360/22533 (68%)]      Loss: 17.763155\n",
      "bce: 17.627842, kld: 0.270626\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 17.637358\n",
      "bce: 17.512135, kld: 0.250447\n",
      "====> Epoch: 175 Average loss: 17.1515, bce: 17.0218, kld: 0.2594\n",
      "====> Testing Average Loss: 14.474814022766608\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 16.756981\n",
      "bce: 16.624781, kld: 0.264400\n",
      "Train Epoch: 176 [5120/22533 (23%)]      Loss: 16.426016\n",
      "bce: 16.293678, kld: 0.264676\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 16.992615\n",
      "bce: 16.864954, kld: 0.255320\n",
      "Train Epoch: 176 [15360/22533 (68%)]      Loss: 16.698597\n",
      "bce: 16.567280, kld: 0.262636\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 16.866905\n",
      "bce: 16.738289, kld: 0.257231\n",
      "====> Epoch: 176 Average loss: 17.0860, bce: 16.9550, kld: 0.2620\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 17.146427\n",
      "bce: 17.015480, kld: 0.261895\n",
      "Train Epoch: 177 [5120/22533 (23%)]      Loss: 16.236958\n",
      "bce: 16.112560, kld: 0.248794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 17.243092\n",
      "bce: 17.110159, kld: 0.265866\n",
      "Train Epoch: 177 [15360/22533 (68%)]      Loss: 16.699245\n",
      "bce: 16.560263, kld: 0.277967\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 16.992161\n",
      "bce: 16.850653, kld: 0.283018\n",
      "====> Epoch: 177 Average loss: 17.0018, bce: 16.8704, kld: 0.2630\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 17.276985\n",
      "bce: 17.145466, kld: 0.263040\n",
      "Train Epoch: 178 [5120/22533 (23%)]      Loss: 17.845430\n",
      "bce: 17.713030, kld: 0.264801\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 16.547779\n",
      "bce: 16.418097, kld: 0.259363\n",
      "Train Epoch: 178 [15360/22533 (68%)]      Loss: 16.516211\n",
      "bce: 16.393063, kld: 0.246296\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 17.081984\n",
      "bce: 16.947968, kld: 0.268032\n",
      "====> Epoch: 178 Average loss: 16.9488, bce: 16.8189, kld: 0.2598\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 17.375841\n",
      "bce: 17.245213, kld: 0.261259\n",
      "Train Epoch: 179 [5120/22533 (23%)]      Loss: 16.836987\n",
      "bce: 16.702635, kld: 0.268703\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 16.106215\n",
      "bce: 15.970199, kld: 0.272031\n",
      "Train Epoch: 179 [15360/22533 (68%)]      Loss: 17.378727\n",
      "bce: 17.254122, kld: 0.249212\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 17.307362\n",
      "bce: 17.180286, kld: 0.254149\n",
      "====> Epoch: 179 Average loss: 16.9099, bce: 16.7792, kld: 0.2613\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 16.836035\n",
      "bce: 16.716492, kld: 0.239085\n",
      "Train Epoch: 180 [5120/22533 (23%)]      Loss: 17.291145\n",
      "bce: 17.156328, kld: 0.269633\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 16.973703\n",
      "bce: 16.848339, kld: 0.250728\n",
      "Train Epoch: 180 [15360/22533 (68%)]      Loss: 16.839058\n",
      "bce: 16.710110, kld: 0.257895\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 16.820122\n",
      "bce: 16.691984, kld: 0.256276\n",
      "====> Epoch: 180 Average loss: 16.8238, bce: 16.6937, kld: 0.2602\n",
      "====> Testing Average Loss: 14.351133571803022\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 16.681765\n",
      "bce: 16.552053, kld: 0.259423\n",
      "Train Epoch: 181 [5120/22533 (23%)]      Loss: 16.452833\n",
      "bce: 16.325239, kld: 0.255187\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 16.400110\n",
      "bce: 16.266472, kld: 0.267277\n",
      "Train Epoch: 181 [15360/22533 (68%)]      Loss: 16.699762\n",
      "bce: 16.569763, kld: 0.259997\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 16.430603\n",
      "bce: 16.300009, kld: 0.261190\n",
      "====> Epoch: 181 Average loss: 16.7513, bce: 16.6206, kld: 0.2614\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 16.315676\n",
      "bce: 16.188492, kld: 0.254368\n",
      "Train Epoch: 182 [5120/22533 (23%)]      Loss: 17.215349\n",
      "bce: 17.090199, kld: 0.250303\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 16.159494\n",
      "bce: 16.019339, kld: 0.280312\n",
      "Train Epoch: 182 [15360/22533 (68%)]      Loss: 16.658024\n",
      "bce: 16.527618, kld: 0.260811\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 17.041695\n",
      "bce: 16.910305, kld: 0.262781\n",
      "====> Epoch: 182 Average loss: 16.7139, bce: 16.5833, kld: 0.2612\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 16.409517\n",
      "bce: 16.278337, kld: 0.262360\n",
      "Train Epoch: 183 [5120/22533 (23%)]      Loss: 16.986843\n",
      "bce: 16.858929, kld: 0.255829\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 16.694674\n",
      "bce: 16.563467, kld: 0.262414\n",
      "Train Epoch: 183 [15360/22533 (68%)]      Loss: 16.914188\n",
      "bce: 16.786818, kld: 0.254743\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 17.172497\n",
      "bce: 17.045536, kld: 0.253923\n",
      "====> Epoch: 183 Average loss: 16.6451, bce: 16.5145, kld: 0.2612\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 16.416071\n",
      "bce: 16.278885, kld: 0.274374\n",
      "Train Epoch: 184 [5120/22533 (23%)]      Loss: 16.842302\n",
      "bce: 16.714609, kld: 0.255385\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 16.508274\n",
      "bce: 16.378685, kld: 0.259177\n",
      "Train Epoch: 184 [15360/22533 (68%)]      Loss: 16.190680\n",
      "bce: 16.063503, kld: 0.254354\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 16.302402\n",
      "bce: 16.166571, kld: 0.271664\n",
      "====> Epoch: 184 Average loss: 16.5845, bce: 16.4546, kld: 0.2598\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 17.083660\n",
      "bce: 16.959339, kld: 0.248643\n",
      "Train Epoch: 185 [5120/22533 (23%)]      Loss: 16.618956\n",
      "bce: 16.485888, kld: 0.266136\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 16.759508\n",
      "bce: 16.629456, kld: 0.260106\n",
      "Train Epoch: 185 [15360/22533 (68%)]      Loss: 16.835506\n",
      "bce: 16.695206, kld: 0.280600\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 16.842726\n",
      "bce: 16.715816, kld: 0.253818\n",
      "====> Epoch: 185 Average loss: 16.5462, bce: 16.4154, kld: 0.2617\n",
      "====> Testing Average Loss: 14.186312938939555\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 16.594124\n",
      "bce: 16.462349, kld: 0.263550\n",
      "Train Epoch: 186 [5120/22533 (23%)]      Loss: 16.482164\n",
      "bce: 16.346493, kld: 0.271343\n",
      "Train Epoch: 186 [10240/22533 (45%)]      Loss: 16.287607\n",
      "bce: 16.153679, kld: 0.267856\n",
      "Train Epoch: 186 [15360/22533 (68%)]      Loss: 15.777122\n",
      "bce: 15.645477, kld: 0.263288\n",
      "Train Epoch: 186 [20480/22533 (91%)]      Loss: 16.516581\n",
      "bce: 16.387224, kld: 0.258711\n",
      "====> Epoch: 186 Average loss: 16.4887, bce: 16.3581, kld: 0.2612\n",
      "Train Epoch: 187 [   0/22533 ( 0%)]      Loss: 16.901390\n",
      "bce: 16.774975, kld: 0.252829\n",
      "Train Epoch: 187 [5120/22533 (23%)]      Loss: 16.896704\n",
      "bce: 16.767094, kld: 0.259221\n",
      "Train Epoch: 187 [10240/22533 (45%)]      Loss: 17.029333\n",
      "bce: 16.898163, kld: 0.262341\n",
      "Train Epoch: 187 [15360/22533 (68%)]      Loss: 16.301439\n",
      "bce: 16.170551, kld: 0.261776\n",
      "Train Epoch: 187 [20480/22533 (91%)]      Loss: 16.187845\n",
      "bce: 16.054029, kld: 0.267633\n",
      "====> Epoch: 187 Average loss: 16.4007, bce: 16.2700, kld: 0.2613\n",
      "Train Epoch: 188 [   0/22533 ( 0%)]      Loss: 16.162468\n",
      "bce: 16.028959, kld: 0.267018\n",
      "Train Epoch: 188 [5120/22533 (23%)]      Loss: 16.093594\n",
      "bce: 15.963462, kld: 0.260264\n",
      "Train Epoch: 188 [10240/22533 (45%)]      Loss: 17.034842\n",
      "bce: 16.908192, kld: 0.253301\n",
      "Train Epoch: 188 [15360/22533 (68%)]      Loss: 16.347044\n",
      "bce: 16.219656, kld: 0.254777\n",
      "Train Epoch: 188 [20480/22533 (91%)]      Loss: 16.911535\n",
      "bce: 16.781910, kld: 0.259249\n",
      "====> Epoch: 188 Average loss: 16.3619, bce: 16.2323, kld: 0.2591\n",
      "Train Epoch: 189 [   0/22533 ( 0%)]      Loss: 16.163221\n",
      "bce: 16.028658, kld: 0.269129\n",
      "Train Epoch: 189 [5120/22533 (23%)]      Loss: 16.783936\n",
      "bce: 16.656513, kld: 0.254846\n",
      "Train Epoch: 189 [10240/22533 (45%)]      Loss: 15.767321\n",
      "bce: 15.634535, kld: 0.265572\n",
      "Train Epoch: 189 [15360/22533 (68%)]      Loss: 16.053686\n",
      "bce: 15.923285, kld: 0.260802\n",
      "Train Epoch: 189 [20480/22533 (91%)]      Loss: 16.529875\n",
      "bce: 16.400854, kld: 0.258041\n",
      "====> Epoch: 189 Average loss: 16.3406, bce: 16.2088, kld: 0.2636\n",
      "Train Epoch: 190 [   0/22533 ( 0%)]      Loss: 17.054008\n",
      "bce: 16.921898, kld: 0.264223\n",
      "Train Epoch: 190 [5120/22533 (23%)]      Loss: 16.897253\n",
      "bce: 16.765713, kld: 0.263079\n",
      "Train Epoch: 190 [10240/22533 (45%)]      Loss: 16.632196\n",
      "bce: 16.503048, kld: 0.258298\n",
      "Train Epoch: 190 [15360/22533 (68%)]      Loss: 15.396984\n",
      "bce: 15.262575, kld: 0.268818\n",
      "Train Epoch: 190 [20480/22533 (91%)]      Loss: 16.579311\n",
      "bce: 16.457283, kld: 0.244058\n",
      "====> Epoch: 190 Average loss: 16.3091, bce: 16.1772, kld: 0.2637\n",
      "====> Testing Average Loss: 14.40987606198409\n",
      "Train Epoch: 191 [   0/22533 ( 0%)]      Loss: 15.653718\n",
      "bce: 15.522696, kld: 0.262043\n",
      "Train Epoch: 191 [5120/22533 (23%)]      Loss: 15.631655\n",
      "bce: 15.500048, kld: 0.263214\n",
      "Train Epoch: 191 [10240/22533 (45%)]      Loss: 16.418179\n",
      "bce: 16.285969, kld: 0.264419\n",
      "Train Epoch: 191 [15360/22533 (68%)]      Loss: 16.007643\n",
      "bce: 15.882980, kld: 0.249326\n",
      "Train Epoch: 191 [20480/22533 (91%)]      Loss: 16.501350\n",
      "bce: 16.366219, kld: 0.270265\n",
      "====> Epoch: 191 Average loss: 16.2243, bce: 16.0934, kld: 0.2619\n",
      "Train Epoch: 192 [   0/22533 ( 0%)]      Loss: 17.170984\n",
      "bce: 17.043734, kld: 0.254502\n",
      "Train Epoch: 192 [5120/22533 (23%)]      Loss: 16.030348\n",
      "bce: 15.896708, kld: 0.267279\n",
      "Train Epoch: 192 [10240/22533 (45%)]      Loss: 15.705477\n",
      "bce: 15.575670, kld: 0.259613\n",
      "Train Epoch: 192 [15360/22533 (68%)]      Loss: 16.198923\n",
      "bce: 16.072601, kld: 0.252645\n",
      "Train Epoch: 192 [20480/22533 (91%)]      Loss: 15.542726\n",
      "bce: 15.409290, kld: 0.266870\n",
      "====> Epoch: 192 Average loss: 16.2094, bce: 16.0787, kld: 0.2614\n",
      "Train Epoch: 193 [   0/22533 ( 0%)]      Loss: 15.445083\n",
      "bce: 15.315213, kld: 0.259738\n",
      "Train Epoch: 193 [5120/22533 (23%)]      Loss: 16.309219\n",
      "bce: 16.177456, kld: 0.263527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 193 [10240/22533 (45%)]      Loss: 16.350098\n",
      "bce: 16.220615, kld: 0.258964\n",
      "Train Epoch: 193 [15360/22533 (68%)]      Loss: 16.113396\n",
      "bce: 15.979789, kld: 0.267215\n",
      "Train Epoch: 193 [20480/22533 (91%)]      Loss: 16.562954\n",
      "bce: 16.432550, kld: 0.260805\n",
      "====> Epoch: 193 Average loss: 16.1725, bce: 16.0420, kld: 0.2611\n",
      "Train Epoch: 194 [   0/22533 ( 0%)]      Loss: 16.107914\n",
      "bce: 15.977500, kld: 0.260829\n",
      "Train Epoch: 194 [5120/22533 (23%)]      Loss: 16.135939\n",
      "bce: 16.002991, kld: 0.265894\n",
      "Train Epoch: 194 [10240/22533 (45%)]      Loss: 16.072525\n",
      "bce: 15.940424, kld: 0.264202\n",
      "Train Epoch: 194 [15360/22533 (68%)]      Loss: 16.609776\n",
      "bce: 16.476410, kld: 0.266731\n",
      "Train Epoch: 194 [20480/22533 (91%)]      Loss: 15.965389\n",
      "bce: 15.834755, kld: 0.261269\n",
      "====> Epoch: 194 Average loss: 16.1217, bce: 15.9893, kld: 0.2646\n",
      "Train Epoch: 195 [   0/22533 ( 0%)]      Loss: 16.118505\n",
      "bce: 15.985634, kld: 0.265745\n",
      "Train Epoch: 195 [5120/22533 (23%)]      Loss: 15.517687\n",
      "bce: 15.379470, kld: 0.276433\n",
      "Train Epoch: 195 [10240/22533 (45%)]      Loss: 16.271973\n",
      "bce: 16.139297, kld: 0.265351\n",
      "Train Epoch: 195 [15360/22533 (68%)]      Loss: 16.382868\n",
      "bce: 16.253124, kld: 0.259487\n",
      "Train Epoch: 195 [20480/22533 (91%)]      Loss: 16.357342\n",
      "bce: 16.220448, kld: 0.273787\n",
      "====> Epoch: 195 Average loss: 16.0817, bce: 15.9497, kld: 0.2641\n",
      "====> Testing Average Loss: 13.543402748884969\n",
      "Train Epoch: 196 [   0/22533 ( 0%)]      Loss: 16.093578\n",
      "bce: 15.963674, kld: 0.259809\n",
      "Train Epoch: 196 [5120/22533 (23%)]      Loss: 16.189960\n",
      "bce: 16.063488, kld: 0.252946\n",
      "Train Epoch: 196 [10240/22533 (45%)]      Loss: 15.984986\n",
      "bce: 15.859318, kld: 0.251337\n",
      "Train Epoch: 196 [15360/22533 (68%)]      Loss: 16.341331\n",
      "bce: 16.207764, kld: 0.267136\n",
      "Train Epoch: 196 [20480/22533 (91%)]      Loss: 16.394121\n",
      "bce: 16.258541, kld: 0.271162\n",
      "====> Epoch: 196 Average loss: 16.0202, bce: 15.8881, kld: 0.2642\n",
      "Train Epoch: 197 [   0/22533 ( 0%)]      Loss: 16.096561\n",
      "bce: 15.967912, kld: 0.257300\n",
      "Train Epoch: 197 [5120/22533 (23%)]      Loss: 15.585005\n",
      "bce: 15.454480, kld: 0.261050\n",
      "Train Epoch: 197 [10240/22533 (45%)]      Loss: 16.441473\n",
      "bce: 16.306850, kld: 0.269245\n",
      "Train Epoch: 197 [15360/22533 (68%)]      Loss: 16.163635\n",
      "bce: 16.034048, kld: 0.259176\n",
      "Train Epoch: 197 [20480/22533 (91%)]      Loss: 15.895049\n",
      "bce: 15.762779, kld: 0.264539\n",
      "====> Epoch: 197 Average loss: 16.0550, bce: 15.9216, kld: 0.2668\n",
      "Train Epoch: 198 [   0/22533 ( 0%)]      Loss: 15.613119\n",
      "bce: 15.482567, kld: 0.261106\n",
      "Train Epoch: 198 [5120/22533 (23%)]      Loss: 15.696723\n",
      "bce: 15.563342, kld: 0.266762\n",
      "Train Epoch: 198 [10240/22533 (45%)]      Loss: 15.800904\n",
      "bce: 15.667933, kld: 0.265942\n",
      "Train Epoch: 198 [15360/22533 (68%)]      Loss: 16.186726\n",
      "bce: 16.049856, kld: 0.273740\n",
      "Train Epoch: 198 [20480/22533 (91%)]      Loss: 15.883468\n",
      "bce: 15.754335, kld: 0.258265\n",
      "====> Epoch: 198 Average loss: 16.0220, bce: 15.8888, kld: 0.2663\n",
      "Train Epoch: 199 [   0/22533 ( 0%)]      Loss: 16.062746\n",
      "bce: 15.932882, kld: 0.259726\n",
      "Train Epoch: 199 [5120/22533 (23%)]      Loss: 16.558531\n",
      "bce: 16.428276, kld: 0.260511\n",
      "Train Epoch: 199 [10240/22533 (45%)]      Loss: 16.570635\n",
      "bce: 16.437092, kld: 0.267086\n",
      "Train Epoch: 199 [15360/22533 (68%)]      Loss: 15.833533\n",
      "bce: 15.702255, kld: 0.262556\n",
      "Train Epoch: 199 [20480/22533 (91%)]      Loss: 15.073780\n",
      "bce: 14.941927, kld: 0.263707\n",
      "====> Epoch: 199 Average loss: 16.0047, bce: 15.8714, kld: 0.2666\n",
      "Train Epoch: 200 [   0/22533 ( 0%)]      Loss: 16.144444\n",
      "bce: 16.013027, kld: 0.262832\n",
      "Train Epoch: 200 [5120/22533 (23%)]      Loss: 15.579515\n",
      "bce: 15.449009, kld: 0.261012\n",
      "Train Epoch: 200 [10240/22533 (45%)]      Loss: 15.696513\n",
      "bce: 15.562378, kld: 0.268270\n",
      "Train Epoch: 200 [15360/22533 (68%)]      Loss: 16.283272\n",
      "bce: 16.153419, kld: 0.259706\n",
      "Train Epoch: 200 [20480/22533 (91%)]      Loss: 15.446359\n",
      "bce: 15.312373, kld: 0.267972\n",
      "====> Epoch: 200 Average loss: 15.8739, bce: 15.7411, kld: 0.2657\n",
      "====> Testing Average Loss: 13.756393747503662\n",
      "Train Epoch: 201 [   0/22533 ( 0%)]      Loss: 15.559456\n",
      "bce: 15.424057, kld: 0.270798\n",
      "Train Epoch: 201 [5120/22533 (23%)]      Loss: 15.796140\n",
      "bce: 15.656620, kld: 0.279040\n",
      "Train Epoch: 201 [10240/22533 (45%)]      Loss: 15.351017\n",
      "bce: 15.223064, kld: 0.255904\n",
      "Train Epoch: 201 [15360/22533 (68%)]      Loss: 16.106619\n",
      "bce: 15.977074, kld: 0.259089\n",
      "Train Epoch: 201 [20480/22533 (91%)]      Loss: 16.367937\n",
      "bce: 16.235012, kld: 0.265849\n",
      "====> Epoch: 201 Average loss: 15.7637, bce: 15.6307, kld: 0.2661\n",
      "Train Epoch: 202 [   0/22533 ( 0%)]      Loss: 15.584617\n",
      "bce: 15.451643, kld: 0.265948\n",
      "Train Epoch: 202 [5120/22533 (23%)]      Loss: 15.207461\n",
      "bce: 15.071754, kld: 0.271413\n",
      "Train Epoch: 202 [10240/22533 (45%)]      Loss: 15.139796\n",
      "bce: 15.007421, kld: 0.264749\n",
      "Train Epoch: 202 [15360/22533 (68%)]      Loss: 16.126524\n",
      "bce: 15.991810, kld: 0.269426\n",
      "Train Epoch: 202 [20480/22533 (91%)]      Loss: 16.293665\n",
      "bce: 16.166714, kld: 0.253902\n",
      "====> Epoch: 202 Average loss: 15.7327, bce: 15.6009, kld: 0.2637\n",
      "Train Epoch: 203 [   0/22533 ( 0%)]      Loss: 15.216032\n",
      "bce: 15.086736, kld: 0.258592\n",
      "Train Epoch: 203 [5120/22533 (23%)]      Loss: 14.988178\n",
      "bce: 14.854538, kld: 0.267281\n",
      "Train Epoch: 203 [10240/22533 (45%)]      Loss: 16.066376\n",
      "bce: 15.940351, kld: 0.252049\n",
      "Train Epoch: 203 [15360/22533 (68%)]      Loss: 15.683673\n",
      "bce: 15.549198, kld: 0.268950\n",
      "Train Epoch: 203 [20480/22533 (91%)]      Loss: 16.067997\n",
      "bce: 15.936057, kld: 0.263878\n",
      "====> Epoch: 203 Average loss: 15.7032, bce: 15.5706, kld: 0.2651\n",
      "Train Epoch: 204 [   0/22533 ( 0%)]      Loss: 15.457831\n",
      "bce: 15.323340, kld: 0.268983\n",
      "Train Epoch: 204 [5120/22533 (23%)]      Loss: 15.836329\n",
      "bce: 15.705339, kld: 0.261978\n",
      "Train Epoch: 204 [10240/22533 (45%)]      Loss: 15.834199\n",
      "bce: 15.706218, kld: 0.255963\n",
      "Train Epoch: 204 [15360/22533 (68%)]      Loss: 15.542360\n",
      "bce: 15.419659, kld: 0.245402\n",
      "Train Epoch: 204 [20480/22533 (91%)]      Loss: 15.439233\n",
      "bce: 15.306946, kld: 0.264574\n",
      "====> Epoch: 204 Average loss: 15.6283, bce: 15.4962, kld: 0.2643\n",
      "Train Epoch: 205 [   0/22533 ( 0%)]      Loss: 15.238804\n",
      "bce: 15.105864, kld: 0.265881\n",
      "Train Epoch: 205 [5120/22533 (23%)]      Loss: 14.861836\n",
      "bce: 14.738987, kld: 0.245698\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=0.5,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
