{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingSketchRnn import TrainingSketchRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "run on GPU\n",
      "Train Epoch: 0 [   0/22533 ( 0%)]      Loss: 11849.190430\n",
      "bce: 106.824974, kld: 46.969460\n",
      "Train Epoch: 0 [10240/22533 (45%)]      Loss: 7803.474609\n",
      "bce: 105.315460, kld: 30.792637\n",
      "Train Epoch: 0 [20480/22533 (91%)]      Loss: 6912.867676\n",
      "bce: 103.602844, kld: 27.237059\n",
      "====> Epoch: 0 Average loss: 8347.7955, bce: 105.2443, kld: 32.9702\n",
      "====> Testing Average Loss: 84.52963986153641\n",
      "Train Epoch: 1 [   0/22533 ( 0%)]      Loss: 6782.563477\n",
      "bce: 103.126144, kld: 26.717751\n",
      "Train Epoch: 1 [10240/22533 (45%)]      Loss: 6377.309570\n",
      "bce: 102.262054, kld: 25.100189\n",
      "Train Epoch: 1 [20480/22533 (91%)]      Loss: 6145.286621\n",
      "bce: 101.166138, kld: 24.176483\n",
      "====> Epoch: 1 Average loss: 6412.7892, bce: 102.1454, kld: 25.2426\n",
      "Train Epoch: 2 [   0/22533 ( 0%)]      Loss: 6101.145996\n",
      "bce: 100.920944, kld: 24.000900\n",
      "Train Epoch: 2 [10240/22533 (45%)]      Loss: 5904.749023\n",
      "bce: 99.646561, kld: 23.220409\n",
      "Train Epoch: 2 [20480/22533 (91%)]      Loss: 5724.397461\n",
      "bce: 98.623131, kld: 22.503098\n",
      "====> Epoch: 2 Average loss: 5904.7012, bce: 99.8012, kld: 23.2196\n",
      "Train Epoch: 3 [   0/22533 ( 0%)]      Loss: 5685.805664\n",
      "bce: 98.337364, kld: 22.349873\n",
      "Train Epoch: 3 [10240/22533 (45%)]      Loss: 5510.575195\n",
      "bce: 97.486832, kld: 21.652353\n",
      "Train Epoch: 3 [20480/22533 (91%)]      Loss: 5337.938477\n",
      "bce: 96.600418, kld: 20.965351\n",
      "====> Epoch: 3 Average loss: 5513.1731, bce: 97.4224, kld: 21.6630\n",
      "Train Epoch: 4 [   0/22533 ( 0%)]      Loss: 5298.886230\n",
      "bce: 96.511101, kld: 20.809500\n",
      "Train Epoch: 4 [10240/22533 (45%)]      Loss: 5118.089844\n",
      "bce: 95.479698, kld: 20.090441\n",
      "Train Epoch: 4 [20480/22533 (91%)]      Loss: 4917.831055\n",
      "bce: 94.907394, kld: 19.291695\n",
      "====> Epoch: 4 Average loss: 5109.5743, bce: 95.6517, kld: 20.0557\n",
      "Train Epoch: 5 [   0/22533 ( 0%)]      Loss: 4875.829590\n",
      "bce: 95.018776, kld: 19.123243\n",
      "Train Epoch: 5 [10240/22533 (45%)]      Loss: 4670.184570\n",
      "bce: 94.586105, kld: 18.302395\n",
      "Train Epoch: 5 [20480/22533 (91%)]      Loss: 4438.005371\n",
      "bce: 93.978119, kld: 17.376110\n",
      "====> Epoch: 5 Average loss: 4661.8513, bce: 94.3030, kld: 18.2702\n",
      "====> Testing Average Loss: 76.02058231260817\n",
      "Train Epoch: 6 [   0/22533 ( 0%)]      Loss: 4390.506836\n",
      "bce: 93.537918, kld: 17.187876\n",
      "Train Epoch: 6 [10240/22533 (45%)]      Loss: 4160.729004\n",
      "bce: 93.123795, kld: 16.270420\n",
      "Train Epoch: 6 [20480/22533 (91%)]      Loss: 3921.470703\n",
      "bce: 92.525406, kld: 15.315782\n",
      "====> Epoch: 6 Average loss: 4158.4726, bce: 93.0363, kld: 16.2617\n",
      "Train Epoch: 7 [   0/22533 ( 0%)]      Loss: 3869.701904\n",
      "bce: 92.281380, kld: 15.109682\n",
      "Train Epoch: 7 [10240/22533 (45%)]      Loss: 3625.785645\n",
      "bce: 91.629761, kld: 14.136624\n",
      "Train Epoch: 7 [20480/22533 (91%)]      Loss: 3377.964844\n",
      "bce: 90.990135, kld: 13.147899\n",
      "====> Epoch: 7 Average loss: 3622.6733, bce: 91.6499, kld: 14.1241\n",
      "Train Epoch: 8 [   0/22533 ( 0%)]      Loss: 3328.446777\n",
      "bce: 90.582581, kld: 12.951457\n",
      "Train Epoch: 8 [10240/22533 (45%)]      Loss: 3091.107910\n",
      "bce: 90.410416, kld: 12.002790\n",
      "Train Epoch: 8 [20480/22533 (91%)]      Loss: 2855.990479\n",
      "bce: 89.325829, kld: 11.066658\n",
      "====> Epoch: 8 Average loss: 3089.3799, bce: 89.9999, kld: 11.9975\n",
      "Train Epoch: 9 [   0/22533 ( 0%)]      Loss: 2809.993652\n",
      "bce: 88.971382, kld: 10.884089\n",
      "Train Epoch: 9 [10240/22533 (45%)]      Loss: 2591.002441\n",
      "bce: 87.946579, kld: 10.012223\n",
      "Train Epoch: 9 [20480/22533 (91%)]      Loss: 2385.025391\n",
      "bce: 87.291862, kld: 9.190934\n",
      "====> Epoch: 9 Average loss: 2592.9648, bce: 88.0592, kld: 10.0196\n",
      "Train Epoch: 10 [   0/22533 ( 0%)]      Loss: 2346.754395\n",
      "bce: 87.119415, kld: 9.038540\n",
      "Train Epoch: 10 [10240/22533 (45%)]      Loss: 2156.254883\n",
      "bce: 86.213501, kld: 8.280166\n",
      "Train Epoch: 10 [20480/22533 (91%)]      Loss: 1977.574829\n",
      "bce: 85.126846, kld: 7.569792\n",
      "====> Epoch: 10 Average loss: 2156.7886, bce: 86.0523, kld: 8.2829\n",
      "====> Testing Average Loss: 66.9825547530289\n",
      "Train Epoch: 11 [   0/22533 ( 0%)]      Loss: 1945.608154\n",
      "bce: 84.858238, kld: 7.442999\n",
      "Train Epoch: 11 [10240/22533 (45%)]      Loss: 1787.427490\n",
      "bce: 83.957359, kld: 6.813880\n",
      "Train Epoch: 11 [20480/22533 (91%)]      Loss: 1643.797485\n",
      "bce: 83.334747, kld: 6.241851\n",
      "====> Epoch: 11 Average loss: 1790.1097, bce: 84.1118, kld: 6.8240\n",
      "Train Epoch: 12 [   0/22533 ( 0%)]      Loss: 1617.643921\n",
      "bce: 83.030907, kld: 6.138452\n",
      "Train Epoch: 12 [10240/22533 (45%)]      Loss: 1487.772705\n",
      "bce: 82.518524, kld: 5.621017\n",
      "Train Epoch: 12 [20480/22533 (91%)]      Loss: 1372.887207\n",
      "bce: 81.375214, kld: 5.166048\n",
      "====> Epoch: 12 Average loss: 1491.2266, bce: 82.4509, kld: 5.6351\n",
      "Train Epoch: 13 [   0/22533 ( 0%)]      Loss: 1350.766357\n",
      "bce: 81.640381, kld: 5.076504\n",
      "Train Epoch: 13 [10240/22533 (45%)]      Loss: 1250.298462\n",
      "bce: 81.274666, kld: 4.676095\n",
      "Train Epoch: 13 [20480/22533 (91%)]      Loss: 1157.780396\n",
      "bce: 80.569260, kld: 4.308845\n",
      "====> Epoch: 13 Average loss: 1251.6155, bce: 81.0710, kld: 4.6822\n",
      "Train Epoch: 14 [   0/22533 ( 0%)]      Loss: 1141.361816\n",
      "bce: 80.377090, kld: 4.243939\n",
      "Train Epoch: 14 [10240/22533 (45%)]      Loss: 1059.475830\n",
      "bce: 80.119850, kld: 3.917424\n",
      "Train Epoch: 14 [20480/22533 (91%)]      Loss: 986.359131\n",
      "bce: 79.378128, kld: 3.627924\n",
      "====> Epoch: 14 Average loss: 1060.8395, bce: 79.8748, kld: 3.9239\n",
      "Train Epoch: 15 [   0/22533 ( 0%)]      Loss: 972.976807\n",
      "bce: 79.445312, kld: 3.574126\n",
      "Train Epoch: 15 [10240/22533 (45%)]      Loss: 907.087769\n",
      "bce: 78.984665, kld: 3.312412\n",
      "Train Epoch: 15 [20480/22533 (91%)]      Loss: 849.401794\n",
      "bce: 78.420776, kld: 3.083924\n",
      "====> Epoch: 15 Average loss: 908.7656, bce: 78.8277, kld: 3.3198\n",
      "====> Testing Average Loss: 59.4592202270004\n",
      "Train Epoch: 16 [   0/22533 ( 0%)]      Loss: 837.987549\n",
      "bce: 78.444748, kld: 3.038171\n",
      "Train Epoch: 16 [10240/22533 (45%)]      Loss: 786.523376\n",
      "bce: 77.590675, kld: 2.835731\n",
      "Train Epoch: 16 [20480/22533 (91%)]      Loss: 738.898987\n",
      "bce: 77.721352, kld: 2.644711\n",
      "====> Epoch: 16 Average loss: 786.9298, bce: 77.8930, kld: 2.8361\n",
      "Train Epoch: 17 [   0/22533 ( 0%)]      Loss: 729.998718\n",
      "bce: 77.454483, kld: 2.610177\n",
      "Train Epoch: 17 [10240/22533 (45%)]      Loss: 687.699585\n",
      "bce: 77.057999, kld: 2.442566\n",
      "Train Epoch: 17 [20480/22533 (91%)]      Loss: 649.220459\n",
      "bce: 76.430923, kld: 2.291158\n",
      "====> Epoch: 17 Average loss: 688.5147, bce: 77.0358, kld: 2.4459\n",
      "Train Epoch: 18 [   0/22533 ( 0%)]      Loss: 642.724060\n",
      "bce: 76.766434, kld: 2.263831\n",
      "Train Epoch: 18 [10240/22533 (45%)]      Loss: 608.676331\n",
      "bce: 76.632141, kld: 2.128177\n",
      "Train Epoch: 18 [20480/22533 (91%)]      Loss: 576.282593\n",
      "bce: 75.941345, kld: 2.001365\n",
      "====> Epoch: 18 Average loss: 608.2717, bce: 76.2501, kld: 2.1281\n",
      "Train Epoch: 19 [   0/22533 ( 0%)]      Loss: 570.898499\n",
      "bce: 75.842148, kld: 1.980225\n",
      "Train Epoch: 19 [10240/22533 (45%)]      Loss: 542.224426\n",
      "bce: 75.808121, kld: 1.865665\n",
      "Train Epoch: 19 [20480/22533 (91%)]      Loss: 515.200928\n",
      "bce: 74.918732, kld: 1.761129\n",
      "====> Epoch: 19 Average loss: 542.2018, bce: 75.5067, kld: 1.8668\n",
      "Train Epoch: 20 [   0/22533 ( 0%)]      Loss: 510.069519\n",
      "bce: 74.953354, kld: 1.740465\n",
      "Train Epoch: 20 [10240/22533 (45%)]      Loss: 487.302032\n",
      "bce: 74.969971, kld: 1.649328\n",
      "Train Epoch: 20 [20480/22533 (91%)]      Loss: 465.024475\n",
      "bce: 74.358818, kld: 1.562663\n",
      "====> Epoch: 20 Average loss: 487.2530, bce: 74.7939, kld: 1.6498\n",
      "====> Testing Average Loss: 55.49152076953801\n",
      "Train Epoch: 21 [   0/22533 ( 0%)]      Loss: 460.225098\n",
      "bce: 74.067368, kld: 1.544631\n",
      "Train Epoch: 21 [10240/22533 (45%)]      Loss: 441.022766\n",
      "bce: 74.162674, kld: 1.467440\n",
      "Train Epoch: 21 [20480/22533 (91%)]      Loss: 422.927429\n",
      "bce: 74.099930, kld: 1.395310\n",
      "====> Epoch: 21 Average loss: 441.1108, bce: 74.1075, kld: 1.4680\n",
      "Train Epoch: 22 [   0/22533 ( 0%)]      Loss: 419.296570\n",
      "bce: 74.058334, kld: 1.380953\n",
      "Train Epoch: 22 [10240/22533 (45%)]      Loss: 401.864960\n",
      "bce: 73.549255, kld: 1.313263\n",
      "Train Epoch: 22 [20480/22533 (91%)]      Loss: 386.355743\n",
      "bce: 73.164909, kld: 1.252763\n",
      "====> Epoch: 22 Average loss: 402.0148, bce: 73.4392, kld: 1.3143\n",
      "Train Epoch: 23 [   0/22533 ( 0%)]      Loss: 382.930298\n",
      "bce: 72.883789, kld: 1.240186\n",
      "Train Epoch: 23 [10240/22533 (45%)]      Loss: 368.728485\n",
      "bce: 72.836823, kld: 1.183567\n",
      "Train Epoch: 23 [20480/22533 (91%)]      Loss: 354.599365\n",
      "bce: 72.255875, kld: 1.129374\n",
      "====> Epoch: 23 Average loss: 368.6297, bce: 72.7948, kld: 1.1833\n",
      "Train Epoch: 24 [   0/22533 ( 0%)]      Loss: 352.571228\n",
      "bce: 72.880692, kld: 1.118762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10240/22533 (45%)]      Loss: 340.020325\n",
      "bce: 72.119873, kld: 1.071602\n",
      "Train Epoch: 24 [20480/22533 (91%)]      Loss: 327.774597\n",
      "bce: 71.481155, kld: 1.025174\n",
      "====> Epoch: 24 Average loss: 339.8806, bce: 72.1562, kld: 1.0709\n",
      "Train Epoch: 25 [   0/22533 ( 0%)]      Loss: 325.601837\n",
      "bce: 71.818726, kld: 1.015132\n",
      "Train Epoch: 25 [10240/22533 (45%)]      Loss: 315.177612\n",
      "bce: 71.484505, kld: 0.974772\n",
      "Train Epoch: 25 [20480/22533 (91%)]      Loss: 305.235321\n",
      "bce: 71.752625, kld: 0.933931\n",
      "====> Epoch: 25 Average loss: 314.9692, bce: 71.5421, kld: 0.9737\n",
      "====> Testing Average Loss: 52.407378553122086\n",
      "Train Epoch: 26 [   0/22533 ( 0%)]      Loss: 302.207550\n",
      "bce: 70.819138, kld: 0.925554\n",
      "Train Epoch: 26 [10240/22533 (45%)]      Loss: 293.275848\n",
      "bce: 71.026070, kld: 0.888999\n",
      "Train Epoch: 26 [20480/22533 (91%)]      Loss: 284.216705\n",
      "bce: 70.721230, kld: 0.853982\n",
      "====> Epoch: 26 Average loss: 293.2072, bce: 70.9320, kld: 0.8891\n",
      "Train Epoch: 27 [   0/22533 ( 0%)]      Loss: 282.967041\n",
      "bce: 70.930359, kld: 0.848147\n",
      "Train Epoch: 27 [10240/22533 (45%)]      Loss: 273.831543\n",
      "bce: 69.958664, kld: 0.815491\n",
      "Train Epoch: 27 [20480/22533 (91%)]      Loss: 266.330963\n",
      "bce: 70.230179, kld: 0.784403\n",
      "====> Epoch: 27 Average loss: 274.1070, bce: 70.3392, kld: 0.8151\n",
      "Train Epoch: 28 [   0/22533 ( 0%)]      Loss: 264.406982\n",
      "bce: 69.990799, kld: 0.777665\n",
      "Train Epoch: 28 [10240/22533 (45%)]      Loss: 257.395142\n",
      "bce: 69.811234, kld: 0.750336\n",
      "Train Epoch: 28 [20480/22533 (91%)]      Loss: 250.131042\n",
      "bce: 69.528679, kld: 0.722409\n",
      "====> Epoch: 28 Average loss: 257.2355, bce: 69.7554, kld: 0.7499\n",
      "Train Epoch: 29 [   0/22533 ( 0%)]      Loss: 248.736542\n",
      "bce: 69.450645, kld: 0.717144\n",
      "Train Epoch: 29 [10240/22533 (45%)]      Loss: 242.097046\n",
      "bce: 68.993607, kld: 0.692414\n",
      "Train Epoch: 29 [20480/22533 (91%)]      Loss: 235.631470\n",
      "bce: 68.805809, kld: 0.667303\n",
      "====> Epoch: 29 Average loss: 242.2393, bce: 69.1822, kld: 0.6922\n",
      "Train Epoch: 30 [   0/22533 ( 0%)]      Loss: 235.069016\n",
      "bce: 68.977478, kld: 0.664366\n",
      "Train Epoch: 30 [10240/22533 (45%)]      Loss: 228.900787\n",
      "bce: 68.732658, kld: 0.640673\n",
      "Train Epoch: 30 [20480/22533 (91%)]      Loss: 223.256775\n",
      "bce: 68.418564, kld: 0.619353\n",
      "====> Epoch: 30 Average loss: 228.8615, bce: 68.6181, kld: 0.6410\n",
      "====> Testing Average Loss: 49.68736374151245\n",
      "Train Epoch: 31 [   0/22533 ( 0%)]      Loss: 222.255463\n",
      "bce: 68.537025, kld: 0.614874\n",
      "Train Epoch: 31 [10240/22533 (45%)]      Loss: 217.241577\n",
      "bce: 68.143555, kld: 0.596392\n",
      "Train Epoch: 31 [20480/22533 (91%)]      Loss: 212.042786\n",
      "bce: 67.959389, kld: 0.576334\n",
      "====> Epoch: 31 Average loss: 216.8536, bce: 68.0624, kld: 0.5952\n",
      "Train Epoch: 32 [   0/22533 ( 0%)]      Loss: 210.769287\n",
      "bce: 67.845924, kld: 0.571693\n",
      "Train Epoch: 32 [10240/22533 (45%)]      Loss: 206.403107\n",
      "bce: 67.588974, kld: 0.555257\n",
      "Train Epoch: 32 [20480/22533 (91%)]      Loss: 201.552078\n",
      "bce: 67.245789, kld: 0.537225\n",
      "====> Epoch: 32 Average loss: 206.0614, bce: 67.5198, kld: 0.5542\n",
      "Train Epoch: 33 [   0/22533 ( 0%)]      Loss: 201.064438\n",
      "bce: 67.452637, kld: 0.534447\n",
      "Train Epoch: 33 [10240/22533 (45%)]      Loss: 197.046402\n",
      "bce: 67.442978, kld: 0.518414\n",
      "Train Epoch: 33 [20480/22533 (91%)]      Loss: 191.811371\n",
      "bce: 66.272171, kld: 0.502157\n",
      "====> Epoch: 33 Average loss: 196.3023, bce: 66.9807, kld: 0.5173\n",
      "Train Epoch: 34 [   0/22533 ( 0%)]      Loss: 191.089783\n",
      "bce: 66.562393, kld: 0.498110\n",
      "Train Epoch: 34 [10240/22533 (45%)]      Loss: 187.680267\n",
      "bce: 66.795151, kld: 0.483540\n",
      "Train Epoch: 34 [20480/22533 (91%)]      Loss: 183.424805\n",
      "bce: 66.105141, kld: 0.469279\n",
      "====> Epoch: 34 Average loss: 187.4340, bce: 66.4532, kld: 0.4839\n",
      "Train Epoch: 35 [   0/22533 ( 0%)]      Loss: 182.793091\n",
      "bce: 65.900719, kld: 0.467570\n",
      "Train Epoch: 35 [10240/22533 (45%)]      Loss: 179.877289\n",
      "bce: 66.542633, kld: 0.453339\n",
      "Train Epoch: 35 [20480/22533 (91%)]      Loss: 175.207947\n",
      "bce: 64.985336, kld: 0.440890\n",
      "====> Epoch: 35 Average loss: 179.3623, bce: 65.9336, kld: 0.4537\n",
      "====> Testing Average Loss: 47.22613292171482\n",
      "Train Epoch: 36 [   0/22533 ( 0%)]      Loss: 174.931595\n",
      "bce: 65.395027, kld: 0.438146\n",
      "Train Epoch: 36 [10240/22533 (45%)]      Loss: 171.947357\n",
      "bce: 65.321968, kld: 0.426502\n",
      "Train Epoch: 36 [20480/22533 (91%)]      Loss: 168.404022\n",
      "bce: 64.966347, kld: 0.413751\n",
      "====> Epoch: 36 Average loss: 171.9852, bce: 65.4220, kld: 0.4263\n",
      "Train Epoch: 37 [   0/22533 ( 0%)]      Loss: 167.996643\n",
      "bce: 65.146858, kld: 0.411399\n",
      "Train Epoch: 37 [10240/22533 (45%)]      Loss: 165.561707\n",
      "bce: 65.411354, kld: 0.400601\n",
      "Train Epoch: 37 [20480/22533 (91%)]      Loss: 162.337433\n",
      "bce: 64.549805, kld: 0.391151\n",
      "====> Epoch: 37 Average loss: 165.2193, bce: 64.9157, kld: 0.4012\n",
      "Train Epoch: 38 [   0/22533 ( 0%)]      Loss: 161.957214\n",
      "bce: 64.751862, kld: 0.388821\n",
      "Train Epoch: 38 [10240/22533 (45%)]      Loss: 158.778625\n",
      "bce: 63.956219, kld: 0.379290\n",
      "Train Epoch: 38 [20480/22533 (91%)]      Loss: 156.540558\n",
      "bce: 64.297585, kld: 0.368972\n",
      "====> Epoch: 38 Average loss: 159.0002, bce: 64.4211, kld: 0.3783\n",
      "Train Epoch: 39 [   0/22533 ( 0%)]      Loss: 156.172058\n",
      "bce: 64.529739, kld: 0.366569\n",
      "Train Epoch: 39 [10240/22533 (45%)]      Loss: 153.110153\n",
      "bce: 63.904167, kld: 0.356824\n",
      "Train Epoch: 39 [20480/22533 (91%)]      Loss: 150.652878\n",
      "bce: 63.482601, kld: 0.348681\n",
      "====> Epoch: 39 Average loss: 153.2564, bce: 63.9295, kld: 0.3573\n",
      "Train Epoch: 40 [   0/22533 ( 0%)]      Loss: 150.462692\n",
      "bce: 63.671623, kld: 0.347164\n",
      "Train Epoch: 40 [10240/22533 (45%)]      Loss: 147.840775\n",
      "bce: 63.424843, kld: 0.337664\n",
      "Train Epoch: 40 [20480/22533 (91%)]      Loss: 145.508148\n",
      "bce: 63.157303, kld: 0.329403\n",
      "====> Epoch: 40 Average loss: 147.9544, bce: 63.4433, kld: 0.3380\n",
      "====> Testing Average Loss: 44.939137182132875\n",
      "Train Epoch: 41 [   0/22533 ( 0%)]      Loss: 144.962006\n",
      "bce: 62.894871, kld: 0.328269\n",
      "Train Epoch: 41 [10240/22533 (45%)]      Loss: 143.134827\n",
      "bce: 63.093704, kld: 0.320164\n",
      "Train Epoch: 41 [20480/22533 (91%)]      Loss: 141.087082\n",
      "bce: 62.895214, kld: 0.312767\n",
      "====> Epoch: 41 Average loss: 143.0372, bce: 62.9717, kld: 0.3203\n",
      "Train Epoch: 42 [   0/22533 ( 0%)]      Loss: 140.214386\n",
      "bce: 62.451588, kld: 0.311051\n",
      "Train Epoch: 42 [10240/22533 (45%)]      Loss: 138.649200\n",
      "bce: 62.584465, kld: 0.304259\n",
      "Train Epoch: 42 [20480/22533 (91%)]      Loss: 136.210678\n",
      "bce: 61.950981, kld: 0.297039\n",
      "====> Epoch: 42 Average loss: 138.4719, bce: 62.5056, kld: 0.3039\n",
      "Train Epoch: 43 [   0/22533 ( 0%)]      Loss: 136.320236\n",
      "bce: 62.439312, kld: 0.295524\n",
      "Train Epoch: 43 [10240/22533 (45%)]      Loss: 134.314316\n",
      "bce: 62.154327, kld: 0.288640\n",
      "Train Epoch: 43 [20480/22533 (91%)]      Loss: 132.488525\n",
      "bce: 61.928551, kld: 0.282240\n",
      "====> Epoch: 43 Average loss: 134.2167, bce: 62.0383, kld: 0.2887\n",
      "Train Epoch: 44 [   0/22533 ( 0%)]      Loss: 132.369827\n",
      "bce: 62.091091, kld: 0.281115\n",
      "Train Epoch: 44 [10240/22533 (45%)]      Loss: 130.838440\n",
      "bce: 62.137062, kld: 0.274805\n",
      "Train Epoch: 44 [20480/22533 (91%)]      Loss: 128.312042\n",
      "bce: 61.175232, kld: 0.268547\n",
      "====> Epoch: 44 Average loss: 130.2544, bce: 61.5863, kld: 0.2747\n",
      "Train Epoch: 45 [   0/22533 ( 0%)]      Loss: 128.074631\n",
      "bce: 61.150463, kld: 0.267697\n",
      "Train Epoch: 45 [10240/22533 (45%)]      Loss: 126.526939\n",
      "bce: 61.220757, kld: 0.261225\n",
      "Train Epoch: 45 [20480/22533 (91%)]      Loss: 124.949654\n",
      "bce: 61.001266, kld: 0.255794\n",
      "====> Epoch: 45 Average loss: 126.5346, bce: 61.1360, kld: 0.2616\n",
      "====> Testing Average Loss: 42.850988342098255\n",
      "Train Epoch: 46 [   0/22533 ( 0%)]      Loss: 124.460892\n",
      "bce: 60.767944, kld: 0.254772\n",
      "Train Epoch: 46 [10240/22533 (45%)]      Loss: 123.086365\n",
      "bce: 60.770004, kld: 0.249265\n",
      "Train Epoch: 46 [20480/22533 (91%)]      Loss: 121.471878\n",
      "bce: 60.514034, kld: 0.243831\n",
      "====> Epoch: 46 Average loss: 123.0514, bce: 60.6898, kld: 0.2494\n",
      "Train Epoch: 47 [   0/22533 ( 0%)]      Loss: 121.101044\n",
      "bce: 60.310448, kld: 0.243162\n",
      "Train Epoch: 47 [10240/22533 (45%)]      Loss: 120.003448\n",
      "bce: 60.212677, kld: 0.239163\n",
      "Train Epoch: 47 [20480/22533 (91%)]      Loss: 118.699280\n",
      "bce: 60.292828, kld: 0.233626\n",
      "====> Epoch: 47 Average loss: 119.7789, bce: 60.2488, kld: 0.2381\n",
      "Train Epoch: 48 [   0/22533 ( 0%)]      Loss: 118.327805\n",
      "bce: 60.279636, kld: 0.232193\n",
      "Train Epoch: 48 [10240/22533 (45%)]      Loss: 116.460266\n",
      "bce: 59.725716, kld: 0.226938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [20480/22533 (91%)]      Loss: 115.671204\n",
      "bce: 59.795177, kld: 0.223504\n",
      "====> Epoch: 48 Average loss: 116.7119, bce: 59.8175, kld: 0.2276\n",
      "Train Epoch: 49 [   0/22533 ( 0%)]      Loss: 115.259132\n",
      "bce: 59.773048, kld: 0.221944\n",
      "Train Epoch: 49 [10240/22533 (45%)]      Loss: 113.703674\n",
      "bce: 59.311020, kld: 0.217571\n",
      "Train Epoch: 49 [20480/22533 (91%)]      Loss: 112.454330\n",
      "bce: 59.136143, kld: 0.213273\n",
      "====> Epoch: 49 Average loss: 113.8136, bce: 59.3930, kld: 0.2177\n",
      "Train Epoch: 50 [   0/22533 ( 0%)]      Loss: 111.807503\n",
      "bce: 58.647430, kld: 0.212640\n",
      "Train Epoch: 50 [10240/22533 (45%)]      Loss: 110.753632\n",
      "bce: 58.529255, kld: 0.208897\n",
      "Train Epoch: 50 [20480/22533 (91%)]      Loss: 109.584106\n",
      "bce: 58.507034, kld: 0.204308\n",
      "====> Epoch: 50 Average loss: 111.0753, bce: 58.9691, kld: 0.2084\n",
      "====> Testing Average Loss: 40.932893214951406\n",
      "Train Epoch: 51 [   0/22533 ( 0%)]      Loss: 109.292511\n",
      "bce: 58.376293, kld: 0.203665\n",
      "Train Epoch: 51 [10240/22533 (45%)]      Loss: 108.138107\n",
      "bce: 58.176830, kld: 0.199845\n",
      "Train Epoch: 51 [20480/22533 (91%)]      Loss: 107.560822\n",
      "bce: 58.576973, kld: 0.195935\n",
      "====> Epoch: 51 Average loss: 108.4894, bce: 58.5520, kld: 0.1997\n",
      "Train Epoch: 52 [   0/22533 ( 0%)]      Loss: 106.959106\n",
      "bce: 58.067024, kld: 0.195568\n",
      "Train Epoch: 52 [10240/22533 (45%)]      Loss: 105.634735\n",
      "bce: 57.804508, kld: 0.191321\n",
      "Train Epoch: 52 [20480/22533 (91%)]      Loss: 105.202271\n",
      "bce: 58.155811, kld: 0.188186\n",
      "====> Epoch: 52 Average loss: 106.0367, bce: 58.1375, kld: 0.1916\n",
      "Train Epoch: 53 [   0/22533 ( 0%)]      Loss: 104.411057\n",
      "bce: 57.587559, kld: 0.187294\n",
      "Train Epoch: 53 [10240/22533 (45%)]      Loss: 103.176834\n",
      "bce: 57.203979, kld: 0.183891\n",
      "Train Epoch: 53 [20480/22533 (91%)]      Loss: 102.863281\n",
      "bce: 57.751106, kld: 0.180449\n",
      "====> Epoch: 53 Average loss: 103.7097, bce: 57.7313, kld: 0.1839\n",
      "Train Epoch: 54 [   0/22533 ( 0%)]      Loss: 102.876862\n",
      "bce: 57.830879, kld: 0.180184\n",
      "Train Epoch: 54 [10240/22533 (45%)]      Loss: 101.431458\n",
      "bce: 57.326370, kld: 0.176420\n",
      "Train Epoch: 54 [20480/22533 (91%)]      Loss: 100.838829\n",
      "bce: 57.356384, kld: 0.173930\n",
      "====> Epoch: 54 Average loss: 101.5031, bce: 57.3258, kld: 0.1767\n",
      "Train Epoch: 55 [   0/22533 ( 0%)]      Loss: 100.048393\n",
      "bce: 56.886330, kld: 0.172648\n",
      "Train Epoch: 55 [10240/22533 (45%)]      Loss: 99.804413\n",
      "bce: 57.285900, kld: 0.170074\n",
      "Train Epoch: 55 [20480/22533 (91%)]      Loss: 98.998779\n",
      "bce: 57.162952, kld: 0.167343\n",
      "====> Epoch: 55 Average loss: 99.4046, bce: 56.9298, kld: 0.1699\n",
      "====> Testing Average Loss: 39.17107201105046\n",
      "Train Epoch: 56 [   0/22533 ( 0%)]      Loss: 98.486244\n",
      "bce: 56.805748, kld: 0.166722\n",
      "Train Epoch: 56 [10240/22533 (45%)]      Loss: 97.847473\n",
      "bce: 56.949646, kld: 0.163591\n",
      "Train Epoch: 56 [20480/22533 (91%)]      Loss: 96.464005\n",
      "bce: 56.343739, kld: 0.160481\n",
      "====> Epoch: 56 Average loss: 97.4116, bce: 56.5383, kld: 0.1635\n",
      "Train Epoch: 57 [   0/22533 ( 0%)]      Loss: 95.751602\n",
      "bce: 55.754333, kld: 0.159989\n",
      "Train Epoch: 57 [10240/22533 (45%)]      Loss: 95.996162\n",
      "bce: 56.549549, kld: 0.157786\n",
      "Train Epoch: 57 [20480/22533 (91%)]      Loss: 94.641754\n",
      "bce: 55.956635, kld: 0.154740\n",
      "====> Epoch: 57 Average loss: 95.5086, bce: 56.1521, kld: 0.1574\n",
      "Train Epoch: 58 [   0/22533 ( 0%)]      Loss: 94.915520\n",
      "bce: 56.243431, kld: 0.154688\n",
      "Train Epoch: 58 [10240/22533 (45%)]      Loss: 93.925453\n",
      "bce: 56.053658, kld: 0.151487\n",
      "Train Epoch: 58 [20480/22533 (91%)]      Loss: 92.892578\n",
      "bce: 55.593491, kld: 0.149196\n",
      "====> Epoch: 58 Average loss: 93.6979, bce: 55.7712, kld: 0.1517\n",
      "Train Epoch: 59 [   0/22533 ( 0%)]      Loss: 92.960968\n",
      "bce: 55.745193, kld: 0.148863\n",
      "Train Epoch: 59 [10240/22533 (45%)]      Loss: 92.115662\n",
      "bce: 55.535278, kld: 0.146322\n",
      "Train Epoch: 59 [20480/22533 (91%)]      Loss: 91.360825\n",
      "bce: 55.327003, kld: 0.144135\n",
      "====> Epoch: 59 Average loss: 91.9613, bce: 55.3937, kld: 0.1463\n",
      "Train Epoch: 60 [   0/22533 ( 0%)]      Loss: 91.147400\n",
      "bce: 55.251431, kld: 0.143584\n",
      "Train Epoch: 60 [10240/22533 (45%)]      Loss: 90.158203\n",
      "bce: 54.819180, kld: 0.141356\n",
      "Train Epoch: 60 [20480/22533 (91%)]      Loss: 89.900887\n",
      "bce: 55.190079, kld: 0.138843\n",
      "====> Epoch: 60 Average loss: 90.3066, bce: 55.0258, kld: 0.1411\n",
      "====> Testing Average Loss: 37.53131552889096\n",
      "Train Epoch: 61 [   0/22533 ( 0%)]      Loss: 89.922302\n",
      "bce: 55.332615, kld: 0.138359\n",
      "Train Epoch: 61 [10240/22533 (45%)]      Loss: 88.818153\n",
      "bce: 54.779533, kld: 0.136154\n",
      "Train Epoch: 61 [20480/22533 (91%)]      Loss: 87.261673\n",
      "bce: 53.719093, kld: 0.134170\n",
      "====> Epoch: 61 Average loss: 88.7198, bce: 54.6575, kld: 0.1362\n",
      "Train Epoch: 62 [   0/22533 ( 0%)]      Loss: 88.287888\n",
      "bce: 54.828407, kld: 0.133838\n",
      "Train Epoch: 62 [10240/22533 (45%)]      Loss: 87.073830\n",
      "bce: 54.167992, kld: 0.131623\n",
      "Train Epoch: 62 [20480/22533 (91%)]      Loss: 86.913414\n",
      "bce: 54.505058, kld: 0.129633\n",
      "====> Epoch: 62 Average loss: 87.2058, bce: 54.3024, kld: 0.1316\n",
      "Train Epoch: 63 [   0/22533 ( 0%)]      Loss: 86.299461\n",
      "bce: 53.996651, kld: 0.129211\n",
      "Train Epoch: 63 [10240/22533 (45%)]      Loss: 85.552628\n",
      "bce: 53.787979, kld: 0.127059\n",
      "Train Epoch: 63 [20480/22533 (91%)]      Loss: 84.930336\n",
      "bce: 53.591274, kld: 0.125356\n",
      "====> Epoch: 63 Average loss: 85.7493, bce: 53.9447, kld: 0.1272\n",
      "Train Epoch: 64 [   0/22533 ( 0%)]      Loss: 85.145203\n",
      "bce: 53.941162, kld: 0.124816\n",
      "Train Epoch: 64 [10240/22533 (45%)]      Loss: 84.992737\n",
      "bce: 54.180687, kld: 0.123248\n",
      "Train Epoch: 64 [20480/22533 (91%)]      Loss: 83.631073\n",
      "bce: 53.229893, kld: 0.121605\n",
      "====> Epoch: 64 Average loss: 84.3493, bce: 53.5931, kld: 0.1230\n",
      "Train Epoch: 65 [   0/22533 ( 0%)]      Loss: 83.750732\n",
      "bce: 53.531448, kld: 0.120877\n",
      "Train Epoch: 65 [10240/22533 (45%)]      Loss: 82.778717\n",
      "bce: 53.028873, kld: 0.118999\n",
      "Train Epoch: 65 [20480/22533 (91%)]      Loss: 82.315964\n",
      "bce: 52.961391, kld: 0.117418\n",
      "====> Epoch: 65 Average loss: 83.0021, bce: 53.2425, kld: 0.1190\n",
      "====> Testing Average Loss: 35.971870423379045\n",
      "Train Epoch: 66 [   0/22533 ( 0%)]      Loss: 82.082405\n",
      "bce: 52.908638, kld: 0.116695\n",
      "Train Epoch: 66 [10240/22533 (45%)]      Loss: 81.686340\n",
      "bce: 52.902405, kld: 0.115136\n",
      "Train Epoch: 66 [20480/22533 (91%)]      Loss: 81.578568\n",
      "bce: 53.201347, kld: 0.113509\n",
      "====> Epoch: 66 Average loss: 81.7155, bce: 52.9043, kld: 0.1152\n",
      "Train Epoch: 67 [   0/22533 ( 0%)]      Loss: 80.900269\n",
      "bce: 52.673317, kld: 0.112908\n",
      "Train Epoch: 67 [10240/22533 (45%)]      Loss: 80.074287\n",
      "bce: 52.185951, kld: 0.111553\n",
      "Train Epoch: 67 [20480/22533 (91%)]      Loss: 80.311996\n",
      "bce: 52.766201, kld: 0.110183\n",
      "====> Epoch: 67 Average loss: 80.4691, bce: 52.5615, kld: 0.1116\n",
      "Train Epoch: 68 [   0/22533 ( 0%)]      Loss: 79.816231\n",
      "bce: 52.405632, kld: 0.109642\n",
      "Train Epoch: 68 [10240/22533 (45%)]      Loss: 78.929550\n",
      "bce: 51.813622, kld: 0.108464\n",
      "Train Epoch: 68 [20480/22533 (91%)]      Loss: 79.253296\n",
      "bce: 52.603085, kld: 0.106601\n",
      "====> Epoch: 68 Average loss: 79.2749, bce: 52.2301, kld: 0.1082\n",
      "Train Epoch: 69 [   0/22533 ( 0%)]      Loss: 78.367653\n",
      "bce: 51.776810, kld: 0.106363\n",
      "Train Epoch: 69 [10240/22533 (45%)]      Loss: 78.325447\n",
      "bce: 52.060314, kld: 0.105061\n",
      "Train Epoch: 69 [20480/22533 (91%)]      Loss: 77.383347\n",
      "bce: 51.593723, kld: 0.103158\n",
      "====> Epoch: 69 Average loss: 78.1248, bce: 51.9076, kld: 0.1049\n",
      "Train Epoch: 70 [   0/22533 ( 0%)]      Loss: 77.349983\n",
      "bce: 51.624260, kld: 0.102903\n",
      "Train Epoch: 70 [10240/22533 (45%)]      Loss: 77.230064\n",
      "bce: 51.756538, kld: 0.101894\n",
      "Train Epoch: 70 [20480/22533 (91%)]      Loss: 76.223274\n",
      "bce: 51.083557, kld: 0.100559\n",
      "====> Epoch: 70 Average loss: 77.0094, bce: 51.5774, kld: 0.1017\n",
      "====> Testing Average Loss: 34.50497291472507\n",
      "Train Epoch: 71 [   0/22533 ( 0%)]      Loss: 76.136002\n",
      "bce: 51.163567, kld: 0.099890\n",
      "Train Epoch: 71 [10240/22533 (45%)]      Loss: 75.154655\n",
      "bce: 50.529900, kld: 0.098499\n",
      "Train Epoch: 71 [20480/22533 (91%)]      Loss: 75.858414\n",
      "bce: 51.523682, kld: 0.097339\n",
      "====> Epoch: 71 Average loss: 75.9374, bce: 51.2571, kld: 0.0987\n",
      "Train Epoch: 72 [   0/22533 ( 0%)]      Loss: 75.468567\n",
      "bce: 51.170685, kld: 0.097192\n",
      "Train Epoch: 72 [10240/22533 (45%)]      Loss: 74.437241\n",
      "bce: 50.513428, kld: 0.095695\n",
      "Train Epoch: 72 [20480/22533 (91%)]      Loss: 74.646454\n",
      "bce: 51.004631, kld: 0.094567\n",
      "====> Epoch: 72 Average loss: 74.8912, bce: 50.9364, kld: 0.0958\n",
      "Train Epoch: 73 [   0/22533 ( 0%)]      Loss: 74.333015\n",
      "bce: 50.718296, kld: 0.094459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [10240/22533 (45%)]      Loss: 73.987656\n",
      "bce: 50.683361, kld: 0.093217\n",
      "Train Epoch: 73 [20480/22533 (91%)]      Loss: 73.740128\n",
      "bce: 50.801910, kld: 0.091753\n",
      "====> Epoch: 73 Average loss: 73.8860, bce: 50.6225, kld: 0.0931\n",
      "Train Epoch: 74 [   0/22533 ( 0%)]      Loss: 73.788010\n",
      "bce: 50.846237, kld: 0.091767\n",
      "Train Epoch: 74 [10240/22533 (45%)]      Loss: 73.319710\n",
      "bce: 50.728310, kld: 0.090366\n",
      "Train Epoch: 74 [20480/22533 (91%)]      Loss: 72.873604\n",
      "bce: 50.536583, kld: 0.089348\n",
      "====> Epoch: 74 Average loss: 72.9234, bce: 50.3186, kld: 0.0904\n",
      "Train Epoch: 75 [   0/22533 ( 0%)]      Loss: 72.293938\n",
      "bce: 49.984871, kld: 0.089236\n",
      "Train Epoch: 75 [10240/22533 (45%)]      Loss: 72.163124\n",
      "bce: 50.181519, kld: 0.087926\n",
      "Train Epoch: 75 [20480/22533 (91%)]      Loss: 71.288643\n",
      "bce: 49.653118, kld: 0.086542\n",
      "====> Epoch: 75 Average loss: 71.9773, bce: 50.0091, kld: 0.0879\n",
      "====> Testing Average Loss: 33.18647546099055\n",
      "Train Epoch: 76 [   0/22533 ( 0%)]      Loss: 71.593948\n",
      "bce: 49.898933, kld: 0.086780\n",
      "Train Epoch: 76 [10240/22533 (45%)]      Loss: 71.067131\n",
      "bce: 49.765205, kld: 0.085208\n",
      "Train Epoch: 76 [20480/22533 (91%)]      Loss: 70.667877\n",
      "bce: 49.479095, kld: 0.084755\n",
      "====> Epoch: 76 Average loss: 71.0677, bce: 49.7085, kld: 0.0854\n",
      "Train Epoch: 77 [   0/22533 ( 0%)]      Loss: 70.602585\n",
      "bce: 49.552254, kld: 0.084201\n",
      "Train Epoch: 77 [10240/22533 (45%)]      Loss: 69.965057\n",
      "bce: 49.165665, kld: 0.083198\n",
      "Train Epoch: 77 [20480/22533 (91%)]      Loss: 69.767525\n",
      "bce: 49.204823, kld: 0.082251\n",
      "====> Epoch: 77 Average loss: 70.1933, bce: 49.4164, kld: 0.0831\n",
      "Train Epoch: 78 [   0/22533 ( 0%)]      Loss: 69.608475\n",
      "bce: 49.114601, kld: 0.081976\n",
      "Train Epoch: 78 [10240/22533 (45%)]      Loss: 69.707352\n",
      "bce: 49.462685, kld: 0.080979\n",
      "Train Epoch: 78 [20480/22533 (91%)]      Loss: 69.114388\n",
      "bce: 49.128311, kld: 0.079944\n",
      "====> Epoch: 78 Average loss: 69.3344, bce: 49.1203, kld: 0.0809\n",
      "Train Epoch: 79 [   0/22533 ( 0%)]      Loss: 68.359932\n",
      "bce: 48.464996, kld: 0.079580\n",
      "Train Epoch: 79 [10240/22533 (45%)]      Loss: 68.104362\n",
      "bce: 48.454704, kld: 0.078599\n",
      "Train Epoch: 79 [20480/22533 (91%)]      Loss: 68.133652\n",
      "bce: 48.676109, kld: 0.077830\n",
      "====> Epoch: 79 Average loss: 68.5054, bce: 48.8289, kld: 0.0787\n",
      "Train Epoch: 80 [   0/22533 ( 0%)]      Loss: 67.905785\n",
      "bce: 48.533253, kld: 0.077490\n",
      "Train Epoch: 80 [10240/22533 (45%)]      Loss: 67.794693\n",
      "bce: 48.665154, kld: 0.076518\n",
      "Train Epoch: 80 [20480/22533 (91%)]      Loss: 67.770859\n",
      "bce: 48.802368, kld: 0.075874\n",
      "====> Epoch: 80 Average loss: 67.6975, bce: 48.5407, kld: 0.0766\n",
      "====> Testing Average Loss: 31.8668796182266\n",
      "Train Epoch: 81 [   0/22533 ( 0%)]      Loss: 67.092705\n",
      "bce: 48.259224, kld: 0.075334\n",
      "Train Epoch: 81 [10240/22533 (45%)]      Loss: 67.226448\n",
      "bce: 48.576439, kld: 0.074600\n",
      "Train Epoch: 81 [20480/22533 (91%)]      Loss: 66.512718\n",
      "bce: 48.037262, kld: 0.073902\n",
      "====> Epoch: 81 Average loss: 66.9234, bce: 48.2587, kld: 0.0747\n",
      "Train Epoch: 82 [   0/22533 ( 0%)]      Loss: 66.301437\n",
      "bce: 47.882366, kld: 0.073676\n",
      "Train Epoch: 82 [10240/22533 (45%)]      Loss: 66.192993\n",
      "bce: 48.007736, kld: 0.072741\n",
      "Train Epoch: 82 [20480/22533 (91%)]      Loss: 65.904869\n",
      "bce: 47.972046, kld: 0.071731\n",
      "====> Epoch: 82 Average loss: 66.1582, bce: 47.9780, kld: 0.0727\n",
      "Train Epoch: 83 [   0/22533 ( 0%)]      Loss: 65.548950\n",
      "bce: 47.682930, kld: 0.071464\n",
      "Train Epoch: 83 [10240/22533 (45%)]      Loss: 65.782028\n",
      "bce: 48.055779, kld: 0.070905\n",
      "Train Epoch: 83 [20480/22533 (91%)]      Loss: 64.899704\n",
      "bce: 47.393990, kld: 0.070023\n",
      "====> Epoch: 83 Average loss: 65.4188, bce: 47.7000, kld: 0.0709\n",
      "Train Epoch: 84 [   0/22533 ( 0%)]      Loss: 64.692978\n",
      "bce: 47.224121, kld: 0.069875\n",
      "Train Epoch: 84 [10240/22533 (45%)]      Loss: 64.461014\n",
      "bce: 47.216591, kld: 0.068978\n",
      "Train Epoch: 84 [20480/22533 (91%)]      Loss: 64.089050\n",
      "bce: 47.006805, kld: 0.068329\n",
      "====> Epoch: 84 Average loss: 64.7092, bce: 47.4302, kld: 0.0691\n",
      "Train Epoch: 85 [   0/22533 ( 0%)]      Loss: 64.058479\n",
      "bce: 47.002602, kld: 0.068224\n",
      "Train Epoch: 85 [10240/22533 (45%)]      Loss: 64.603806\n",
      "bce: 47.767117, kld: 0.067347\n",
      "Train Epoch: 85 [20480/22533 (91%)]      Loss: 63.309486\n",
      "bce: 46.633308, kld: 0.066705\n",
      "====> Epoch: 85 Average loss: 64.0113, bce: 47.1642, kld: 0.0674\n",
      "====> Testing Average Loss: 30.668039999667155\n",
      "Train Epoch: 86 [   0/22533 ( 0%)]      Loss: 63.583038\n",
      "bce: 46.944656, kld: 0.066554\n",
      "Train Epoch: 86 [10240/22533 (45%)]      Loss: 63.581593\n",
      "bce: 47.126968, kld: 0.065818\n",
      "Train Epoch: 86 [20480/22533 (91%)]      Loss: 63.031891\n",
      "bce: 46.766747, kld: 0.065061\n",
      "====> Epoch: 86 Average loss: 63.3280, bce: 46.8902, kld: 0.0658\n",
      "Train Epoch: 87 [   0/22533 ( 0%)]      Loss: 63.532738\n",
      "bce: 47.308762, kld: 0.064896\n",
      "Train Epoch: 87 [10240/22533 (45%)]      Loss: 63.006271\n",
      "bce: 46.991638, kld: 0.064059\n",
      "Train Epoch: 87 [20480/22533 (91%)]      Loss: 61.713135\n",
      "bce: 45.814575, kld: 0.063594\n",
      "====> Epoch: 87 Average loss: 62.6636, bce: 46.6274, kld: 0.0641\n",
      "Train Epoch: 88 [   0/22533 ( 0%)]      Loss: 62.266472\n",
      "bce: 46.446732, kld: 0.063279\n",
      "Train Epoch: 88 [10240/22533 (45%)]      Loss: 62.109329\n",
      "bce: 46.414097, kld: 0.062781\n",
      "Train Epoch: 88 [20480/22533 (91%)]      Loss: 61.965855\n",
      "bce: 46.535065, kld: 0.061723\n",
      "====> Epoch: 88 Average loss: 62.0179, bce: 46.3646, kld: 0.0626\n",
      "Train Epoch: 89 [   0/22533 ( 0%)]      Loss: 61.149075\n",
      "bce: 45.697014, kld: 0.061808\n",
      "Train Epoch: 89 [10240/22533 (45%)]      Loss: 62.340641\n",
      "bce: 47.101181, kld: 0.060958\n",
      "Train Epoch: 89 [20480/22533 (91%)]      Loss: 61.368011\n",
      "bce: 46.238789, kld: 0.060517\n",
      "====> Epoch: 89 Average loss: 61.3913, bce: 46.1108, kld: 0.0611\n",
      "Train Epoch: 90 [   0/22533 ( 0%)]      Loss: 60.816711\n",
      "bce: 45.748371, kld: 0.060273\n",
      "Train Epoch: 90 [10240/22533 (45%)]      Loss: 61.062004\n",
      "bce: 46.114662, kld: 0.059789\n",
      "Train Epoch: 90 [20480/22533 (91%)]      Loss: 60.829678\n",
      "bce: 46.006554, kld: 0.059292\n",
      "====> Epoch: 90 Average loss: 60.7793, bce: 45.8533, kld: 0.0597\n",
      "====> Testing Average Loss: 29.608087305285583\n",
      "Train Epoch: 91 [   0/22533 ( 0%)]      Loss: 61.002529\n",
      "bce: 46.252296, kld: 0.059001\n",
      "Train Epoch: 91 [10240/22533 (45%)]      Loss: 60.710297\n",
      "bce: 46.115925, kld: 0.058377\n",
      "Train Epoch: 91 [20480/22533 (91%)]      Loss: 59.958744\n",
      "bce: 45.527660, kld: 0.057724\n",
      "====> Epoch: 91 Average loss: 60.1785, bce: 45.6003, kld: 0.0583\n",
      "Train Epoch: 92 [   0/22533 ( 0%)]      Loss: 60.348541\n",
      "bce: 45.918102, kld: 0.057722\n",
      "Train Epoch: 92 [10240/22533 (45%)]      Loss: 59.852554\n",
      "bce: 45.605942, kld: 0.056986\n",
      "Train Epoch: 92 [20480/22533 (91%)]      Loss: 59.151390\n",
      "bce: 45.054756, kld: 0.056387\n",
      "====> Epoch: 92 Average loss: 59.5882, bce: 45.3474, kld: 0.0570\n",
      "Train Epoch: 93 [   0/22533 ( 0%)]      Loss: 59.757854\n",
      "bce: 45.697937, kld: 0.056240\n",
      "Train Epoch: 93 [10240/22533 (45%)]      Loss: 58.532593\n",
      "bce: 44.660202, kld: 0.055490\n",
      "Train Epoch: 93 [20480/22533 (91%)]      Loss: 58.790318\n",
      "bce: 44.997101, kld: 0.055173\n",
      "====> Epoch: 93 Average loss: 59.0224, bce: 45.1057, kld: 0.0557\n",
      "Train Epoch: 94 [   0/22533 ( 0%)]      Loss: 58.293537\n",
      "bce: 44.524429, kld: 0.055076\n",
      "Train Epoch: 94 [10240/22533 (45%)]      Loss: 58.822865\n",
      "bce: 45.233681, kld: 0.054357\n",
      "Train Epoch: 94 [20480/22533 (91%)]      Loss: 58.673168\n",
      "bce: 45.192993, kld: 0.053921\n",
      "====> Epoch: 94 Average loss: 58.4704, bce: 44.8639, kld: 0.0544\n",
      "Train Epoch: 95 [   0/22533 ( 0%)]      Loss: 58.904202\n",
      "bce: 45.495682, kld: 0.053634\n",
      "Train Epoch: 95 [10240/22533 (45%)]      Loss: 57.631165\n",
      "bce: 44.354202, kld: 0.053108\n",
      "Train Epoch: 95 [20480/22533 (91%)]      Loss: 57.764339\n",
      "bce: 44.576794, kld: 0.052750\n",
      "====> Epoch: 95 Average loss: 57.9273, bce: 44.6234, kld: 0.0532\n",
      "====> Testing Average Loss: 28.50701783217947\n",
      "Train Epoch: 96 [   0/22533 ( 0%)]      Loss: 58.076660\n",
      "bce: 44.941311, kld: 0.052541\n",
      "Train Epoch: 96 [10240/22533 (45%)]      Loss: 57.442787\n",
      "bce: 44.437363, kld: 0.052022\n",
      "Train Epoch: 96 [20480/22533 (91%)]      Loss: 57.543495\n",
      "bce: 44.669365, kld: 0.051497\n",
      "====> Epoch: 96 Average loss: 57.3859, bce: 44.3770, kld: 0.0520\n",
      "Train Epoch: 97 [   0/22533 ( 0%)]      Loss: 57.183178\n",
      "bce: 44.333912, kld: 0.051397\n",
      "Train Epoch: 97 [10240/22533 (45%)]      Loss: 56.880657\n",
      "bce: 44.111435, kld: 0.051077\n",
      "Train Epoch: 97 [20480/22533 (91%)]      Loss: 56.568768\n",
      "bce: 43.974564, kld: 0.050377\n",
      "====> Epoch: 97 Average loss: 56.8700, bce: 44.1454, kld: 0.0509\n",
      "Train Epoch: 98 [   0/22533 ( 0%)]      Loss: 56.342979\n",
      "bce: 43.783516, kld: 0.050238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [10240/22533 (45%)]      Loss: 55.955223\n",
      "bce: 43.460701, kld: 0.049978\n",
      "Train Epoch: 98 [20480/22533 (91%)]      Loss: 55.825607\n",
      "bce: 43.490543, kld: 0.049340\n",
      "====> Epoch: 98 Average loss: 56.3632, bce: 43.9142, kld: 0.0498\n",
      "Train Epoch: 99 [   0/22533 ( 0%)]      Loss: 56.092056\n",
      "bce: 43.795525, kld: 0.049186\n",
      "Train Epoch: 99 [10240/22533 (45%)]      Loss: 56.078648\n",
      "bce: 43.910416, kld: 0.048673\n",
      "Train Epoch: 99 [20480/22533 (91%)]      Loss: 55.798855\n",
      "bce: 43.701515, kld: 0.048389\n",
      "====> Epoch: 99 Average loss: 55.8672, bce: 43.6834, kld: 0.0487\n",
      "Train Epoch: 100 [   0/22533 ( 0%)]      Loss: 55.947441\n",
      "bce: 43.893166, kld: 0.048217\n",
      "Train Epoch: 100 [10240/22533 (45%)]      Loss: 55.865108\n",
      "bce: 43.930092, kld: 0.047740\n",
      "Train Epoch: 100 [20480/22533 (91%)]      Loss: 55.015247\n",
      "bce: 43.199726, kld: 0.047262\n",
      "====> Epoch: 100 Average loss: 55.3862, bce: 43.4586, kld: 0.0477\n",
      "====> Testing Average Loss: 27.536713861336708\n",
      "Train Epoch: 101 [   0/22533 ( 0%)]      Loss: 55.674557\n",
      "bce: 43.850948, kld: 0.047294\n",
      "Train Epoch: 101 [10240/22533 (45%)]      Loss: 55.437439\n",
      "bce: 43.760746, kld: 0.046707\n",
      "Train Epoch: 101 [20480/22533 (91%)]      Loss: 54.676605\n",
      "bce: 43.139435, kld: 0.046149\n",
      "====> Epoch: 101 Average loss: 54.8976, bce: 43.2263, kld: 0.0467\n",
      "Train Epoch: 102 [   0/22533 ( 0%)]      Loss: 55.215202\n",
      "bce: 43.643566, kld: 0.046287\n",
      "Train Epoch: 102 [10240/22533 (45%)]      Loss: 54.324673\n",
      "bce: 42.898621, kld: 0.045704\n",
      "Train Epoch: 102 [20480/22533 (91%)]      Loss: 54.180046\n",
      "bce: 42.869865, kld: 0.045241\n",
      "====> Epoch: 102 Average loss: 54.4428, bce: 43.0091, kld: 0.0457\n",
      "Train Epoch: 103 [   0/22533 ( 0%)]      Loss: 54.491119\n",
      "bce: 43.185379, kld: 0.045223\n",
      "Train Epoch: 103 [10240/22533 (45%)]      Loss: 54.385555\n",
      "bce: 43.187244, kld: 0.044793\n",
      "Train Epoch: 103 [20480/22533 (91%)]      Loss: 53.309013\n",
      "bce: 42.197079, kld: 0.044448\n",
      "====> Epoch: 103 Average loss: 53.9737, bce: 42.7812, kld: 0.0448\n",
      "Train Epoch: 104 [   0/22533 ( 0%)]      Loss: 53.416580\n",
      "bce: 42.342503, kld: 0.044296\n",
      "Train Epoch: 104 [10240/22533 (45%)]      Loss: 53.166386\n",
      "bce: 42.220551, kld: 0.043783\n",
      "Train Epoch: 104 [20480/22533 (91%)]      Loss: 53.880409\n",
      "bce: 43.020927, kld: 0.043438\n",
      "====> Epoch: 104 Average loss: 53.5346, bce: 42.5707, kld: 0.0439\n",
      "Train Epoch: 105 [   0/22533 ( 0%)]      Loss: 52.979103\n",
      "bce: 42.152954, kld: 0.043305\n",
      "Train Epoch: 105 [10240/22533 (45%)]      Loss: 53.505337\n",
      "bce: 42.776119, kld: 0.042917\n",
      "Train Epoch: 105 [20480/22533 (91%)]      Loss: 53.098660\n",
      "bce: 42.437679, kld: 0.042644\n",
      "====> Epoch: 105 Average loss: 53.0917, bce: 42.3484, kld: 0.0430\n",
      "====> Testing Average Loss: 26.582525837105578\n",
      "Train Epoch: 106 [   0/22533 ( 0%)]      Loss: 52.517315\n",
      "bce: 41.890045, kld: 0.042509\n",
      "Train Epoch: 106 [10240/22533 (45%)]      Loss: 52.751747\n",
      "bce: 42.248932, kld: 0.042011\n",
      "Train Epoch: 106 [20480/22533 (91%)]      Loss: 52.275299\n",
      "bce: 41.820663, kld: 0.041819\n",
      "====> Epoch: 106 Average loss: 52.6722, bce: 42.1439, kld: 0.0421\n",
      "Train Epoch: 107 [   0/22533 ( 0%)]      Loss: 53.271606\n",
      "bce: 42.865829, kld: 0.041623\n",
      "Train Epoch: 107 [10240/22533 (45%)]      Loss: 52.313530\n",
      "bce: 41.996056, kld: 0.041270\n",
      "Train Epoch: 107 [20480/22533 (91%)]      Loss: 52.259640\n",
      "bce: 42.016830, kld: 0.040971\n",
      "====> Epoch: 107 Average loss: 52.2526, bce: 41.9338, kld: 0.0413\n",
      "Train Epoch: 108 [   0/22533 ( 0%)]      Loss: 52.335804\n",
      "bce: 42.096649, kld: 0.040957\n",
      "Train Epoch: 108 [10240/22533 (45%)]      Loss: 52.112785\n",
      "bce: 42.020172, kld: 0.040370\n",
      "Train Epoch: 108 [20480/22533 (91%)]      Loss: 51.946091\n",
      "bce: 41.905087, kld: 0.040164\n",
      "====> Epoch: 108 Average loss: 51.8418, bce: 41.7275, kld: 0.0405\n",
      "Train Epoch: 109 [   0/22533 ( 0%)]      Loss: 51.393188\n",
      "bce: 41.357712, kld: 0.040142\n",
      "Train Epoch: 109 [10240/22533 (45%)]      Loss: 51.984200\n",
      "bce: 42.081131, kld: 0.039612\n",
      "Train Epoch: 109 [20480/22533 (91%)]      Loss: 51.488937\n",
      "bce: 41.661972, kld: 0.039308\n",
      "====> Epoch: 109 Average loss: 51.4281, bce: 41.5131, kld: 0.0397\n",
      "Train Epoch: 110 [   0/22533 ( 0%)]      Loss: 50.354904\n",
      "bce: 40.544716, kld: 0.039241\n",
      "Train Epoch: 110 [10240/22533 (45%)]      Loss: 50.684673\n",
      "bce: 40.967545, kld: 0.038869\n",
      "Train Epoch: 110 [20480/22533 (91%)]      Loss: 51.036072\n",
      "bce: 41.381672, kld: 0.038618\n",
      "====> Epoch: 110 Average loss: 51.0279, bce: 41.3055, kld: 0.0389\n",
      "====> Testing Average Loss: 25.785307070463322\n",
      "Train Epoch: 111 [   0/22533 ( 0%)]      Loss: 50.529404\n",
      "bce: 40.924721, kld: 0.038419\n",
      "Train Epoch: 111 [10240/22533 (45%)]      Loss: 51.380371\n",
      "bce: 41.836708, kld: 0.038175\n",
      "Train Epoch: 111 [20480/22533 (91%)]      Loss: 50.578270\n",
      "bce: 41.155182, kld: 0.037692\n",
      "====> Epoch: 111 Average loss: 50.6441, bce: 41.1066, kld: 0.0382\n",
      "Train Epoch: 112 [   0/22533 ( 0%)]      Loss: 50.566715\n",
      "bce: 41.106293, kld: 0.037842\n",
      "Train Epoch: 112 [10240/22533 (45%)]      Loss: 49.561153\n",
      "bce: 40.207283, kld: 0.037415\n",
      "Train Epoch: 112 [20480/22533 (91%)]      Loss: 50.058071\n",
      "bce: 40.770115, kld: 0.037152\n",
      "====> Epoch: 112 Average loss: 50.2619, bce: 40.9060, kld: 0.0374\n",
      "Train Epoch: 113 [   0/22533 ( 0%)]      Loss: 49.939888\n",
      "bce: 40.674099, kld: 0.037063\n",
      "Train Epoch: 113 [10240/22533 (45%)]      Loss: 50.011986\n",
      "bce: 40.846600, kld: 0.036662\n",
      "Train Epoch: 113 [20480/22533 (91%)]      Loss: 49.879272\n",
      "bce: 40.751808, kld: 0.036510\n",
      "====> Epoch: 113 Average loss: 49.8928, bce: 40.7114, kld: 0.0367\n",
      "Train Epoch: 114 [   0/22533 ( 0%)]      Loss: 49.408894\n",
      "bce: 40.331200, kld: 0.036311\n",
      "Train Epoch: 114 [10240/22533 (45%)]      Loss: 49.682541\n",
      "bce: 40.639599, kld: 0.036172\n",
      "Train Epoch: 114 [20480/22533 (91%)]      Loss: 48.960979\n",
      "bce: 40.040718, kld: 0.035681\n",
      "====> Epoch: 114 Average loss: 49.5180, bce: 40.5140, kld: 0.0360\n",
      "Train Epoch: 115 [   0/22533 ( 0%)]      Loss: 49.135838\n",
      "bce: 40.217705, kld: 0.035673\n",
      "Train Epoch: 115 [10240/22533 (45%)]      Loss: 49.180805\n",
      "bce: 40.346268, kld: 0.035338\n",
      "Train Epoch: 115 [20480/22533 (91%)]      Loss: 48.941597\n",
      "bce: 40.155300, kld: 0.035145\n",
      "====> Epoch: 115 Average loss: 49.1580, bce: 40.3202, kld: 0.0354\n",
      "====> Testing Average Loss: 24.880840392424446\n",
      "Train Epoch: 116 [   0/22533 ( 0%)]      Loss: 49.936668\n",
      "bce: 41.180607, kld: 0.035024\n",
      "Train Epoch: 116 [10240/22533 (45%)]      Loss: 48.388027\n",
      "bce: 39.714325, kld: 0.034695\n",
      "Train Epoch: 116 [20480/22533 (91%)]      Loss: 48.575237\n",
      "bce: 39.978710, kld: 0.034386\n",
      "====> Epoch: 116 Average loss: 48.8040, bce: 40.1260, kld: 0.0347\n",
      "Train Epoch: 117 [   0/22533 ( 0%)]      Loss: 48.534424\n",
      "bce: 39.973412, kld: 0.034244\n",
      "Train Epoch: 117 [10240/22533 (45%)]      Loss: 47.921581\n",
      "bce: 39.421837, kld: 0.033999\n",
      "Train Epoch: 117 [20480/22533 (91%)]      Loss: 48.190464\n",
      "bce: 39.729179, kld: 0.033845\n",
      "====> Epoch: 117 Average loss: 48.4522, bce: 39.9339, kld: 0.0341\n",
      "Train Epoch: 118 [   0/22533 ( 0%)]      Loss: 48.280750\n",
      "bce: 39.833633, kld: 0.033788\n",
      "Train Epoch: 118 [10240/22533 (45%)]      Loss: 47.841999\n",
      "bce: 39.433304, kld: 0.033635\n",
      "Train Epoch: 118 [20480/22533 (91%)]      Loss: 47.921539\n",
      "bce: 39.629845, kld: 0.033167\n",
      "====> Epoch: 118 Average loss: 48.1049, bce: 39.7435, kld: 0.0334\n",
      "Train Epoch: 119 [   0/22533 ( 0%)]      Loss: 48.051750\n",
      "bce: 39.764919, kld: 0.033147\n",
      "Train Epoch: 119 [10240/22533 (45%)]      Loss: 47.465805\n",
      "bce: 39.260124, kld: 0.032823\n",
      "Train Epoch: 119 [20480/22533 (91%)]      Loss: 47.367813\n",
      "bce: 39.221912, kld: 0.032584\n",
      "====> Epoch: 119 Average loss: 47.7686, bce: 39.5594, kld: 0.0328\n",
      "Train Epoch: 120 [   0/22533 ( 0%)]      Loss: 48.448254\n",
      "bce: 40.342228, kld: 0.032424\n",
      "Train Epoch: 120 [10240/22533 (45%)]      Loss: 47.234474\n",
      "bce: 39.182098, kld: 0.032210\n",
      "Train Epoch: 120 [20480/22533 (91%)]      Loss: 47.334728\n",
      "bce: 39.330307, kld: 0.032018\n",
      "====> Epoch: 120 Average loss: 47.4439, bce: 39.3805, kld: 0.0323\n",
      "====> Testing Average Loss: 24.03249244857542\n",
      "Train Epoch: 121 [   0/22533 ( 0%)]      Loss: 46.954643\n",
      "bce: 38.987640, kld: 0.031868\n",
      "Train Epoch: 121 [10240/22533 (45%)]      Loss: 47.386520\n",
      "bce: 39.434784, kld: 0.031807\n",
      "Train Epoch: 121 [20480/22533 (91%)]      Loss: 46.631409\n",
      "bce: 38.791264, kld: 0.031361\n",
      "====> Epoch: 121 Average loss: 47.1118, bce: 39.1907, kld: 0.0317\n",
      "Train Epoch: 122 [   0/22533 ( 0%)]      Loss: 46.189445\n",
      "bce: 38.351578, kld: 0.031351\n",
      "Train Epoch: 122 [10240/22533 (45%)]      Loss: 47.339828\n",
      "bce: 39.537941, kld: 0.031208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [20480/22533 (91%)]      Loss: 46.345173\n",
      "bce: 38.625450, kld: 0.030879\n",
      "====> Epoch: 122 Average loss: 46.7862, bce: 39.0077, kld: 0.0311\n",
      "Train Epoch: 123 [   0/22533 ( 0%)]      Loss: 46.630013\n",
      "bce: 38.911797, kld: 0.030873\n",
      "Train Epoch: 123 [10240/22533 (45%)]      Loss: 46.585148\n",
      "bce: 38.905441, kld: 0.030719\n",
      "Train Epoch: 123 [20480/22533 (91%)]      Loss: 46.324814\n",
      "bce: 38.723236, kld: 0.030406\n",
      "====> Epoch: 123 Average loss: 46.4777, bce: 38.8348, kld: 0.0306\n",
      "Train Epoch: 124 [   0/22533 ( 0%)]      Loss: 46.403667\n",
      "bce: 38.824921, kld: 0.030315\n",
      "Train Epoch: 124 [10240/22533 (45%)]      Loss: 46.887012\n",
      "bce: 39.368492, kld: 0.030074\n",
      "Train Epoch: 124 [20480/22533 (91%)]      Loss: 45.571682\n",
      "bce: 38.093010, kld: 0.029915\n",
      "====> Epoch: 124 Average loss: 46.1613, bce: 38.6499, kld: 0.0300\n",
      "Train Epoch: 125 [   0/22533 ( 0%)]      Loss: 45.912300\n",
      "bce: 38.469963, kld: 0.029769\n",
      "Train Epoch: 125 [10240/22533 (45%)]      Loss: 46.153355\n",
      "bce: 38.746017, kld: 0.029629\n",
      "Train Epoch: 125 [20480/22533 (91%)]      Loss: 44.897057\n",
      "bce: 37.596790, kld: 0.029201\n",
      "====> Epoch: 125 Average loss: 45.8666, bce: 38.4836, kld: 0.0295\n",
      "====> Testing Average Loss: 23.417371188922914\n",
      "Train Epoch: 126 [   0/22533 ( 0%)]      Loss: 45.469025\n",
      "bce: 38.168011, kld: 0.029204\n",
      "Train Epoch: 126 [10240/22533 (45%)]      Loss: 45.929688\n",
      "bce: 38.655979, kld: 0.029095\n",
      "Train Epoch: 126 [20480/22533 (91%)]      Loss: 45.188030\n",
      "bce: 38.005573, kld: 0.028730\n",
      "====> Epoch: 126 Average loss: 45.5580, bce: 38.3030, kld: 0.0290\n",
      "Train Epoch: 127 [   0/22533 ( 0%)]      Loss: 45.598282\n",
      "bce: 38.402309, kld: 0.028784\n",
      "Train Epoch: 127 [10240/22533 (45%)]      Loss: 44.836380\n",
      "bce: 37.708176, kld: 0.028513\n",
      "Train Epoch: 127 [20480/22533 (91%)]      Loss: 45.103191\n",
      "bce: 38.029587, kld: 0.028294\n",
      "====> Epoch: 127 Average loss: 45.2665, bce: 38.1364, kld: 0.0285\n",
      "Train Epoch: 128 [   0/22533 ( 0%)]      Loss: 45.040131\n",
      "bce: 37.993057, kld: 0.028188\n",
      "Train Epoch: 128 [10240/22533 (45%)]      Loss: 45.604790\n",
      "bce: 38.575066, kld: 0.028119\n",
      "Train Epoch: 128 [20480/22533 (91%)]      Loss: 44.671276\n",
      "bce: 37.722977, kld: 0.027793\n",
      "====> Epoch: 128 Average loss: 44.9702, bce: 37.9605, kld: 0.0280\n",
      "Train Epoch: 129 [   0/22533 ( 0%)]      Loss: 45.168633\n",
      "bce: 38.241646, kld: 0.027708\n",
      "Train Epoch: 129 [10240/22533 (45%)]      Loss: 44.890415\n",
      "bce: 37.999657, kld: 0.027563\n",
      "Train Epoch: 129 [20480/22533 (91%)]      Loss: 43.959770\n",
      "bce: 37.142632, kld: 0.027269\n",
      "====> Epoch: 129 Average loss: 44.6941, bce: 37.7993, kld: 0.0276\n",
      "Train Epoch: 130 [   0/22533 ( 0%)]      Loss: 44.396523\n",
      "bce: 37.565418, kld: 0.027324\n",
      "Train Epoch: 130 [10240/22533 (45%)]      Loss: 44.501534\n",
      "bce: 37.698681, kld: 0.027211\n",
      "Train Epoch: 130 [20480/22533 (91%)]      Loss: 44.532303\n",
      "bce: 37.793701, kld: 0.026954\n",
      "====> Epoch: 130 Average loss: 44.4045, bce: 37.6278, kld: 0.0271\n",
      "====> Testing Average Loss: 22.751683988483556\n",
      "Train Epoch: 131 [   0/22533 ( 0%)]      Loss: 44.121841\n",
      "bce: 37.400192, kld: 0.026887\n",
      "Train Epoch: 131 [10240/22533 (45%)]      Loss: 44.432014\n",
      "bce: 37.762245, kld: 0.026679\n",
      "Train Epoch: 131 [20480/22533 (91%)]      Loss: 44.006916\n",
      "bce: 37.359436, kld: 0.026590\n",
      "====> Epoch: 131 Average loss: 44.1353, bce: 37.4684, kld: 0.0267\n",
      "Train Epoch: 132 [   0/22533 ( 0%)]      Loss: 44.082134\n",
      "bce: 37.490189, kld: 0.026368\n",
      "Train Epoch: 132 [10240/22533 (45%)]      Loss: 44.011372\n",
      "bce: 37.449768, kld: 0.026246\n",
      "Train Epoch: 132 [20480/22533 (91%)]      Loss: 43.665161\n",
      "bce: 37.139244, kld: 0.026104\n",
      "====> Epoch: 132 Average loss: 43.8616, bce: 37.3054, kld: 0.0262\n",
      "Train Epoch: 133 [   0/22533 ( 0%)]      Loss: 44.163166\n",
      "bce: 37.667366, kld: 0.025983\n",
      "Train Epoch: 133 [10240/22533 (45%)]      Loss: 44.319500\n",
      "bce: 37.859138, kld: 0.025841\n",
      "Train Epoch: 133 [20480/22533 (91%)]      Loss: 43.057743\n",
      "bce: 36.651985, kld: 0.025623\n",
      "====> Epoch: 133 Average loss: 43.5889, bce: 37.1411, kld: 0.0258\n",
      "Train Epoch: 134 [   0/22533 ( 0%)]      Loss: 43.713451\n",
      "bce: 37.312874, kld: 0.025602\n",
      "Train Epoch: 134 [10240/22533 (45%)]      Loss: 44.060448\n",
      "bce: 37.732738, kld: 0.025311\n",
      "Train Epoch: 134 [20480/22533 (91%)]      Loss: 43.541389\n",
      "bce: 37.242786, kld: 0.025194\n",
      "====> Epoch: 134 Average loss: 43.3239, bce: 36.9814, kld: 0.0254\n",
      "Train Epoch: 135 [   0/22533 ( 0%)]      Loss: 42.851635\n",
      "bce: 36.591434, kld: 0.025041\n",
      "Train Epoch: 135 [10240/22533 (45%)]      Loss: 42.357948\n",
      "bce: 36.100571, kld: 0.025030\n",
      "Train Epoch: 135 [20480/22533 (91%)]      Loss: 42.195393\n",
      "bce: 36.020050, kld: 0.024701\n",
      "====> Epoch: 135 Average loss: 43.0668, bce: 36.8252, kld: 0.0250\n",
      "====> Testing Average Loss: 21.94219727732659\n",
      "Train Epoch: 136 [   0/22533 ( 0%)]      Loss: 43.073757\n",
      "bce: 36.888119, kld: 0.024743\n",
      "Train Epoch: 136 [10240/22533 (45%)]      Loss: 42.785690\n",
      "bce: 36.656540, kld: 0.024517\n",
      "Train Epoch: 136 [20480/22533 (91%)]      Loss: 42.525490\n",
      "bce: 36.430370, kld: 0.024380\n",
      "====> Epoch: 136 Average loss: 42.8092, bce: 36.6679, kld: 0.0246\n",
      "Train Epoch: 137 [   0/22533 ( 0%)]      Loss: 42.618614\n",
      "bce: 36.540543, kld: 0.024312\n",
      "Train Epoch: 137 [10240/22533 (45%)]      Loss: 42.680580\n",
      "bce: 36.644688, kld: 0.024144\n",
      "Train Epoch: 137 [20480/22533 (91%)]      Loss: 42.368431\n",
      "bce: 36.383965, kld: 0.023938\n",
      "====> Epoch: 137 Average loss: 42.5589, bce: 36.5144, kld: 0.0242\n",
      "Train Epoch: 138 [   0/22533 ( 0%)]      Loss: 42.913395\n",
      "bce: 36.927822, kld: 0.023942\n",
      "Train Epoch: 138 [10240/22533 (45%)]      Loss: 42.134857\n",
      "bce: 36.206875, kld: 0.023712\n",
      "Train Epoch: 138 [20480/22533 (91%)]      Loss: 41.954258\n",
      "bce: 36.058441, kld: 0.023583\n",
      "====> Epoch: 138 Average loss: 42.3137, bce: 36.3656, kld: 0.0238\n",
      "Train Epoch: 139 [   0/22533 ( 0%)]      Loss: 42.880241\n",
      "bce: 36.982586, kld: 0.023591\n",
      "Train Epoch: 139 [10240/22533 (45%)]      Loss: 41.637405\n",
      "bce: 35.803181, kld: 0.023337\n",
      "Train Epoch: 139 [20480/22533 (91%)]      Loss: 42.583626\n",
      "bce: 36.770546, kld: 0.023252\n",
      "====> Epoch: 139 Average loss: 42.0689, bce: 36.2122, kld: 0.0234\n",
      "Train Epoch: 140 [   0/22533 ( 0%)]      Loss: 42.000175\n",
      "bce: 36.199268, kld: 0.023204\n",
      "Train Epoch: 140 [10240/22533 (45%)]      Loss: 42.018295\n",
      "bce: 36.257347, kld: 0.023044\n",
      "Train Epoch: 140 [20480/22533 (91%)]      Loss: 41.862610\n",
      "bce: 36.103054, kld: 0.023038\n",
      "====> Epoch: 140 Average loss: 41.8164, bce: 36.0506, kld: 0.0231\n",
      "====> Testing Average Loss: 21.381351621788045\n",
      "Train Epoch: 141 [   0/22533 ( 0%)]      Loss: 41.722099\n",
      "bce: 36.013058, kld: 0.022836\n",
      "Train Epoch: 141 [10240/22533 (45%)]      Loss: 41.182034\n",
      "bce: 35.536469, kld: 0.022582\n",
      "Train Epoch: 141 [20480/22533 (91%)]      Loss: 41.599548\n",
      "bce: 35.966450, kld: 0.022532\n",
      "====> Epoch: 141 Average loss: 41.5795, bce: 35.9046, kld: 0.0227\n",
      "Train Epoch: 142 [   0/22533 ( 0%)]      Loss: 41.465996\n",
      "bce: 35.823765, kld: 0.022569\n",
      "Train Epoch: 142 [10240/22533 (45%)]      Loss: 40.933083\n",
      "bce: 35.349689, kld: 0.022334\n",
      "Train Epoch: 142 [20480/22533 (91%)]      Loss: 40.760509\n",
      "bce: 35.218296, kld: 0.022169\n",
      "====> Epoch: 142 Average loss: 41.3464, bce: 35.7596, kld: 0.0223\n",
      "Train Epoch: 143 [   0/22533 ( 0%)]      Loss: 41.199303\n",
      "bce: 35.659584, kld: 0.022159\n",
      "Train Epoch: 143 [10240/22533 (45%)]      Loss: 41.338203\n",
      "bce: 35.822109, kld: 0.022064\n",
      "Train Epoch: 143 [20480/22533 (91%)]      Loss: 41.136230\n",
      "bce: 35.684120, kld: 0.021808\n",
      "====> Epoch: 143 Average loss: 41.1035, bce: 35.6024, kld: 0.0220\n",
      "Train Epoch: 144 [   0/22533 ( 0%)]      Loss: 41.813717\n",
      "bce: 36.349430, kld: 0.021857\n",
      "Train Epoch: 144 [10240/22533 (45%)]      Loss: 41.175770\n",
      "bce: 35.746590, kld: 0.021717\n",
      "Train Epoch: 144 [20480/22533 (91%)]      Loss: 40.742317\n",
      "bce: 35.348045, kld: 0.021577\n",
      "====> Epoch: 144 Average loss: 40.8808, bce: 35.4633, kld: 0.0217\n",
      "Train Epoch: 145 [   0/22533 ( 0%)]      Loss: 40.863056\n",
      "bce: 35.498741, kld: 0.021457\n",
      "Train Epoch: 145 [10240/22533 (45%)]      Loss: 40.929703\n",
      "bce: 35.581760, kld: 0.021392\n",
      "Train Epoch: 145 [20480/22533 (91%)]      Loss: 40.573254\n",
      "bce: 35.272339, kld: 0.021204\n",
      "====> Epoch: 145 Average loss: 40.6598, bce: 35.3238, kld: 0.0213\n",
      "====> Testing Average Loss: 20.7080734714086\n",
      "Train Epoch: 146 [   0/22533 ( 0%)]      Loss: 39.965660\n",
      "bce: 34.707783, kld: 0.021032\n",
      "Train Epoch: 146 [10240/22533 (45%)]      Loss: 40.154457\n",
      "bce: 34.892105, kld: 0.021049\n",
      "Train Epoch: 146 [20480/22533 (91%)]      Loss: 40.663944\n",
      "bce: 35.441376, kld: 0.020890\n",
      "====> Epoch: 146 Average loss: 40.4307, bce: 35.1746, kld: 0.0210\n",
      "Train Epoch: 147 [   0/22533 ( 0%)]      Loss: 39.941261\n",
      "bce: 34.718033, kld: 0.020893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [10240/22533 (45%)]      Loss: 39.984142\n",
      "bce: 34.788277, kld: 0.020783\n",
      "Train Epoch: 147 [20480/22533 (91%)]      Loss: 39.901550\n",
      "bce: 34.770584, kld: 0.020524\n",
      "====> Epoch: 147 Average loss: 40.2108, bce: 35.0347, kld: 0.0207\n",
      "Train Epoch: 148 [   0/22533 ( 0%)]      Loss: 40.044472\n",
      "bce: 34.926903, kld: 0.020470\n",
      "Train Epoch: 148 [10240/22533 (45%)]      Loss: 40.418228\n",
      "bce: 35.340324, kld: 0.020312\n",
      "Train Epoch: 148 [20480/22533 (91%)]      Loss: 39.234688\n",
      "bce: 34.164291, kld: 0.020282\n",
      "====> Epoch: 148 Average loss: 39.9970, bce: 34.8974, kld: 0.0204\n",
      "Train Epoch: 149 [   0/22533 ( 0%)]      Loss: 40.196091\n",
      "bce: 35.146515, kld: 0.020198\n",
      "Train Epoch: 149 [10240/22533 (45%)]      Loss: 39.989040\n",
      "bce: 34.966728, kld: 0.020089\n",
      "Train Epoch: 149 [20480/22533 (91%)]      Loss: 39.312351\n",
      "bce: 34.315742, kld: 0.019986\n",
      "====> Epoch: 149 Average loss: 39.7793, bce: 34.7550, kld: 0.0201\n",
      "Train Epoch: 150 [   0/22533 ( 0%)]      Loss: 39.987705\n",
      "bce: 34.994873, kld: 0.019971\n",
      "Train Epoch: 150 [10240/22533 (45%)]      Loss: 39.557274\n",
      "bce: 34.606094, kld: 0.019805\n",
      "Train Epoch: 150 [20480/22533 (91%)]      Loss: 39.544853\n",
      "bce: 34.605434, kld: 0.019758\n",
      "====> Epoch: 150 Average loss: 39.5714, bce: 34.6201, kld: 0.0198\n",
      "====> Testing Average Loss: 20.25917716515777\n",
      "Train Epoch: 151 [   0/22533 ( 0%)]      Loss: 39.061333\n",
      "bce: 34.179104, kld: 0.019529\n",
      "Train Epoch: 151 [10240/22533 (45%)]      Loss: 38.883953\n",
      "bce: 34.000034, kld: 0.019536\n",
      "Train Epoch: 151 [20480/22533 (91%)]      Loss: 40.226421\n",
      "bce: 35.364136, kld: 0.019449\n",
      "====> Epoch: 151 Average loss: 39.3730, bce: 34.4940, kld: 0.0195\n",
      "Train Epoch: 152 [   0/22533 ( 0%)]      Loss: 38.652405\n",
      "bce: 33.811810, kld: 0.019362\n",
      "Train Epoch: 152 [10240/22533 (45%)]      Loss: 39.384270\n",
      "bce: 34.573044, kld: 0.019245\n",
      "Train Epoch: 152 [20480/22533 (91%)]      Loss: 38.825211\n",
      "bce: 34.028915, kld: 0.019185\n",
      "====> Epoch: 152 Average loss: 39.1564, bce: 34.3483, kld: 0.0192\n",
      "Train Epoch: 153 [   0/22533 ( 0%)]      Loss: 39.815292\n",
      "bce: 35.038593, kld: 0.019107\n",
      "Train Epoch: 153 [10240/22533 (45%)]      Loss: 38.395187\n",
      "bce: 33.662800, kld: 0.018930\n",
      "Train Epoch: 153 [20480/22533 (91%)]      Loss: 38.644630\n",
      "bce: 33.944347, kld: 0.018801\n",
      "====> Epoch: 153 Average loss: 38.9621, bce: 34.2249, kld: 0.0189\n",
      "Train Epoch: 154 [   0/22533 ( 0%)]      Loss: 38.700111\n",
      "bce: 34.009018, kld: 0.018764\n",
      "Train Epoch: 154 [10240/22533 (45%)]      Loss: 38.770931\n",
      "bce: 34.072693, kld: 0.018793\n",
      "Train Epoch: 154 [20480/22533 (91%)]      Loss: 38.723785\n",
      "bce: 34.072273, kld: 0.018606\n",
      "====> Epoch: 154 Average loss: 38.7508, bce: 34.0820, kld: 0.0187\n",
      "Train Epoch: 155 [   0/22533 ( 0%)]      Loss: 38.325157\n",
      "bce: 33.701546, kld: 0.018494\n",
      "Train Epoch: 155 [10240/22533 (45%)]      Loss: 38.949642\n",
      "bce: 34.333767, kld: 0.018464\n",
      "Train Epoch: 155 [20480/22533 (91%)]      Loss: 37.981937\n",
      "bce: 33.423321, kld: 0.018234\n",
      "====> Epoch: 155 Average loss: 38.5599, bce: 33.9563, kld: 0.0184\n",
      "====> Testing Average Loss: 19.64697610171748\n",
      "Train Epoch: 156 [   0/22533 ( 0%)]      Loss: 38.493126\n",
      "bce: 33.910526, kld: 0.018330\n",
      "Train Epoch: 156 [10240/22533 (45%)]      Loss: 38.516491\n",
      "bce: 33.950809, kld: 0.018263\n",
      "Train Epoch: 156 [20480/22533 (91%)]      Loss: 38.325138\n",
      "bce: 33.812290, kld: 0.018051\n",
      "====> Epoch: 156 Average loss: 38.3742, bce: 33.8365, kld: 0.0182\n",
      "Train Epoch: 157 [   0/22533 ( 0%)]      Loss: 38.570995\n",
      "bce: 34.050907, kld: 0.018080\n",
      "Train Epoch: 157 [10240/22533 (45%)]      Loss: 37.909489\n",
      "bce: 33.435463, kld: 0.017896\n",
      "Train Epoch: 157 [20480/22533 (91%)]      Loss: 37.746593\n",
      "bce: 33.309551, kld: 0.017748\n",
      "====> Epoch: 157 Average loss: 38.1849, bce: 33.7090, kld: 0.0179\n",
      "Train Epoch: 158 [   0/22533 ( 0%)]      Loss: 38.354317\n",
      "bce: 33.886826, kld: 0.017870\n",
      "Train Epoch: 158 [10240/22533 (45%)]      Loss: 38.343266\n",
      "bce: 33.929192, kld: 0.017656\n",
      "Train Epoch: 158 [20480/22533 (91%)]      Loss: 38.567574\n",
      "bce: 34.204681, kld: 0.017452\n",
      "====> Epoch: 158 Average loss: 37.9834, bce: 33.5723, kld: 0.0176\n",
      "Train Epoch: 159 [   0/22533 ( 0%)]      Loss: 37.773487\n",
      "bce: 33.397957, kld: 0.017502\n",
      "Train Epoch: 159 [10240/22533 (45%)]      Loss: 37.763443\n",
      "bce: 33.407814, kld: 0.017423\n",
      "Train Epoch: 159 [20480/22533 (91%)]      Loss: 37.643547\n",
      "bce: 33.324844, kld: 0.017275\n",
      "====> Epoch: 159 Average loss: 37.7976, bce: 33.4486, kld: 0.0174\n",
      "Train Epoch: 160 [   0/22533 ( 0%)]      Loss: 37.459766\n",
      "bce: 33.140129, kld: 0.017279\n",
      "Train Epoch: 160 [10240/22533 (45%)]      Loss: 37.691872\n",
      "bce: 33.401413, kld: 0.017162\n",
      "Train Epoch: 160 [20480/22533 (91%)]      Loss: 37.576298\n",
      "bce: 33.326496, kld: 0.016999\n",
      "====> Epoch: 160 Average loss: 37.6176, bce: 33.3279, kld: 0.0172\n",
      "====> Testing Average Loss: 19.279938382039674\n",
      "Train Epoch: 161 [   0/22533 ( 0%)]      Loss: 38.120716\n",
      "bce: 33.858894, kld: 0.017047\n",
      "Train Epoch: 161 [10240/22533 (45%)]      Loss: 37.348640\n",
      "bce: 33.125706, kld: 0.016892\n",
      "Train Epoch: 161 [20480/22533 (91%)]      Loss: 37.580402\n",
      "bce: 33.373367, kld: 0.016828\n",
      "====> Epoch: 161 Average loss: 37.4379, bce: 33.2087, kld: 0.0169\n",
      "Train Epoch: 162 [   0/22533 ( 0%)]      Loss: 37.453568\n",
      "bce: 33.266006, kld: 0.016750\n",
      "Train Epoch: 162 [10240/22533 (45%)]      Loss: 37.109825\n",
      "bce: 32.923660, kld: 0.016745\n",
      "Train Epoch: 162 [20480/22533 (91%)]      Loss: 37.608139\n",
      "bce: 33.475204, kld: 0.016532\n",
      "====> Epoch: 162 Average loss: 37.2386, bce: 33.0678, kld: 0.0167\n",
      "Train Epoch: 163 [   0/22533 ( 0%)]      Loss: 36.646641\n",
      "bce: 32.500847, kld: 0.016583\n",
      "Train Epoch: 163 [10240/22533 (45%)]      Loss: 37.224358\n",
      "bce: 33.111748, kld: 0.016450\n",
      "Train Epoch: 163 [20480/22533 (91%)]      Loss: 37.652634\n",
      "bce: 33.565853, kld: 0.016347\n",
      "====> Epoch: 163 Average loss: 37.0740, bce: 32.9603, kld: 0.0165\n",
      "Train Epoch: 164 [   0/22533 ( 0%)]      Loss: 37.268532\n",
      "bce: 33.182617, kld: 0.016344\n",
      "Train Epoch: 164 [10240/22533 (45%)]      Loss: 37.167713\n",
      "bce: 33.105873, kld: 0.016247\n",
      "Train Epoch: 164 [20480/22533 (91%)]      Loss: 36.745869\n",
      "bce: 32.720284, kld: 0.016102\n",
      "====> Epoch: 164 Average loss: 36.9080, bce: 32.8493, kld: 0.0162\n",
      "Train Epoch: 165 [   0/22533 ( 0%)]      Loss: 37.209835\n",
      "bce: 33.154816, kld: 0.016220\n",
      "Train Epoch: 165 [10240/22533 (45%)]      Loss: 36.226974\n",
      "bce: 32.228088, kld: 0.015996\n",
      "Train Epoch: 165 [20480/22533 (91%)]      Loss: 36.652897\n",
      "bce: 32.680492, kld: 0.015890\n",
      "====> Epoch: 165 Average loss: 36.7308, bce: 32.7258, kld: 0.0160\n",
      "====> Testing Average Loss: 18.73511402027027\n",
      "Train Epoch: 166 [   0/22533 ( 0%)]      Loss: 36.777653\n",
      "bce: 32.794014, kld: 0.015935\n",
      "Train Epoch: 166 [10240/22533 (45%)]      Loss: 36.334236\n",
      "bce: 32.385387, kld: 0.015795\n",
      "Train Epoch: 166 [20480/22533 (91%)]      Loss: 36.451649\n",
      "bce: 32.533470, kld: 0.015673\n",
      "====> Epoch: 166 Average loss: 36.5516, bce: 32.6002, kld: 0.0158\n",
      "Train Epoch: 167 [   0/22533 ( 0%)]      Loss: 36.715633\n",
      "bce: 32.789383, kld: 0.015705\n",
      "Train Epoch: 167 [10240/22533 (45%)]      Loss: 35.884552\n",
      "bce: 31.989178, kld: 0.015582\n",
      "Train Epoch: 167 [20480/22533 (91%)]      Loss: 36.266045\n",
      "bce: 32.391586, kld: 0.015498\n",
      "====> Epoch: 167 Average loss: 36.3789, bce: 32.4827, kld: 0.0156\n",
      "Train Epoch: 168 [   0/22533 ( 0%)]      Loss: 35.874886\n",
      "bce: 32.001038, kld: 0.015495\n",
      "Train Epoch: 168 [10240/22533 (45%)]      Loss: 35.891399\n",
      "bce: 32.054581, kld: 0.015347\n",
      "Train Epoch: 168 [20480/22533 (91%)]      Loss: 36.030403\n",
      "bce: 32.194569, kld: 0.015343\n",
      "====> Epoch: 168 Average loss: 36.2104, bce: 32.3649, kld: 0.0154\n",
      "Train Epoch: 169 [   0/22533 ( 0%)]      Loss: 35.657990\n",
      "bce: 31.839905, kld: 0.015272\n",
      "Train Epoch: 169 [10240/22533 (45%)]      Loss: 36.586449\n",
      "bce: 32.775326, kld: 0.015244\n",
      "Train Epoch: 169 [20480/22533 (91%)]      Loss: 35.793255\n",
      "bce: 32.033722, kld: 0.015038\n",
      "====> Epoch: 169 Average loss: 36.0451, bce: 32.2503, kld: 0.0152\n",
      "Train Epoch: 170 [   0/22533 ( 0%)]      Loss: 36.028290\n",
      "bce: 32.234818, kld: 0.015174\n",
      "Train Epoch: 170 [10240/22533 (45%)]      Loss: 36.194672\n",
      "bce: 32.456306, kld: 0.014953\n",
      "Train Epoch: 170 [20480/22533 (91%)]      Loss: 35.682076\n",
      "bce: 31.974632, kld: 0.014830\n",
      "====> Epoch: 170 Average loss: 35.8874, bce: 32.1430, kld: 0.0150\n",
      "====> Testing Average Loss: 18.244001506124352\n",
      "Train Epoch: 171 [   0/22533 ( 0%)]      Loss: 35.654869\n",
      "bce: 31.936188, kld: 0.014875\n",
      "Train Epoch: 171 [10240/22533 (45%)]      Loss: 35.402607\n",
      "bce: 31.711275, kld: 0.014765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171 [20480/22533 (91%)]      Loss: 36.396389\n",
      "bce: 32.736496, kld: 0.014640\n",
      "====> Epoch: 171 Average loss: 35.7205, bce: 32.0256, kld: 0.0148\n",
      "Train Epoch: 172 [   0/22533 ( 0%)]      Loss: 36.042801\n",
      "bce: 32.369720, kld: 0.014692\n",
      "Train Epoch: 172 [10240/22533 (45%)]      Loss: 35.190315\n",
      "bce: 31.547113, kld: 0.014573\n",
      "Train Epoch: 172 [20480/22533 (91%)]      Loss: 35.292267\n",
      "bce: 31.650080, kld: 0.014569\n",
      "====> Epoch: 172 Average loss: 35.5741, bce: 31.9254, kld: 0.0146\n",
      "Train Epoch: 173 [   0/22533 ( 0%)]      Loss: 35.421970\n",
      "bce: 31.812759, kld: 0.014437\n",
      "Train Epoch: 173 [10240/22533 (45%)]      Loss: 35.022026\n",
      "bce: 31.407890, kld: 0.014457\n",
      "Train Epoch: 173 [20480/22533 (91%)]      Loss: 35.135757\n",
      "bce: 31.566669, kld: 0.014276\n",
      "====> Epoch: 173 Average loss: 35.4114, bce: 31.8101, kld: 0.0144\n",
      "Train Epoch: 174 [   0/22533 ( 0%)]      Loss: 34.988781\n",
      "bce: 31.408916, kld: 0.014319\n",
      "Train Epoch: 174 [10240/22533 (45%)]      Loss: 35.656898\n",
      "bce: 32.107948, kld: 0.014196\n",
      "Train Epoch: 174 [20480/22533 (91%)]      Loss: 35.413139\n",
      "bce: 31.881327, kld: 0.014127\n",
      "====> Epoch: 174 Average loss: 35.2508, bce: 31.6957, kld: 0.0142\n",
      "Train Epoch: 175 [   0/22533 ( 0%)]      Loss: 35.505924\n",
      "bce: 31.981348, kld: 0.014098\n",
      "Train Epoch: 175 [10240/22533 (45%)]      Loss: 35.114475\n",
      "bce: 31.600004, kld: 0.014058\n",
      "Train Epoch: 175 [20480/22533 (91%)]      Loss: 34.982483\n",
      "bce: 31.509193, kld: 0.013893\n",
      "====> Epoch: 175 Average loss: 35.0859, bce: 31.5781, kld: 0.0140\n",
      "====> Testing Average Loss: 17.792510567833844\n",
      "Train Epoch: 176 [   0/22533 ( 0%)]      Loss: 35.271530\n",
      "bce: 31.776714, kld: 0.013979\n",
      "Train Epoch: 176 [10240/22533 (45%)]      Loss: 35.017761\n",
      "bce: 31.556889, kld: 0.013843\n",
      "Train Epoch: 176 [20480/22533 (91%)]      Loss: 34.998222\n",
      "bce: 31.560539, kld: 0.013751\n",
      "====> Epoch: 176 Average loss: 34.9302, bce: 31.4675, kld: 0.0139\n",
      "Train Epoch: 177 [   0/22533 ( 0%)]      Loss: 34.186531\n",
      "bce: 30.734097, kld: 0.013810\n",
      "Train Epoch: 177 [10240/22533 (45%)]      Loss: 35.018761\n",
      "bce: 31.603619, kld: 0.013661\n",
      "Train Epoch: 177 [20480/22533 (91%)]      Loss: 34.226902\n",
      "bce: 30.824295, kld: 0.013610\n",
      "====> Epoch: 177 Average loss: 34.7964, bce: 31.3737, kld: 0.0137\n",
      "Train Epoch: 178 [   0/22533 ( 0%)]      Loss: 34.522354\n",
      "bce: 31.128643, kld: 0.013575\n",
      "Train Epoch: 178 [10240/22533 (45%)]      Loss: 34.204983\n",
      "bce: 30.815556, kld: 0.013558\n",
      "Train Epoch: 178 [20480/22533 (91%)]      Loss: 34.356098\n",
      "bce: 31.005096, kld: 0.013404\n",
      "====> Epoch: 178 Average loss: 34.6325, bce: 31.2544, kld: 0.0135\n",
      "Train Epoch: 179 [   0/22533 ( 0%)]      Loss: 34.400967\n",
      "bce: 31.051502, kld: 0.013398\n",
      "Train Epoch: 179 [10240/22533 (45%)]      Loss: 34.313786\n",
      "bce: 30.987968, kld: 0.013303\n",
      "Train Epoch: 179 [20480/22533 (91%)]      Loss: 34.687378\n",
      "bce: 31.368681, kld: 0.013275\n",
      "====> Epoch: 179 Average loss: 34.4768, bce: 31.1446, kld: 0.0133\n",
      "Train Epoch: 180 [   0/22533 ( 0%)]      Loss: 34.234394\n",
      "bce: 30.916597, kld: 0.013271\n",
      "Train Epoch: 180 [10240/22533 (45%)]      Loss: 34.268227\n",
      "bce: 30.967690, kld: 0.013202\n",
      "Train Epoch: 180 [20480/22533 (91%)]      Loss: 33.621017\n",
      "bce: 30.350580, kld: 0.013082\n",
      "====> Epoch: 180 Average loss: 34.3407, bce: 31.0490, kld: 0.0132\n",
      "====> Testing Average Loss: 17.438435086872587\n",
      "Train Epoch: 181 [   0/22533 ( 0%)]      Loss: 34.128895\n",
      "bce: 30.857330, kld: 0.013086\n",
      "Train Epoch: 181 [10240/22533 (45%)]      Loss: 34.140743\n",
      "bce: 30.878736, kld: 0.013048\n",
      "Train Epoch: 181 [20480/22533 (91%)]      Loss: 34.320110\n",
      "bce: 31.068279, kld: 0.013007\n",
      "====> Epoch: 181 Average loss: 34.2042, bce: 30.9520, kld: 0.0130\n",
      "Train Epoch: 182 [   0/22533 ( 0%)]      Loss: 34.198414\n",
      "bce: 30.944580, kld: 0.013015\n",
      "Train Epoch: 182 [10240/22533 (45%)]      Loss: 33.794033\n",
      "bce: 30.589752, kld: 0.012817\n",
      "Train Epoch: 182 [20480/22533 (91%)]      Loss: 33.831963\n",
      "bce: 30.645103, kld: 0.012747\n",
      "====> Epoch: 182 Average loss: 34.0452, bce: 30.8324, kld: 0.0129\n",
      "Train Epoch: 183 [   0/22533 ( 0%)]      Loss: 33.190113\n",
      "bce: 29.982952, kld: 0.012829\n",
      "Train Epoch: 183 [10240/22533 (45%)]      Loss: 33.990337\n",
      "bce: 30.814957, kld: 0.012702\n",
      "Train Epoch: 183 [20480/22533 (91%)]      Loss: 33.647713\n",
      "bce: 30.499008, kld: 0.012595\n",
      "====> Epoch: 183 Average loss: 33.9130, bce: 30.7399, kld: 0.0127\n",
      "Train Epoch: 184 [   0/22533 ( 0%)]      Loss: 34.053406\n",
      "bce: 30.892229, kld: 0.012645\n",
      "Train Epoch: 184 [10240/22533 (45%)]      Loss: 34.404854\n",
      "bce: 31.276638, kld: 0.012513\n",
      "Train Epoch: 184 [20480/22533 (91%)]      Loss: 33.748787\n",
      "bce: 30.603882, kld: 0.012580\n",
      "====> Epoch: 184 Average loss: 33.7774, bce: 30.6408, kld: 0.0125\n",
      "Train Epoch: 185 [   0/22533 ( 0%)]      Loss: 34.005482\n",
      "bce: 30.890694, kld: 0.012459\n",
      "Train Epoch: 185 [10240/22533 (45%)]      Loss: 33.505295\n",
      "bce: 30.396927, kld: 0.012433\n",
      "Train Epoch: 185 [20480/22533 (91%)]      Loss: 33.605259\n",
      "bce: 30.529137, kld: 0.012304\n",
      "====> Epoch: 185 Average loss: 33.6371, bce: 30.5392, kld: 0.0124\n",
      "====> Testing Average Loss: 16.87779693948875\n",
      "Train Epoch: 186 [   0/22533 ( 0%)]      Loss: 33.794094\n",
      "bce: 30.716484, kld: 0.012310\n",
      "Train Epoch: 186 [10240/22533 (45%)]      Loss: 33.112026\n",
      "bce: 30.046686, kld: 0.012261\n",
      "Train Epoch: 186 [20480/22533 (91%)]      Loss: 33.358498\n",
      "bce: 30.317104, kld: 0.012166\n",
      "====> Epoch: 186 Average loss: 33.5048, bce: 30.4411, kld: 0.0123\n",
      "Train Epoch: 187 [   0/22533 ( 0%)]      Loss: 33.380733\n",
      "bce: 30.339834, kld: 0.012164\n",
      "Train Epoch: 187 [10240/22533 (45%)]      Loss: 33.404083\n",
      "bce: 30.399845, kld: 0.012017\n",
      "Train Epoch: 187 [20480/22533 (91%)]      Loss: 34.082623\n",
      "bce: 31.050760, kld: 0.012127\n",
      "====> Epoch: 187 Average loss: 33.3658, bce: 30.3387, kld: 0.0121\n",
      "Train Epoch: 188 [   0/22533 ( 0%)]      Loss: 33.188843\n",
      "bce: 30.187080, kld: 0.012007\n",
      "Train Epoch: 188 [10240/22533 (45%)]      Loss: 33.129307\n",
      "bce: 30.118397, kld: 0.012044\n",
      "Train Epoch: 188 [20480/22533 (91%)]      Loss: 33.191296\n",
      "bce: 30.212662, kld: 0.011915\n",
      "====> Epoch: 188 Average loss: 33.2342, bce: 30.2401, kld: 0.0120\n",
      "Train Epoch: 189 [   0/22533 ( 0%)]      Loss: 33.045094\n",
      "bce: 30.075127, kld: 0.011880\n",
      "Train Epoch: 189 [10240/22533 (45%)]      Loss: 33.390526\n",
      "bce: 30.433319, kld: 0.011829\n",
      "Train Epoch: 189 [20480/22533 (91%)]      Loss: 33.287579\n",
      "bce: 30.348597, kld: 0.011756\n",
      "====> Epoch: 189 Average loss: 33.1088, bce: 30.1519, kld: 0.0118\n",
      "Train Epoch: 190 [   0/22533 ( 0%)]      Loss: 33.284626\n",
      "bce: 30.329533, kld: 0.011820\n",
      "Train Epoch: 190 [10240/22533 (45%)]      Loss: 33.153637\n",
      "bce: 30.223650, kld: 0.011720\n",
      "Train Epoch: 190 [20480/22533 (91%)]      Loss: 32.795044\n",
      "bce: 29.905563, kld: 0.011558\n",
      "====> Epoch: 190 Average loss: 32.9936, bce: 30.0701, kld: 0.0117\n",
      "====> Testing Average Loss: 16.718428076321395\n",
      "Train Epoch: 191 [   0/22533 ( 0%)]      Loss: 32.258461\n",
      "bce: 29.364637, kld: 0.011575\n",
      "Train Epoch: 191 [10240/22533 (45%)]      Loss: 32.874794\n",
      "bce: 29.983002, kld: 0.011567\n",
      "Train Epoch: 191 [20480/22533 (91%)]      Loss: 33.173088\n",
      "bce: 30.296673, kld: 0.011506\n",
      "====> Epoch: 191 Average loss: 32.8541, bce: 29.9711, kld: 0.0115\n",
      "Train Epoch: 192 [   0/22533 ( 0%)]      Loss: 33.262463\n",
      "bce: 30.388680, kld: 0.011495\n",
      "Train Epoch: 192 [10240/22533 (45%)]      Loss: 32.450665\n",
      "bce: 29.603891, kld: 0.011387\n",
      "Train Epoch: 192 [20480/22533 (91%)]      Loss: 32.517586\n",
      "bce: 29.687748, kld: 0.011319\n",
      "====> Epoch: 192 Average loss: 32.7108, bce: 29.8604, kld: 0.0114\n",
      "Train Epoch: 193 [   0/22533 ( 0%)]      Loss: 32.116043\n",
      "bce: 29.281796, kld: 0.011337\n",
      "Train Epoch: 193 [10240/22533 (45%)]      Loss: 32.809612\n",
      "bce: 29.998516, kld: 0.011244\n",
      "Train Epoch: 193 [20480/22533 (91%)]      Loss: 32.141911\n",
      "bce: 29.342840, kld: 0.011196\n",
      "====> Epoch: 193 Average loss: 32.5826, bce: 29.7607, kld: 0.0113\n",
      "Train Epoch: 194 [   0/22533 ( 0%)]      Loss: 32.207840\n",
      "bce: 29.423162, kld: 0.011139\n",
      "Train Epoch: 194 [10240/22533 (45%)]      Loss: 32.723896\n",
      "bce: 29.939920, kld: 0.011136\n",
      "Train Epoch: 194 [20480/22533 (91%)]      Loss: 32.408890\n",
      "bce: 29.647903, kld: 0.011044\n",
      "====> Epoch: 194 Average loss: 32.4487, bce: 29.6671, kld: 0.0111\n",
      "Train Epoch: 195 [   0/22533 ( 0%)]      Loss: 31.996880\n",
      "bce: 29.231094, kld: 0.011063\n",
      "Train Epoch: 195 [10240/22533 (45%)]      Loss: 32.326645\n",
      "bce: 29.568670, kld: 0.011032\n",
      "Train Epoch: 195 [20480/22533 (91%)]      Loss: 32.402821\n",
      "bce: 29.667736, kld: 0.010940\n",
      "====> Epoch: 195 Average loss: 32.3327, bce: 29.5766, kld: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Testing Average Loss: 16.237936443216615\n",
      "Train Epoch: 196 [   0/22533 ( 0%)]      Loss: 32.394833\n",
      "bce: 29.660973, kld: 0.010935\n",
      "Train Epoch: 196 [10240/22533 (45%)]      Loss: 32.212982\n",
      "bce: 29.497826, kld: 0.010861\n",
      "Train Epoch: 196 [20480/22533 (91%)]      Loss: 32.201237\n",
      "bce: 29.505865, kld: 0.010781\n",
      "====> Epoch: 196 Average loss: 32.2019, bce: 29.4827, kld: 0.0109\n",
      "Train Epoch: 197 [   0/22533 ( 0%)]      Loss: 32.108986\n",
      "bce: 29.408903, kld: 0.010800\n",
      "Train Epoch: 197 [10240/22533 (45%)]      Loss: 32.083710\n",
      "bce: 29.392910, kld: 0.010763\n",
      "Train Epoch: 197 [20480/22533 (91%)]      Loss: 31.649742\n",
      "bce: 28.975435, kld: 0.010697\n",
      "====> Epoch: 197 Average loss: 32.0820, bce: 29.3919, kld: 0.0108\n",
      "Train Epoch: 198 [   0/22533 ( 0%)]      Loss: 32.545044\n",
      "bce: 29.882505, kld: 0.010650\n",
      "Train Epoch: 198 [10240/22533 (45%)]      Loss: 31.796120\n",
      "bce: 29.146963, kld: 0.010597\n",
      "Train Epoch: 198 [20480/22533 (91%)]      Loss: 32.149544\n",
      "bce: 29.516987, kld: 0.010530\n",
      "====> Epoch: 198 Average loss: 31.9568, bce: 29.3006, kld: 0.0106\n",
      "Train Epoch: 199 [   0/22533 ( 0%)]      Loss: 30.938869\n",
      "bce: 28.305847, kld: 0.010532\n",
      "Train Epoch: 199 [10240/22533 (45%)]      Loss: 31.226910\n",
      "bce: 28.594389, kld: 0.010530\n",
      "Train Epoch: 199 [20480/22533 (91%)]      Loss: 31.914349\n",
      "bce: 29.317904, kld: 0.010386\n",
      "====> Epoch: 199 Average loss: 31.8410, bce: 29.2120, kld: 0.0105\n"
     ]
    }
   ],
   "source": [
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'\n",
    "\n",
    "tg=TrainingSketchRnn(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset,beta=250,linear_hidden_size=[64,32],gru_hidden_size=64)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'sketchrnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
