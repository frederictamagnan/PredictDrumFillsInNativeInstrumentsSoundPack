{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity_metrics\n",
      "(6729, 36)\n",
      "offbeat_notes\n",
      "(6729, 1)\n",
      "bpm\n",
      "(6729, 1)\n",
      "vae_embeddings\n",
      "(6729, 32)\n",
      "genre\n",
      "(6729, 12)\n",
      "dataset\n",
      "(6729, 2)\n",
      "random\n",
      "(6729, 3)\n",
      "fills\n",
      "(6729, 2, 1)\n",
      "drums_pitches_used\n",
      "(6729, 9)\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/ftamagnan/dataset/\"\n",
    "name=\"total_metrics_training.npz\"\n",
    "data=dict(np.load(path+name))\n",
    "\n",
    "data[\"random\"]= np.random.rand(6729,3)\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "    print(data[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity_metrics\n",
      "offbeat_notes\n",
      "drums_pitches_used\n",
      "(6729, 46)\n",
      "(6729,)\n"
     ]
    }
   ],
   "source": [
    "list_x=[]\n",
    "# list_label=['vae_embeddings','offbeat_notes','drums_pitches_used','velocity_metrics']\n",
    "list_label=['vae_embeddings']\n",
    "list_label=['offbeat_notes','drums_pitches_used','velocity_metrics']\n",
    "list_x=[]\n",
    "for key in data.keys():\n",
    "    if key in list_label:\n",
    "        list_x.append(data[key])\n",
    "        print(key)\n",
    "X=np.concatenate(list_x,axis=1)\n",
    "y=data['fills'][:,1].reshape(-1)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.16959660e+01 1.08679830e+02 5.72940552e+01\n",
      " 1.56764331e+01 3.32876858e+01 4.39231423e+01 1.93912951e+01\n",
      " 8.94140127e+00 2.47983015e+01 1.54982634e+01 1.99859049e+01\n",
      " 1.13956130e+01 2.47703127e+00 5.57637415e+00 7.40790570e+00\n",
      " 2.96391829e+00 1.44127922e+00 5.44169562e+00 1.54982634e+01\n",
      " 1.99859049e+01 1.13956130e+01 2.47703127e+00 5.57637415e+00\n",
      " 7.40790570e+00 2.96391829e+00 1.44127922e+00 5.44169562e+00\n",
      " 1.28099788e+01 7.54777070e-01 9.50318471e-01 5.36730361e-01\n",
      " 1.50955414e-01 2.95966030e-01 4.11464968e-01 1.83439490e-01\n",
      " 7.91932059e-02 2.32696391e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegressionCV(cv=2, random_state=0,\n",
    "                           multi_class='ovr',penalty='l2',solver='liblinear',max_iter=300,n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386.0\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "print(y_pred.sum())\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn,fp,fn,tp =  1567 48 66 338\n",
      "Accuracy =  0.9435364041604755\n",
      "Recall =  0.8366336633663366\n",
      "Precision =  0.8756476683937824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp=confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn,fp,fn,tp = \",tn,fp,fn,tp)\n",
    "print(\"Accuracy = \",(tp+tn)/(tn+fp+fn+tp))\n",
    "print(\"Recall = \",(tp)/(fn+tp))\n",
    "print(\"Precision = \",(tp)/(fp+tp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(scaler=True,cv=True):\n",
    "\n",
    "    \n",
    "    list_list_label=[['vae_embeddings','offbeat_notes','drums_pitches_used','velocity_metrics'],\n",
    "                   ['offbeat_notes','drums_pitches_used','velocity_metrics'],\n",
    "                   ['vae_embeddings'],\n",
    "                   ['offbeat_notes'],\n",
    "                   ['drums_pitches_used'],\n",
    "                   ['velocity_metrics'],\n",
    "                     ['drums_pitches_used','velocity_metrics'],\n",
    "                     ['random']\n",
    "]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for list_label in list_list_label:\n",
    "            list_x=[]\n",
    "            for key in data.keys():\n",
    "                if key in list_label:\n",
    "                    list_x.append(data[key])\n",
    "                    print(key)\n",
    "            X=np.concatenate(list_x,axis=1)\n",
    "            y=data['fills'][:,1].reshape(-1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "            if scaler:\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(X_train)\n",
    "                X_train=scaler.transform(X_train)\n",
    "                X_test=scaler.transform(X_test)\n",
    "            \n",
    "            if cv:\n",
    "                clf = LogisticRegressionCV(cv=2, random_state=0,\n",
    "                                   multi_class='ovr',penalty='l2',solver='liblinear',max_iter=300,n_jobs=-1).fit(X_train, y_train)\n",
    "            else:\n",
    "                clf = LogisticRegression(random_state=0,C=100000000).fit(X_train, y_train)\n",
    "\n",
    "            y_pred=clf.predict(X_test)\n",
    "            tn, fp, fn, tp=confusion_matrix(y_test, y_pred).ravel()\n",
    "            print(X_train.shape)\n",
    "            print(\"__________\"+str(list_label)+\"_______\")\n",
    "            print(\"tn,fp,fn,tp = \",tn,fp,fn,tp)\n",
    "            print(\"Accuracy = \",(tp+tn)/(tn+fp+fn+tp))\n",
    "            print(\"Recall = \",(tp)/(fn+tp))\n",
    "            print(\"Precision = \",(tp)/(fp+tp))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity_metrics\n",
      "offbeat_notes\n",
      "vae_embeddings\n",
      "drums_pitches_used\n",
      "(4710, 78)\n",
      "__________['vae_embeddings', 'offbeat_notes', 'drums_pitches_used', 'velocity_metrics']_______\n",
      "tn,fp,fn,tp =  1577 38 62 342\n",
      "Accuracy =  0.9504705299653293\n",
      "Recall =  0.8465346534653465\n",
      "Precision =  0.9\n",
      "velocity_metrics\n",
      "offbeat_notes\n",
      "drums_pitches_used\n",
      "(4710, 46)\n",
      "__________['offbeat_notes', 'drums_pitches_used', 'velocity_metrics']_______\n",
      "tn,fp,fn,tp =  1567 48 67 337\n",
      "Accuracy =  0.9430411094601288\n",
      "Recall =  0.8341584158415841\n",
      "Precision =  0.8753246753246753\n",
      "vae_embeddings\n",
      "(4710, 32)\n",
      "__________['vae_embeddings']_______\n",
      "tn,fp,fn,tp =  1601 14 365 39\n",
      "Accuracy =  0.8122833085685983\n",
      "Recall =  0.09653465346534654\n",
      "Precision =  0.7358490566037735\n",
      "offbeat_notes\n",
      "(4710, 1)\n",
      "__________['offbeat_notes']_______\n",
      "tn,fp,fn,tp =  1614 1 404 0\n",
      "Accuracy =  0.799405646359584\n",
      "Recall =  0.0\n",
      "Precision =  0.0\n",
      "drums_pitches_used\n"
     ]
    }
   ],
   "source": [
    "feature_selection(scaler=True,cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
