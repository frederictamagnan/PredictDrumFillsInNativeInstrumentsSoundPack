{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingGeneratorDnn2 import TrainingGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200\n",
    "local_dataset='/home/ftamagnan/dataset/bigsupervised.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(37555, 2, 16, 9) SHAPE NUMPU\n",
      "37555 LEN DATASET\n",
      "22533 SELF TRAIN\n",
      "7511 SELF validation\n",
      "7511 SELF test\n",
      "139920 PARAMETERS_RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftamagnan/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/TrainingGeneratorDnn2.py:108: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  total_val_loss += val_loss_size.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs  0  : val loss tensor(0.7003, device='cuda:0') training loss 0.7005671696229414\n",
      "(294912,) (294912,)\n",
      "ACC 0.5244547526041666 1 139582\n",
      "None\n",
      "epochs  1  : val loss tensor(0.6995, device='cuda:0') training loss 0.6999660676175897\n",
      "(294912,) (294912,)\n",
      "ACC 0.5266282823350694 1 138999\n",
      "None\n",
      "epochs  2  : val loss tensor(0.6988, device='cuda:0') training loss 0.6992375363003124\n",
      "(294912,) (294912,)\n",
      "ACC 0.5273844401041666 1 138710\n",
      "None\n",
      "epochs  3  : val loss tensor(0.6982, device='cuda:0') training loss 0.6985631530935114\n",
      "(294912,) (294912,)\n",
      "ACC 0.5300530327690972 1 137971\n",
      "None\n",
      "epochs  4  : val loss tensor(0.6977, device='cuda:0') training loss 0.6979740045287393\n",
      "(294912,) (294912,)\n",
      "ACC 0.5284762912326388 1 138674\n",
      "None\n",
      "epochs  5  : val loss tensor(0.6972, device='cuda:0') training loss 0.6974661512808367\n",
      "(294912,) (294912,)\n",
      "ACC 0.5296393500434028 1 138523\n",
      "None\n",
      "epochs  6  : val loss tensor(0.6968, device='cuda:0') training loss 0.6970243074677207\n",
      "(294912,) (294912,)\n",
      "ACC 0.530609130859375 1 138403\n",
      "None\n",
      "epochs  7  : val loss tensor(0.6964, device='cuda:0') training loss 0.6966365359046243\n",
      "(294912,) (294912,)\n",
      "ACC 0.5311143663194444 1 138366\n",
      "None\n",
      "epochs  8  : val loss tensor(0.6961, device='cuda:0') training loss 0.6962935816157948\n",
      "(294912,) (294912,)\n",
      "ACC 0.53118896484375 1 138444\n",
      "None\n",
      "epochs  9  : val loss tensor(0.6958, device='cuda:0') training loss 0.6959863901138306\n",
      "(294912,) (294912,)\n",
      "ACC 0.5325453016493056 1 138144\n",
      "None\n",
      "epochs  10  : val loss tensor(0.6956, device='cuda:0') training loss 0.6957090713761069\n",
      "(294912,) (294912,)\n",
      "ACC 0.5345594618055556 1 137556\n",
      "None\n",
      "epochs  11  : val loss tensor(0.6953, device='cuda:0') training loss 0.695457702333277\n",
      "(294912,) (294912,)\n",
      "ACC 0.5380418565538194 1 136485\n",
      "None\n",
      "epochs  12  : val loss tensor(0.6951, device='cuda:0') training loss 0.6952285766601562\n",
      "(294912,) (294912,)\n",
      "ACC 0.5410800509982638 1 135437\n",
      "None\n",
      "epochs  13  : val loss tensor(0.6949, device='cuda:0') training loss 0.6950189579616893\n",
      "(294912,) (294912,)\n",
      "ACC 0.5447014702690972 1 134209\n",
      "None\n",
      "epochs  14  : val loss tensor(0.6947, device='cuda:0') training loss 0.6948264728892933\n",
      "(294912,) (294912,)\n",
      "ACC 0.5494283040364584 1 132693\n",
      "None\n",
      "epochs  15  : val loss tensor(0.6946, device='cuda:0') training loss 0.6946493658152494\n",
      "(294912,) (294912,)\n",
      "ACC 0.5536566840277778 1 131278\n",
      "None\n",
      "epochs  16  : val loss tensor(0.6944, device='cuda:0') training loss 0.6944866180419922\n",
      "(294912,) (294912,)\n",
      "ACC 0.5595737033420138 1 129257\n",
      "None\n",
      "epochs  17  : val loss tensor(0.6943, device='cuda:0') training loss 0.694336636499925\n",
      "(294912,) (294912,)\n",
      "ACC 0.5673828125 1 126588\n",
      "None\n",
      "epochs  18  : val loss tensor(0.6941, device='cuda:0') training loss 0.6941987817937677\n",
      "(294912,) (294912,)\n",
      "ACC 0.5749749077690972 1 124071\n",
      "None\n",
      "epochs  19  : val loss tensor(0.6940, device='cuda:0') training loss 0.6940722519701178\n",
      "(294912,) (294912,)\n",
      "ACC 0.5855305989583334 1 120536\n",
      "None\n",
      "epochs  20  : val loss tensor(0.6939, device='cuda:0') training loss 0.6939566514708779\n",
      "(294912,) (294912,)\n",
      "ACC 0.6003587510850694 1 115625\n",
      "None\n",
      "epochs  21  : val loss tensor(0.6938, device='cuda:0') training loss 0.6938519261100076\n",
      "(294912,) (294912,)\n",
      "ACC 0.6153021918402778 1 110734\n",
      "None\n",
      "epochs  22  : val loss tensor(0.6937, device='cuda:0') training loss 0.6937572793527083\n",
      "(294912,) (294912,)\n",
      "ACC 0.6345926920572916 1 104091\n",
      "None\n",
      "epochs  23  : val loss tensor(0.6936, device='cuda:0') training loss 0.6936721259897406\n",
      "(294912,) (294912,)\n",
      "ACC 0.6469963921440972 1 99947\n",
      "None\n",
      "epochs  24  : val loss tensor(0.6936, device='cuda:0') training loss 0.6935949542305686\n",
      "(294912,) (294912,)\n",
      "ACC 0.6633978949652778 1 94648\n",
      "None\n",
      "epochs  25  : val loss tensor(0.6935, device='cuda:0') training loss 0.6935255310752175\n",
      "(294912,) (294912,)\n",
      "ACC 0.6734517415364584 1 91393\n",
      "None\n",
      "epochs  26  : val loss tensor(0.6934, device='cuda:0') training loss 0.6934628757563505\n",
      "(294912,) (294912,)\n",
      "ACC 0.6812540690104166 1 88954\n",
      "None\n",
      "epochs  27  : val loss tensor(0.6934, device='cuda:0') training loss 0.6934057582508434\n",
      "(294912,) (294912,)\n",
      "ACC 0.6904669867621528 1 86053\n",
      "None\n",
      "epochs  28  : val loss tensor(0.6933, device='cuda:0') training loss 0.6933542056517168\n",
      "(294912,) (294912,)\n",
      "ACC 0.706146240234375 1 81017\n",
      "None\n",
      "epochs  29  : val loss tensor(0.6933, device='cuda:0') training loss 0.6933086893775247\n",
      "(294912,) (294912,)\n",
      "ACC 0.7238260904947916 1 74267\n",
      "None\n",
      "epochs  30  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932694207538258\n",
      "(294912,) (294912,)\n",
      "ACC 0.7482028537326388 1 66168\n",
      "None\n",
      "epochs  31  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932371963154186\n",
      "(294912,) (294912,)\n",
      "ACC 0.7792392306857638 1 56053\n",
      "None\n",
      "epochs  32  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932132244110107\n",
      "(294912,) (294912,)\n",
      "ACC 0.8173116048177084 1 41029\n",
      "None\n",
      "epochs  33  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931959390640259\n",
      "(294912,) (294912,)\n",
      "ACC 0.8266465928819444 1 37514\n",
      "None\n",
      "epochs  34  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931817314841531\n",
      "(294912,) (294912,)\n",
      "ACC 0.8445197211371528 1 31541\n",
      "None\n",
      "epochs  35  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931711760434237\n",
      "(294912,) (294912,)\n",
      "ACC 0.8626708984375 1 25768\n",
      "None\n",
      "epochs  36  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931646737185392\n",
      "(294912,) (294912,)\n",
      "ACC 0.8731892903645834 1 21268\n",
      "None\n",
      "epochs  37  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931603767655112\n",
      "(294912,) (294912,)\n",
      "ACC 0.8853488498263888 1 17298\n",
      "None\n",
      "epochs  38  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931579113006592\n",
      "(294912,) (294912,)\n",
      "ACC 0.8870680067274306 1 15355\n",
      "None\n",
      "epochs  39  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931558359753002\n",
      "(294912,) (294912,)\n",
      "ACC 0.8870747884114584 1 15217\n",
      "None\n",
      "epochs  40  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931540044871244\n",
      "(294912,) (294912,)\n",
      "ACC 0.891082763671875 1 13269\n",
      "None\n",
      "epochs  41  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931525468826294\n",
      "(294912,) (294912,)\n",
      "ACC 0.8944261338975694 1 11151\n",
      "None\n",
      "epochs  42  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931515715338967\n",
      "(294912,) (294912,)\n",
      "ACC 0.8943277994791666 1 11218\n",
      "None\n",
      "epochs  43  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931507316502658\n",
      "(294912,) (294912,)\n",
      "ACC 0.8944837782118056 1 11096\n",
      "None\n",
      "epochs  44  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931499513712797\n",
      "(294912,) (294912,)\n",
      "ACC 0.8947007921006944 1 10946\n",
      "None\n",
      "epochs  45  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931492144411261\n",
      "(294912,) (294912,)\n",
      "ACC 0.8946940104166666 1 11134\n",
      "None\n",
      "epochs  46  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931486454876986\n",
      "(294912,) (294912,)\n",
      "ACC 0.8998209635416666 1 7000\n",
      "None\n",
      "epochs  47  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931483257900585\n",
      "(294912,) (294912,)\n",
      "ACC 0.9001634385850694 1 6745\n",
      "None\n",
      "epochs  48  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931480169296265\n",
      "(294912,) (294912,)\n",
      "ACC 0.900238037109375 1 6753\n",
      "None\n",
      "epochs  49  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931477730924432\n",
      "(294912,) (294912,)\n",
      "ACC 0.9000311957465278 1 6802\n",
      "None\n",
      "epochs  50  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931475021622397\n",
      "(294912,) (294912,)\n",
      "ACC 0.901885986328125 1 4691\n",
      "None\n",
      "epochs  51  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473666971381\n",
      "(294912,) (294912,)\n",
      "ACC 0.9054734971788194 1 335\n",
      "None\n",
      "epochs  52  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9045240614149306 1 1039\n",
      "None\n",
      "epochs  53  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9052225748697916 1 531\n",
      "None\n",
      "epochs  54  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9057854546440972 1 127\n",
      "None\n",
      "epochs  55  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059346516927084 1 15\n",
      "None\n",
      "epochs  56  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059583875868056 1 6\n",
      "None\n",
      "epochs  57  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059278700086806 1 13\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs  58  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059516059027778 1 6\n",
      "None\n",
      "epochs  59  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  60  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059651692708334 1 2\n",
      "None\n",
      "epochs  61  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059651692708334 1 2\n",
      "None\n",
      "epochs  62  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  63  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  64  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  65  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  66  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  67  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n",
      "epochs  68  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9059719509548612 1 0\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-614a9e20af5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./../models/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dnn_generation.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/TrainingGeneratorDnn2.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mtotal_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/RnnGenerateDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tg=TrainingGenerator(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'dnn_generation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
