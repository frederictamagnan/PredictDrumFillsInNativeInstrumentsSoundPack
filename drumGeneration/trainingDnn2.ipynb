{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingGeneratorDnn2 import TrainingGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "BATCH_SIZE=2048\n",
    "N_EPOCHS=200\n",
    "local_dataset='/home/ftamagnan/dataset/FillsExtractedSupervised.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on GPU\n",
      "(36948, 2, 16, 9) SHAPE NUMPU\n",
      "36948 LEN DATASET\n",
      "22168 SELF TRAIN\n",
      "7390 SELF validation\n",
      "7390 SELF test\n",
      "139920 PARAMETERS_RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftamagnan/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/TrainingGeneratorDnn2.py:108: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  total_val_loss += val_loss_size.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs  0  : val loss tensor(0.7014, device='cuda:0') training loss 0.7016647338867188\n",
      "(294912,) (294912,)\n",
      "ACC 0.5208095974392362 1 139618\n",
      "None\n",
      "epochs  1  : val loss tensor(0.7007, device='cuda:0') training loss 0.7010935008525848\n",
      "(294912,) (294912,)\n",
      "ACC 0.5229356553819444 1 138943\n",
      "None\n",
      "epochs  2  : val loss tensor(0.7000, device='cuda:0') training loss 0.7003670871257782\n",
      "(294912,) (294912,)\n",
      "ACC 0.5239766438802084 1 138594\n",
      "None\n",
      "epochs  3  : val loss tensor(0.6993, device='cuda:0') training loss 0.6996666371822358\n",
      "(294912,) (294912,)\n",
      "ACC 0.5227016872829862 1 138876\n",
      "None\n",
      "epochs  4  : val loss tensor(0.6987, device='cuda:0') training loss 0.6990411043167114\n",
      "(294912,) (294912,)\n",
      "ACC 0.5236985948350694 1 138428\n",
      "None\n",
      "epochs  5  : val loss tensor(0.6982, device='cuda:0') training loss 0.6984885454177856\n",
      "(294912,) (294912,)\n",
      "ACC 0.5227457682291666 1 138637\n",
      "None\n",
      "epochs  6  : val loss tensor(0.6978, device='cuda:0') training loss 0.6980057716369629\n",
      "(294912,) (294912,)\n",
      "ACC 0.5237562391493056 1 138315\n",
      "None\n",
      "epochs  7  : val loss tensor(0.6974, device='cuda:0') training loss 0.6975760400295258\n",
      "(294912,) (294912,)\n",
      "ACC 0.52496337890625 1 138035\n",
      "None\n",
      "epochs  8  : val loss tensor(0.6970, device='cuda:0') training loss 0.6971895337104798\n",
      "(294912,) (294912,)\n",
      "ACC 0.5249735514322916 1 137910\n",
      "None\n",
      "epochs  9  : val loss tensor(0.6967, device='cuda:0') training loss 0.6968388259410858\n",
      "(294912,) (294912,)\n",
      "ACC 0.5274149576822916 1 137144\n",
      "None\n",
      "epochs  10  : val loss tensor(0.6964, device='cuda:0') training loss 0.6965235590934753\n",
      "(294912,) (294912,)\n",
      "ACC 0.5278218587239584 1 137052\n",
      "None\n",
      "epochs  11  : val loss tensor(0.6961, device='cuda:0') training loss 0.6962321877479554\n",
      "(294912,) (294912,)\n",
      "ACC 0.5289781358506944 1 136661\n",
      "None\n",
      "epochs  12  : val loss tensor(0.6958, device='cuda:0') training loss 0.6959644854068756\n",
      "(294912,) (294912,)\n",
      "ACC 0.5298902723524306 1 136332\n",
      "None\n",
      "epochs  13  : val loss tensor(0.6956, device='cuda:0') training loss 0.695716792345047\n",
      "(294912,) (294912,)\n",
      "ACC 0.5310872395833334 1 135967\n",
      "None\n",
      "epochs  14  : val loss tensor(0.6954, device='cuda:0') training loss 0.6954875409603118\n",
      "(294912,) (294912,)\n",
      "ACC 0.5337388780381944 1 135133\n",
      "None\n",
      "epochs  15  : val loss tensor(0.6952, device='cuda:0') training loss 0.6952747285366059\n",
      "(294912,) (294912,)\n",
      "ACC 0.5358106825086806 1 134386\n",
      "None\n",
      "epochs  16  : val loss tensor(0.6950, device='cuda:0') training loss 0.6950752556324005\n",
      "(294912,) (294912,)\n",
      "ACC 0.538360595703125 1 133484\n",
      "None\n",
      "epochs  17  : val loss tensor(0.6948, device='cuda:0') training loss 0.6948918282985688\n",
      "(294912,) (294912,)\n",
      "ACC 0.5420057508680556 1 132201\n",
      "None\n",
      "epochs  18  : val loss tensor(0.6946, device='cuda:0') training loss 0.6947195768356323\n",
      "(294912,) (294912,)\n",
      "ACC 0.545440673828125 1 131042\n",
      "None\n",
      "epochs  19  : val loss tensor(0.6945, device='cuda:0') training loss 0.6945586621761322\n",
      "(294912,) (294912,)\n",
      "ACC 0.5503811306423612 1 129453\n",
      "None\n",
      "epochs  20  : val loss tensor(0.6943, device='cuda:0') training loss 0.6944111168384552\n",
      "(294912,) (294912,)\n",
      "ACC 0.5568101671006944 1 127367\n",
      "None\n",
      "epochs  21  : val loss tensor(0.6942, device='cuda:0') training loss 0.6942730188369751\n",
      "(294912,) (294912,)\n",
      "ACC 0.5662740071614584 1 124372\n",
      "None\n",
      "epochs  22  : val loss tensor(0.6941, device='cuda:0') training loss 0.694146853685379\n",
      "(294912,) (294912,)\n",
      "ACC 0.573883056640625 1 121844\n",
      "None\n",
      "epochs  23  : val loss tensor(0.6940, device='cuda:0') training loss 0.6940282702445983\n",
      "(294912,) (294912,)\n",
      "ACC 0.5816311306423612 1 119433\n",
      "None\n",
      "epochs  24  : val loss tensor(0.6939, device='cuda:0') training loss 0.6939186692237854\n",
      "(294912,) (294912,)\n",
      "ACC 0.5907016330295138 1 116516\n",
      "None\n",
      "epochs  25  : val loss tensor(0.6938, device='cuda:0') training loss 0.6938171148300171\n",
      "(294912,) (294912,)\n",
      "ACC 0.6061164008246528 1 111506\n",
      "None\n",
      "epochs  26  : val loss tensor(0.6937, device='cuda:0') training loss 0.6937248170375824\n",
      "(294912,) (294912,)\n",
      "ACC 0.6216939290364584 1 106204\n",
      "None\n",
      "epochs  27  : val loss tensor(0.6936, device='cuda:0') training loss 0.6936410009860993\n",
      "(294912,) (294912,)\n",
      "ACC 0.6393059624565972 1 100508\n",
      "None\n",
      "epochs  28  : val loss tensor(0.6935, device='cuda:0') training loss 0.6935647070407868\n",
      "(294912,) (294912,)\n",
      "ACC 0.6637471516927084 1 92608\n",
      "None\n",
      "epochs  29  : val loss tensor(0.6935, device='cuda:0') training loss 0.6934973776340485\n",
      "(294912,) (294912,)\n",
      "ACC 0.687744140625 1 85109\n",
      "None\n",
      "epochs  30  : val loss tensor(0.6934, device='cuda:0') training loss 0.6934379518032074\n",
      "(294912,) (294912,)\n",
      "ACC 0.7118326822916666 1 77331\n",
      "None\n",
      "epochs  31  : val loss tensor(0.6934, device='cuda:0') training loss 0.6933857262134552\n",
      "(294912,) (294912,)\n",
      "ACC 0.7164137098524306 1 75772\n",
      "None\n",
      "epochs  32  : val loss tensor(0.6933, device='cuda:0') training loss 0.6933380842208863\n",
      "(294912,) (294912,)\n",
      "ACC 0.7299669053819444 1 71319\n",
      "None\n",
      "epochs  33  : val loss tensor(0.6933, device='cuda:0') training loss 0.6932958543300629\n",
      "(294912,) (294912,)\n",
      "ACC 0.7635565863715278 1 59801\n",
      "None\n",
      "epochs  34  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932606995105743\n",
      "(294912,) (294912,)\n",
      "ACC 0.7799479166666666 1 54555\n",
      "None\n",
      "epochs  35  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932309329509735\n",
      "(294912,) (294912,)\n",
      "ACC 0.8093736436631944 1 43227\n",
      "None\n",
      "epochs  36  : val loss tensor(0.6932, device='cuda:0') training loss 0.6932064652442932\n",
      "(294912,) (294912,)\n",
      "ACC 0.8182712131076388 1 39131\n",
      "None\n",
      "epochs  37  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931857764720917\n",
      "(294912,) (294912,)\n",
      "ACC 0.8353644476996528 1 33822\n",
      "None\n",
      "epochs  38  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931690633296966\n",
      "(294912,) (294912,)\n",
      "ACC 0.8626471625434028 1 24936\n",
      "None\n",
      "epochs  39  : val loss tensor(0.6932, device='cuda:0') training loss 0.6931572675704956\n",
      "(294912,) (294912,)\n",
      "ACC 0.8859659830729166 1 17575\n",
      "None\n",
      "epochs  40  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931511402130127\n",
      "(294912,) (294912,)\n",
      "ACC 0.9169921875 1 6337\n",
      "None\n",
      "epochs  41  : val loss tensor(0.6931, device='cuda:0') training loss 0.693149209022522\n",
      "(294912,) (294912,)\n",
      "ACC 0.92315673828125 1 4257\n",
      "None\n",
      "epochs  42  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931484520435334\n",
      "(294912,) (294912,)\n",
      "ACC 0.9231126573350694 1 4272\n",
      "None\n",
      "epochs  43  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931479096412658\n",
      "(294912,) (294912,)\n",
      "ACC 0.9274631076388888 1 2207\n",
      "None\n",
      "epochs  44  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931477129459381\n",
      "(294912,) (294912,)\n",
      "ACC 0.9275275336371528 1 2184\n",
      "None\n",
      "epochs  45  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931474685668946\n",
      "(294912,) (294912,)\n",
      "ACC 0.9274834526909722 1 2209\n",
      "None\n",
      "epochs  46  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9301317003038194 1 144\n",
      "None\n",
      "epochs  47  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9303317599826388 1 91\n",
      "None\n",
      "epochs  48  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9303656684027778 1 75\n",
      "None\n",
      "epochs  49  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9303453233506944 1 85\n",
      "None\n",
      "epochs  50  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9303351508246528 1 88\n",
      "None\n",
      "epochs  51  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9304097493489584 1 68\n",
      "None\n",
      "epochs  52  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9304097493489584 1 66\n",
      "None\n",
      "epochs  53  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9304300944010416 1 56\n",
      "None\n",
      "epochs  54  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9304436577690972 1 54\n",
      "None\n",
      "epochs  55  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305148654513888 1 35\n",
      "None\n",
      "epochs  56  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305352105034722 1 23\n",
      "None\n",
      "epochs  57  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305013020833334 1 31\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs  58  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305521647135416 1 20\n",
      "None\n",
      "epochs  59  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305589463975694 1 16\n",
      "None\n",
      "epochs  60  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305657280815972 1 12\n",
      "None\n",
      "epochs  61  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305928548177084 1 6\n",
      "None\n",
      "epochs  62  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305826822916666 1 9\n",
      "None\n",
      "epochs  63  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9305996365017362 1 2\n",
      "None\n",
      "epochs  64  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9306064181857638 1 0\n",
      "None\n",
      "epochs  65  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.93060302734375 1 1\n",
      "None\n",
      "epochs  66  : val loss tensor(0.6931, device='cuda:0') training loss 0.6931473612785339\n",
      "(294912,) (294912,)\n",
      "ACC 0.9306064181857638 1 0\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-614a9e20af5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./../models/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dnn_generation.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/TrainingGeneratorDnn2.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PredictDrumFillsInNativeInstrumentsSoundPack/drumGeneration/RnnGenerateDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tg=TrainingGenerator(lr=LR,batch_size=BATCH_SIZE,n_epochs=N_EPOCHS,dataset_filepath=local_dataset)\n",
    "tg.load_data()\n",
    "tg.split_data()\n",
    "tg.train_model()\n",
    "tg.save_model(\"./../models/\",'dnn_generation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
